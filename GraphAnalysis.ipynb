{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Analysis Script\n",
    "This script will contain the following analyses:\n",
    "* Spectral Graph Partitioning\n",
    "* Node Degree Centrality Analysis\n",
    "* Hierarchy Index Calculation\n",
    "* Rich Club Coefficient Calculation\n",
    "* Triangulative Potential Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the required environment (skip if already done)\n",
    "\n",
    "Running the following cell will create a file graphs.yml that can be used to setup a conda environment containing the required packages. If you already downloaded the file from my GitHub, skip the next cell and create the env directly from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile graphs.yml\n",
    "name: graphs\n",
    "channels:\n",
    "  - conda-forge\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - python=3.6\n",
    "  - jupyter\n",
    "  - imageio\n",
    "  - imageio-ffmpeg\n",
    "  - matplotlib\n",
    "  - scikit-image\n",
    "  - opencv\n",
    "  - networkx\n",
    "  - pandas\n",
    "  - statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Creation\n",
    "To create the environment, open the terminal, go to the directory where you stored the graphs.yml file (the directory of the notebook) and type\n",
    "conda env create -f graphs.yml\n",
    "After running this command you have to activate the environment (Linux/MacOS: conda activate graphs, Windows: activate graphs) and then reopen the notebook in that environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import glob\n",
    "import scipy.cluster.vq as clusters\n",
    "import scipy.sparse as sparse\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from pandas.plotting import autocorrelation_plot as AC_plot \n",
    "from statsmodels.graphics import tsaplots\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from skimage.filters import gaussian\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "\n",
    "OG_DATA_PATH = './'\n",
    "GIT_DATA_PATH = './Data Exploration/'\n",
    "GIT_PROCESSED_DATA_PATH = './Results/'\n",
    "GIT_GRAPH_PATH = './Results/Graphs/'\n",
    "RESSOURCES_PATH = './Ressources/'\n",
    "\n",
    "# Reset the Datapath since the data is not yet on Git, comment out if data is on Git \n",
    "DATA_PATH = '/Volumes/EXTENSION/Uni/Study Project/Data Exploration/'\n",
    "\n",
    "PROCESSED_DATA_PATH = '/Volumes/EXTENSION/Uni/Study Project/Results/'\n",
    "GRAPH_DATA_PATH = '/Volumes/EXTENSION/Uni/Study Project/Results/Graphs/'\n",
    "# Getting the Folder without hidden files in ascending order \n",
    "DATA_FOLDER = sorted([f for f in os.listdir(DATA_PATH) if not f.startswith('.')], key=str.lower)\n",
    "PROCESSED_DATA_FOLDER = sorted([f for f in os.listdir(PROCESSED_DATA_PATH) if not f.startswith('.')], key=str.lower)\n",
    "GIT_PROCESSED_DATA_FOLDER = sorted([f for f in os.listdir(GIT_PROCESSED_DATA_PATH) if not f.startswith('.')], key=str.lower)\n",
    "GIT_GRAPH_FOLDER = sorted([f for f in os.listdir(GIT_GRAPH_PATH) if not f.startswith('.')], key=str.lower)\n",
    "\n",
    "#houselist \n",
    "house_file = RESSOURCES_PATH + 'building_collider_list.csv'\n",
    "try:\n",
    "    houselist = pd.read_csv(house_file)\n",
    "except:\n",
    "    print('HouseList could not be loaded!')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting all subject IDs from the data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1005 1008 1010 1011 1013 1017 1018 1019 1021 1023 1079 1080]\n"
     ]
    }
   ],
   "source": [
    "subIDs = []\n",
    "for sub in DATA_FOLDER:\n",
    "    if sub[0].isdigit():\n",
    "        subIDs.append(int(sub[0:4]))\n",
    "    else:\n",
    "        pass\n",
    "subIDs = np.unique(subIDs)\n",
    "print(subIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom subID\n",
    "subIDs = [1005]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the edgelists and creating the graphs \n",
    "* Also including the analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 1005 started - 1/1\n",
      "smallest Eigenvalue is 0\n",
      "Graph is fully connected\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# --------- Preparation ---------\n",
    "Plotting_bool = False # if you want to plot the graph\n",
    "Graph_save_img_bool = False # if you want to save the graph as an image\n",
    "plot_edges_bool = False # if you want to plot the graph's edges\n",
    "save_centrality = False # if you want to save the centrality dataframe (node degree) as csv \n",
    "\n",
    "calculate_Partitioning = True # if you want to calculate the graph partitioning\n",
    "calculate_ND = False # if you want to calculate the node degree statistics\n",
    "calculate_Hierarchy = False  # if you want to calculate the hierarchy index \n",
    "calculate_RC = False  # if you want to calculate the rich club coefficient\n",
    "calculate_triang = False  # if you want to calculate the triangulation\n",
    "\n",
    "subcount = 0 # count subjects\n",
    "\n",
    "# implement parula color map scheme from matlab \n",
    "cm_data = [[0.2081, 0.1663, 0.5292], [0.2116238095, 0.1897809524, 0.5776761905], \n",
    " [0.212252381, 0.2137714286, 0.6269714286], [0.2081, 0.2386, 0.6770857143], \n",
    " [0.1959047619, 0.2644571429, 0.7279], [0.1707285714, 0.2919380952, \n",
    "  0.779247619], [0.1252714286, 0.3242428571, 0.8302714286], \n",
    " [0.0591333333, 0.3598333333, 0.8683333333], [0.0116952381, 0.3875095238, \n",
    "  0.8819571429], [0.0059571429, 0.4086142857, 0.8828428571], \n",
    " [0.0165142857, 0.4266, 0.8786333333], [0.032852381, 0.4430428571, \n",
    "  0.8719571429], [0.0498142857, 0.4585714286, 0.8640571429], \n",
    " [0.0629333333, 0.4736904762, 0.8554380952], [0.0722666667, 0.4886666667, \n",
    "  0.8467], [0.0779428571, 0.5039857143, 0.8383714286], \n",
    " [0.079347619, 0.5200238095, 0.8311809524], [0.0749428571, 0.5375428571, \n",
    "  0.8262714286], [0.0640571429, 0.5569857143, 0.8239571429], \n",
    " [0.0487714286, 0.5772238095, 0.8228285714], [0.0343428571, 0.5965809524, \n",
    "  0.819852381], [0.0265, 0.6137, 0.8135], [0.0238904762, 0.6286619048, \n",
    "  0.8037619048], [0.0230904762, 0.6417857143, 0.7912666667], \n",
    " [0.0227714286, 0.6534857143, 0.7767571429], [0.0266619048, 0.6641952381, \n",
    "  0.7607190476], [0.0383714286, 0.6742714286, 0.743552381], \n",
    " [0.0589714286, 0.6837571429, 0.7253857143], \n",
    " [0.0843, 0.6928333333, 0.7061666667], [0.1132952381, 0.7015, 0.6858571429], \n",
    " [0.1452714286, 0.7097571429, 0.6646285714], [0.1801333333, 0.7176571429, \n",
    "  0.6424333333], [0.2178285714, 0.7250428571, 0.6192619048], \n",
    " [0.2586428571, 0.7317142857, 0.5954285714], [0.3021714286, 0.7376047619, \n",
    "  0.5711857143], [0.3481666667, 0.7424333333, 0.5472666667], \n",
    " [0.3952571429, 0.7459, 0.5244428571], [0.4420095238, 0.7480809524, \n",
    "  0.5033142857], [0.4871238095, 0.7490619048, 0.4839761905], \n",
    " [0.5300285714, 0.7491142857, 0.4661142857], [0.5708571429, 0.7485190476, \n",
    "  0.4493904762], [0.609852381, 0.7473142857, 0.4336857143], \n",
    " [0.6473, 0.7456, 0.4188], [0.6834190476, 0.7434761905, 0.4044333333], \n",
    " [0.7184095238, 0.7411333333, 0.3904761905], \n",
    " [0.7524857143, 0.7384, 0.3768142857], [0.7858428571, 0.7355666667, \n",
    "  0.3632714286], [0.8185047619, 0.7327333333, 0.3497904762], \n",
    " [0.8506571429, 0.7299, 0.3360285714], [0.8824333333, 0.7274333333, 0.3217], \n",
    " [0.9139333333, 0.7257857143, 0.3062761905], [0.9449571429, 0.7261142857, \n",
    "  0.2886428571], [0.9738952381, 0.7313952381, 0.266647619], \n",
    " [0.9937714286, 0.7454571429, 0.240347619], [0.9990428571, 0.7653142857, \n",
    "  0.2164142857], [0.9955333333, 0.7860571429, 0.196652381], \n",
    " [0.988, 0.8066, 0.1793666667], [0.9788571429, 0.8271428571, 0.1633142857], \n",
    " [0.9697, 0.8481380952, 0.147452381], [0.9625857143, 0.8705142857, 0.1309], \n",
    " [0.9588714286, 0.8949, 0.1132428571], [0.9598238095, 0.9218333333, \n",
    "  0.0948380952], [0.9661, 0.9514428571, 0.0755333333], \n",
    " [0.9763, 0.9831, 0.0538]]\n",
    "\n",
    "parula_map = LinearSegmentedColormap.from_list('parula', cm_data)\n",
    "\n",
    "# load the city map image\n",
    "white_bg_img = cv2.imread(\"./ressources/map_white.png\")\n",
    "\n",
    "# Dataframe for degrees with colums = subject + houselist\n",
    "centrality_df = pd.DataFrame(columns= [*['Subject'], *np.unique(houselist.target_collider_name)])\n",
    "\n",
    "\n",
    "\n",
    "# --------- MAIN PART ---------\n",
    "# load the files \n",
    "for subject in subIDs:\n",
    "    subcount +=1\n",
    "    print('Subject ' + str(subject) + ' started - ' + str(subcount) + '/' + str(len(subIDs)))\n",
    "    \n",
    "    # get the data files according to the subject\n",
    "    subject_folder = sorted([f for f in GIT_GRAPH_FOLDER \n",
    "                             if f.startswith(str(subject)+'_edgelist')], key=str.lower)\n",
    "\n",
    "    if len(subject_folder) != 0:\n",
    "        \n",
    "        # open the JSON file as dictionary\n",
    "        with open(GIT_GRAPH_PATH + subject_folder[0]) as f:\n",
    "            try:\n",
    "                edge_list = pd.read_csv(f)\n",
    "            except:\n",
    "                    print(\"\\tCould not load subject \" + str(subject) + \" edgelist!\")\n",
    "\n",
    "    else:\n",
    "        print('Subject ' + str(subject) + ' has no data file!')\n",
    "        continue \n",
    "\n",
    "\n",
    "\n",
    "    # --------- GRAPH CREATION ---------\n",
    "\n",
    "    # create graph from edgelist\n",
    "    G = nx.Graph()\n",
    "    G = nx.from_pandas_edgelist(edge_list, 'Edge1', 'Edge2')\n",
    "\n",
    "\n",
    "    # Setting the node coordinates of each node of the graph\n",
    "\n",
    "\n",
    "    # node list\n",
    "    nodelist = list(G.nodes)\n",
    "    nodearray = np.array(G.nodes)\n",
    "\n",
    "    # coord dict\n",
    "    node_pos = {}\n",
    "\n",
    "    for node in nodelist:\n",
    "        # assign node coordinates\n",
    "        x = houselist['transformed_collidercenter_x'][houselist.target_collider_name==node].values[0]\n",
    "        y = houselist['transformed_collidercenter_y'][houselist.target_collider_name==node].values[0]\n",
    "        node_pos[node] = (x,y) \n",
    "\n",
    "    # set the graph's node coordinates attribute\n",
    "    nx.set_node_attributes(G, node_pos, 'coord')\n",
    "\n",
    "\n",
    "    # --------- ANALYSIS ---------\n",
    "\n",
    "    # --------- PARTITIONING ---------\n",
    "    if calculate_Partitioning == True:     \n",
    "        # ---- Step 1 ----\n",
    "        \n",
    "        # get laplacian matrix and its eigenvalues + eigenvectors\n",
    "        laplacian_matrix = nx.laplacian_matrix(G)\n",
    "        laplacian_matrix = sparse.csr_matrix.toarray(laplacian_matrix)\n",
    "        # Eigenvalues and vectors\n",
    "        Eigenvalue, Eigenvector = np.linalg.eig(laplacian_matrix)\n",
    "        # sort Eigenvalues in ascending order and use index to sort eigenvectors\n",
    "        index_array = np.argsort(Eigenvalue)\n",
    "        eig_vec_index = np.argsort(Eigenvector[index_array][1])\n",
    "    \n",
    "        # check if smallest eigenvalue is 0 (or close to 0)\n",
    "        if Eigenvalue[index_array][0] < 1e-10:\n",
    "            print('smallest Eigenvalue is 0')\n",
    "            # check if second smallest eigenvalue is larger 0 (this means the graph is fully connected)\n",
    "            if Eigenvalue[index_array][1] > 1e-10:\n",
    "                print('Graph is fully connected')\n",
    "                \n",
    "                # create a dataframe and assign both the eigenvector sorted\n",
    "                house_eig_df = pd.DataFrame()\n",
    "                house_eig_df['House'] = nodearray[eig_vec_index]\n",
    "                house_eig_df['Eigenvector'] = Eigenvector[index_array][1][eig_vec_index]\n",
    "                \n",
    "                eig_pos = house_eig_df[house_eig_df.Eigenvector > 0]\n",
    "                eig_neg = house_eig_df[house_eig_df.Eigenvector < 0]\n",
    "                \n",
    "                \n",
    "                \n",
    "            else:\n",
    "                print('Graph is not fully connected')\n",
    "    \n",
    "    \n",
    "    # --------- NODE DEGREE ---------\n",
    "    if calculate_ND == True: \n",
    "    \n",
    "        # create degree list of the graph \n",
    "        sub_degree = dict(list(G.degree))\n",
    "        # add the subject ID to the dictionary\n",
    "        sub_degree.update({'Subject': str(subject)})  \n",
    "        # append the centrality df by the subjects degree list\n",
    "        centrality_df = centrality_df.append(sub_degree, ignore_index=True)\n",
    "        #centrality_df['betweenness'] = list(nx.betweenness_centrality(G))\n",
    "\n",
    "\n",
    "        mean_degree = np.nanmean(pd.to_numeric(centrality_df[centrality_df.Subject==str(subject)].values[0])[1:])\n",
    "        std_degree = np.nanstd(pd.to_numeric(centrality_df[centrality_df.Subject==str(subject)].values[0])[1:])\n",
    "        max_degree = max(pd.to_numeric(centrality_df[centrality_df.Subject==str(subject)].values[0])[1:])\n",
    "\n",
    "\n",
    "    \n",
    "    # --------- HIERARCHY INDEX ---------\n",
    "    if calculate_Hierarchy == True: \n",
    "        pass\n",
    "    \n",
    "    \n",
    "    # --------- RICH CLUB COEFFICIENT ---------\n",
    "    if calculate_RC == True:     \n",
    "        pass\n",
    "    \n",
    "    \n",
    "    # --------- TRIANGULATION ---------\n",
    "    if calculate_triang == True: \n",
    "        pass\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    # --------- PLOTTING ---------    \n",
    "\n",
    "    if Plotting_bool == True:\n",
    "\n",
    "        # plot the map\n",
    "        fig = plt.figure(figsize=(20,15))\n",
    "        ax = plt.subplot2grid((10, 10), (0, 0), colspan=9,rowspan=10)\n",
    "        plt.title(\"Graph on Map - Subject \" + str(subject))\n",
    "        plt.xlim(0, 4096)\n",
    "        plt.ylim(0, 4096)\n",
    "        ax.set_frame_on(False)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(white_bg_img,aspect=ax.get_aspect(),\n",
    "                 extent= ax.get_xlim() + ax.get_ylim(),\n",
    "                 zorder=1, alpha=0.8)\n",
    "\n",
    "        # Draw the graph \n",
    "        vmin = centrality_df['degree'].min()\n",
    "        vmax = centrality_df['degree'].max()\n",
    "\n",
    "        nx.draw_networkx_nodes(G,\n",
    "                               node_pos, \n",
    "                               alpha = 1, \n",
    "                               node_size = 100, \n",
    "                               node_color=centrality_df['degree'], \n",
    "                               cmap=parula_map)\n",
    "\n",
    "        if plot_edges_bool == True:\n",
    "            nx.draw_networkx_edges(G, \n",
    "                                   node_pos, \n",
    "                                   edge_color='k', \n",
    "                                   alpha=0.5, \n",
    "                                   width=1,\n",
    "                                   style='dashed')\n",
    "\n",
    "\n",
    "        # subgraph for highlighting single nodes\n",
    "        building = centrality_df.sort_values('degree', ascending=False)[:10].node.values\n",
    "        #nx.draw_networkx(G.subgraph(building), node_color = 'r', pos=node_pos, node_size=400)\n",
    "\n",
    "\n",
    "        sm = plt.cm.ScalarMappable(cmap=parula_map, norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "        sm.set_array([])\n",
    "        cbar = plt.colorbar(sm)\n",
    "        cbar.ax.tick_params(labelsize=20)\n",
    "        cbar.set_label('Node Degree', size=20)\n",
    "\n",
    "    else:\n",
    "        Graph_save_img_bool = False\n",
    "\n",
    "\n",
    "    # --------- SAVING ---------\n",
    "\n",
    "\n",
    "    # save the graph as png \n",
    "    if Graph_save_img_bool == True:\n",
    "        # saving the subject info dataframe\n",
    "        try:\n",
    "            plt.savefig(GIT_GRAPH_PATH + str(subject) + \"_Graph.png\", format=\"PNG\")\n",
    "\n",
    "            print(\"\\tGraph PNG saved\")\n",
    "        except:\n",
    "            print(\"\\tCould not save subject \" + str(subject) + \" Graph as PNG!\")\n",
    "\n",
    "            \n",
    "            \n",
    "# --------- SUBJECT INDEPENDENT SAVINGS ---------   \n",
    "            \n",
    "# Add the mean over both axes to the centrality df and save it \n",
    "\n",
    "\n",
    "house_mean_dict = dict(centrality_df.loc[:,centrality_df.columns[1:]].mean(axis=0))\n",
    "house_mean_dict.update({'Subject': 'Mean'})  \n",
    "                 \n",
    "house_std_dict = dict(centrality_df.loc[:,centrality_df.columns[1:]].std(axis=0))\n",
    "house_std_dict.update({'Subject': 'STD'})  \n",
    "                \n",
    "centrality_df = centrality_df.append(house_mean_dict, ignore_index=True)\n",
    "centrality_df = centrality_df.append(house_std_dict, ignore_index=True)\n",
    "\n",
    "subject_mean = centrality_df.loc[:,centrality_df.columns[1:]].mean(axis=1)\n",
    "subject_std = centrality_df.loc[:,centrality_df.columns[1:]].std(axis=1)\n",
    "                 \n",
    "centrality_df['Mean'] = subject_mean\n",
    "centrality_df['STD'] = subject_std\n",
    "    \n",
    "        \n",
    "if save_centrality == True: \n",
    "    # saving the subject info dataframe\n",
    "    try:\n",
    "        centrality_df.to_csv(GIT_GRAPH_PATH\n",
    "                        + \"_degree_table.csv\", \n",
    "                        index=False)\n",
    "\n",
    "        print(\"\\tCentrality Dataframe saved\")\n",
    "    except:\n",
    "        print(\"\\tCould not save centrality dataframe!\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "print('Done')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_eig_df['House'] = nodearray[eig_vec_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>House</th>\n",
       "      <th>Eigenvector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Building_123</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Building_142</td>\n",
       "      <td>0.000148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Building_185</td>\n",
       "      <td>0.000178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>crane_2</td>\n",
       "      <td>0.000603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>TaskBuilding_1</td>\n",
       "      <td>0.000932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>Building_172</td>\n",
       "      <td>0.183366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>TaskBuilding_52</td>\n",
       "      <td>0.185737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Building_152</td>\n",
       "      <td>0.218548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Building_124</td>\n",
       "      <td>0.281999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>TaskBuilding_40</td>\n",
       "      <td>0.329527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               House  Eigenvector\n",
       "107     Building_123     0.000071\n",
       "108     Building_142     0.000148\n",
       "109     Building_185     0.000178\n",
       "110          crane_2     0.000603\n",
       "111   TaskBuilding_1     0.000932\n",
       "..               ...          ...\n",
       "234     Building_172     0.183366\n",
       "235  TaskBuilding_52     0.185737\n",
       "236     Building_152     0.218548\n",
       "237     Building_124     0.281999\n",
       "238  TaskBuilding_40     0.329527\n",
       "\n",
       "[132 rows x 2 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eig_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 1005 started - 1/1\n"
     ]
    }
   ],
   "source": [
    "# --------- Preparation ---------\n",
    "Plotting_bool = False # if you want to plot the graph\n",
    "Graph_save_img_bool = False # if you want to save the graph as an image\n",
    "plot_edges_bool = False # if you want to plot the graph's edges\n",
    "save_centrality = False # if you want to save the centrality dataframe (node degree) as csv \n",
    "\n",
    "calculate_Partitioning = True # if you want to calculate the graph partitioning\n",
    "calculate_ND = False # if you want to calculate the node degree statistics\n",
    "calculate_Hierarchy = False  # if you want to calculate the hierarchy index \n",
    "calculate_RC = False  # if you want to calculate the rich club coefficient\n",
    "calculate_triang = False  # if you want to calculate the triangulation\n",
    "\n",
    "subcount = 0 # count subjects\n",
    "\n",
    "# implement parula color map scheme from matlab \n",
    "cm_data = [[0.2081, 0.1663, 0.5292], [0.2116238095, 0.1897809524, 0.5776761905], \n",
    " [0.212252381, 0.2137714286, 0.6269714286], [0.2081, 0.2386, 0.6770857143], \n",
    " [0.1959047619, 0.2644571429, 0.7279], [0.1707285714, 0.2919380952, \n",
    "  0.779247619], [0.1252714286, 0.3242428571, 0.8302714286], \n",
    " [0.0591333333, 0.3598333333, 0.8683333333], [0.0116952381, 0.3875095238, \n",
    "  0.8819571429], [0.0059571429, 0.4086142857, 0.8828428571], \n",
    " [0.0165142857, 0.4266, 0.8786333333], [0.032852381, 0.4430428571, \n",
    "  0.8719571429], [0.0498142857, 0.4585714286, 0.8640571429], \n",
    " [0.0629333333, 0.4736904762, 0.8554380952], [0.0722666667, 0.4886666667, \n",
    "  0.8467], [0.0779428571, 0.5039857143, 0.8383714286], \n",
    " [0.079347619, 0.5200238095, 0.8311809524], [0.0749428571, 0.5375428571, \n",
    "  0.8262714286], [0.0640571429, 0.5569857143, 0.8239571429], \n",
    " [0.0487714286, 0.5772238095, 0.8228285714], [0.0343428571, 0.5965809524, \n",
    "  0.819852381], [0.0265, 0.6137, 0.8135], [0.0238904762, 0.6286619048, \n",
    "  0.8037619048], [0.0230904762, 0.6417857143, 0.7912666667], \n",
    " [0.0227714286, 0.6534857143, 0.7767571429], [0.0266619048, 0.6641952381, \n",
    "  0.7607190476], [0.0383714286, 0.6742714286, 0.743552381], \n",
    " [0.0589714286, 0.6837571429, 0.7253857143], \n",
    " [0.0843, 0.6928333333, 0.7061666667], [0.1132952381, 0.7015, 0.6858571429], \n",
    " [0.1452714286, 0.7097571429, 0.6646285714], [0.1801333333, 0.7176571429, \n",
    "  0.6424333333], [0.2178285714, 0.7250428571, 0.6192619048], \n",
    " [0.2586428571, 0.7317142857, 0.5954285714], [0.3021714286, 0.7376047619, \n",
    "  0.5711857143], [0.3481666667, 0.7424333333, 0.5472666667], \n",
    " [0.3952571429, 0.7459, 0.5244428571], [0.4420095238, 0.7480809524, \n",
    "  0.5033142857], [0.4871238095, 0.7490619048, 0.4839761905], \n",
    " [0.5300285714, 0.7491142857, 0.4661142857], [0.5708571429, 0.7485190476, \n",
    "  0.4493904762], [0.609852381, 0.7473142857, 0.4336857143], \n",
    " [0.6473, 0.7456, 0.4188], [0.6834190476, 0.7434761905, 0.4044333333], \n",
    " [0.7184095238, 0.7411333333, 0.3904761905], \n",
    " [0.7524857143, 0.7384, 0.3768142857], [0.7858428571, 0.7355666667, \n",
    "  0.3632714286], [0.8185047619, 0.7327333333, 0.3497904762], \n",
    " [0.8506571429, 0.7299, 0.3360285714], [0.8824333333, 0.7274333333, 0.3217], \n",
    " [0.9139333333, 0.7257857143, 0.3062761905], [0.9449571429, 0.7261142857, \n",
    "  0.2886428571], [0.9738952381, 0.7313952381, 0.266647619], \n",
    " [0.9937714286, 0.7454571429, 0.240347619], [0.9990428571, 0.7653142857, \n",
    "  0.2164142857], [0.9955333333, 0.7860571429, 0.196652381], \n",
    " [0.988, 0.8066, 0.1793666667], [0.9788571429, 0.8271428571, 0.1633142857], \n",
    " [0.9697, 0.8481380952, 0.147452381], [0.9625857143, 0.8705142857, 0.1309], \n",
    " [0.9588714286, 0.8949, 0.1132428571], [0.9598238095, 0.9218333333, \n",
    "  0.0948380952], [0.9661, 0.9514428571, 0.0755333333], \n",
    " [0.9763, 0.9831, 0.0538]]\n",
    "\n",
    "parula_map = LinearSegmentedColormap.from_list('parula', cm_data)\n",
    "\n",
    "# load the city map image\n",
    "white_bg_img = cv2.imread(\"./ressources/map_white.png\")\n",
    "\n",
    "# Dataframe for degrees with colums = subject + houselist\n",
    "centrality_df = pd.DataFrame(columns= [*['Subject'], *np.unique(houselist.target_collider_name)])\n",
    "\n",
    "\n",
    "\n",
    "# --------- MAIN PART ---------\n",
    "# load the files \n",
    "for subject in subIDs:\n",
    "    subcount +=1\n",
    "    print('Subject ' + str(subject) + ' started - ' + str(subcount) + '/' + str(len(subIDs)))\n",
    "    \n",
    "    # get the data files according to the subject\n",
    "    subject_folder = sorted([f for f in GIT_GRAPH_FOLDER \n",
    "                             if f.startswith(str(subject)+'_edgelist')], key=str.lower)\n",
    "\n",
    "    if len(subject_folder) != 0:\n",
    "        \n",
    "        # open the JSON file as dictionary\n",
    "        with open(GIT_GRAPH_PATH + subject_folder[0]) as f:\n",
    "            try:\n",
    "                edge_list = pd.read_csv(f)\n",
    "            except:\n",
    "                    print(\"\\tCould not load subject \" + str(subject) + \" edgelist!\")\n",
    "\n",
    "    else:\n",
    "        print('Subject ' + str(subject) + ' has no data file!')\n",
    "        continue \n",
    "\n",
    "\n",
    "\n",
    "    # --------- GRAPH CREATION ---------\n",
    "\n",
    "    # create graph from edgelist\n",
    "    G = nx.Graph()\n",
    "    G = nx.from_pandas_edgelist(edge_list, 'Edge1', 'Edge2')\n",
    "\n",
    "\n",
    "    # Setting the node coordinates of each node of the graph\n",
    "\n",
    "\n",
    "    # node list\n",
    "    nodelist = list(G.nodes)\n",
    "\n",
    "    # coord dict\n",
    "    node_pos = {}\n",
    "\n",
    "    for node in nodelist:\n",
    "        # assign node coordinates\n",
    "        x = houselist['transformed_collidercenter_x'][houselist.target_collider_name==node].values[0]\n",
    "        y = houselist['transformed_collidercenter_y'][houselist.target_collider_name==node].values[0]\n",
    "        node_pos[node] = (x,y) \n",
    "\n",
    "    # set the graph's node coordinates attribute\n",
    "    nx.set_node_attributes(G, node_pos, 'coord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Laplacian_spectrum = nx.laplacian_spectrum(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplacian_matrix = nx.laplacian_matrix(G)\n",
    "laplacian_matrix = sparse.csr_matrix.toarray(laplacian_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplacian_matrix = nx.laplacian_matrix(G)\n",
    "laplacian_matrix = sparse.csr_matrix.toarray(laplacian_matrix)\n",
    "Eigenvalue, Eigenvector = np.linalg.eig(laplacian_matrix)\n",
    "\n",
    "index_array = np.argsort(Eigenvalue)\n",
    "eig_vec_index = np.argsort(Eigenvector[index_array][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_array = np.argsort(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_veg_index = np.argsort(v[index_array][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Building_118', 'Building_57', 'TaskBuilding_41', 'Building_119',\n",
       "       'Building_147', 'Building_72', 'Building_202', 'Building_141',\n",
       "       'Building_179', 'Building_191', 'Building_106', 'Building_168',\n",
       "       'TaskBuilding_54', 'TaskBuilding_47', 'Building_80',\n",
       "       'Building_113', 'Building_163', 'Building_151', 'Building_66',\n",
       "       'Building_65', 'Building_221', 'Building_186', 'Building_200',\n",
       "       'Building_59', 'Building_138', 'Garage_86', 'Building_187',\n",
       "       'Building_205', 'House_49', 'TaskBuilding_32', 'Building_183',\n",
       "       'Building_125', 'Building_92', 'Building_108', 'Building_161',\n",
       "       'Garage_235', 'Building_74', 'Building_134', 'Building_62',\n",
       "       'Building_96', 'Building_155', 'Building_153', 'Building_180',\n",
       "       'Building_160', 'Building_171', 'TaskBuilding_33', 'Building_135',\n",
       "       'TaskBuilding_48', 'TaskBuilding_29', 'TaskBuilding_23',\n",
       "       'Building_220', 'Building_149', 'Building_114', 'TaskBuilding_4',\n",
       "       'Building_131', 'Building_58', 'TaskBuilding_25', 'Building_103',\n",
       "       'TaskBuilding_27', 'Building_143', 'Building_136', 'Building_91',\n",
       "       'TaskBuilding_31', 'Building_189', 'Building_212', 'Building_234',\n",
       "       'TaskBuilding_11', 'Building_222', 'Building_154', 'Building_117',\n",
       "       'Building_232', 'Building_226', 'Building_197',\n",
       "       'Windmill-TaskBuilding_10_1', 'Building_99', 'Building_236',\n",
       "       'Building_90', 'TaskBuilding_34', 'Building_228', 'Building_157',\n",
       "       'Building_159', 'Building_81', 'Building_201',\n",
       "       'HighSilo-TaskBuilding_49', 'Building_101', 'TaskBuilding_51',\n",
       "       'Building_175', 'Building_230', 'TaskBuilding_19', 'Building_63',\n",
       "       'Building_215', 'Building_60', 'Church-TaskBuilding_16',\n",
       "       'Building_137', 'TaskBuilding_14', 'Building_130', 'Building_203',\n",
       "       'TaskBuilding_15', 'Building_94', 'Building_84', 'Building_93',\n",
       "       'Building_158', 'Building_199', 'Building_223', 'Building_68',\n",
       "       'Building_218', 'Building_156', 'Building_123', 'Building_142',\n",
       "       'Building_185', 'crane_2', 'TaskBuilding_1', 'Building_214',\n",
       "       'Building_88', 'Building_83', 'TaskBuilding_26', 'TaskBuilding_50',\n",
       "       'Building_87', 'TaskBuilding_44', 'Building_176', 'Building_61',\n",
       "       'Building_126', 'Building_69', 'TaskBuilding_35', 'Building_148',\n",
       "       'Building_75', 'Building_167', 'Building_162', 'Building_224',\n",
       "       'TaskBuilding_12', 'Building_71', 'Building_133',\n",
       "       'TaskBuilding_39', 'Building_181', 'TaskBuilding_37',\n",
       "       'TaskBuilding_5', 'Building_105', 'Building_213', 'Building_182',\n",
       "       'Building_combined_115_116', 'Building_89', 'Building_177',\n",
       "       'Building_122', 'TaskBuilding_38', 'Building_169', 'Building_216',\n",
       "       'Building_110', 'Building_132', 'Building_174', 'Building_102',\n",
       "       'Building_70', 'Building_86', 'TaskBuilding_21', 'Building_193',\n",
       "       'Garage_98', 'Building_210', 'Building_165', 'Building_217',\n",
       "       'Building_95', 'TaskBuilding_30', 'TaskBuilding_55',\n",
       "       'Building_107', 'Building_231', 'Building_85', 'TaskBuilding_13',\n",
       "       'Garage_224', 'Building_196', 'Building_166', 'Building_97',\n",
       "       'Building_192', 'TaskBuilding_46', 'Building_164', 'Building_173',\n",
       "       'TaskBuilding_7', 'Building_127', 'TaskBuilding_36',\n",
       "       'Building_111', 'TaskBuilding_20', 'Building_64', 'Building_227',\n",
       "       'TaskBuilding_18', 'TaskBuilding_3', 'TaskBuilding_45',\n",
       "       'TaskBuilding_53', 'TaskBuilding_43', 'Building_104',\n",
       "       'Building_120', 'Building_128', 'Building_204', 'Building_195',\n",
       "       'TaskBuilding_42', 'Garage_185', 'TaskBuilding_28', 'Building_150',\n",
       "       'Building_194', 'TaskBuilding_9', 'Building_208', 'Building_206',\n",
       "       'Building_139', 'Building_198', 'Building_233', 'Building_100',\n",
       "       'Castle-TaskBuilding_56', 'Building_67', 'Building_73',\n",
       "       'Building_146', 'Building_211', 'Building_188', 'TaskBuilding_2',\n",
       "       'crane_1', 'Building_178', 'Building_235', 'Building_170',\n",
       "       'Building_219', 'Building_184', 'Building_225', 'Building_98',\n",
       "       'House_10', 'Building_76', 'TaskBuilding_24', 'Building_229',\n",
       "       'TaskBuilding_17', 'TaskBuilding_6', 'TaskBuilding_22',\n",
       "       'Building_144', 'Building_207', 'Building_112', 'Building_109',\n",
       "       'TaskBuilding_8', 'Building_140', 'Building_209', 'Building_145',\n",
       "       'Building_121', 'Building_82', 'Building_172', 'TaskBuilding_52',\n",
       "       'Building_152', 'Building_124', 'TaskBuilding_40'], dtype='<U26')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = np.array(G.nodes)\n",
    "\n",
    "nodes[eig_veg_index]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
