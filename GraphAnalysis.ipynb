{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Analysis Script\n",
    "This script will contain the following analyses:\n",
    "* Spectral Graph Partitioning\n",
    "* Node Degree Centrality Analysis\n",
    "* Hierarchy Index Calculation\n",
    "* Rich Club Coefficient Calculation\n",
    "* Triangulative Potential Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the required environment (skip if already done)\n",
    "\n",
    "Running the following cell will create a file graphs.yml that can be used to setup a conda environment containing the required packages. If you already downloaded the file from my GitHub, skip the next cell and create the env directly from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile graphs.yml\n",
    "name: graphs\n",
    "channels:\n",
    "  - conda-forge\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - python=3.6\n",
    "  - jupyter\n",
    "  - imageio\n",
    "  - imageio-ffmpeg\n",
    "  - matplotlib\n",
    "  - scikit-image\n",
    "  - opencv\n",
    "  - networkx\n",
    "  - pandas\n",
    "  - statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Creation\n",
    "To create the environment, open the terminal, go to the directory where you stored the graphs.yml file (the directory of the notebook) and type\n",
    "conda env create -f graphs.yml\n",
    "After running this command you have to activate the environment (Linux/MacOS: conda activate graphs, Windows: activate graphs) and then reopen the notebook in that environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Imports:\n",
    "* To calculate the Rich Club coefficient (particularly the random degree distribution graphs), the package random_graph needs to be imported in the terminal by typing ``` pip install git+https://github.com/jamesross2/random_graph ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import glob\n",
    "import scipy.cluster.vq as clusters\n",
    "import scipy.sparse as sparse\n",
    "import warnings\n",
    "import random_graph\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from scipy.ndimage import binary_dilation\n",
    "from scipy.special import binom as nchoosek\n",
    "from pandas.plotting import autocorrelation_plot as AC_plot \n",
    "from statsmodels.graphics import tsaplots\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from skimage.filters import gaussian\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable, axes_size\n",
    "from skimage.transform.pyramids import pyramid_expand as expand\n",
    "from skimage.transform.pyramids import pyramid_reduce as reduce\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.colors import ListedColormap\n",
    "from itertools import combinations\n",
    "\n",
    "import Ressources.TransformHelper as TransformHelper\n",
    "import pickle\n",
    "from matplotlib.axes._axes import _log as matplotlib_axes_logger\n",
    "matplotlib_axes_logger.setLevel('ERROR')\n",
    "\n",
    "\n",
    "def save_to_disk(data, filepath):\n",
    "    with open(filepath, 'wb') as file:\n",
    "        pickle.dump(data, file)\n",
    "def load_from_disk(filepath):\n",
    "    with open(filepath, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "        return data\n",
    "    \n",
    "def bins_labels(bins, **kwargs):\n",
    "    bin_w = (max(bins) - min(bins)) / (len(bins) - 1)\n",
    "    plt.xticks(np.arange(min(bins)+bin_w/2, max(bins), bin_w), bins, **kwargs)\n",
    "    plt.xlim(bins[0], bins[-1])\n",
    "    \n",
    "\n",
    "\n",
    "# Git Paths\n",
    "OG_DATA_PATH = './'\n",
    "GIT_DATA_PATH = './Data Exploration/'\n",
    "GIT_PROCESSED_DATA_PATH = './Results/'\n",
    "GIT_GRAPH_PATH = './Results/Graphs/'\n",
    "RESSOURCES_PATH = './Ressources/'\n",
    "    \n",
    "\n",
    "# Getting the Folder without hidden files in ascending order \n",
    "GIT_PROCESSED_DATA_FOLDER = sorted([f for f in os.listdir(GIT_PROCESSED_DATA_PATH) if not f.startswith('.')], key=str.lower)\n",
    "GIT_GRAPH_FOLDER = sorted([f for f in os.listdir(GIT_GRAPH_PATH) if not f.startswith('.')], key=str.lower)\n",
    "\n",
    "#houselist \n",
    "house_file = RESSOURCES_PATH + 'building_collider_list.csv'\n",
    "try:\n",
    "    houselist = pd.read_csv(house_file)\n",
    "except:\n",
    "    print('HouseList could not be loaded!')\n",
    "    \n",
    "    \n",
    "# External data for mapping \n",
    "transform_infos = load_from_disk(\"./Ressources/map_image_transform_infos.pickle\")\n",
    "transform_matrix = transform_infos[\"perspective_transform_matrix\"]\n",
    "\n",
    "# load the city map image\n",
    "white_bg_img = cv2.imread(\"./ressources/map_white.png\")\n",
    "\n",
    "\n",
    "# Global variables\n",
    "fontsize = 20\n",
    "fontweight = 'bold'\n",
    "labelfontsize = 30\n",
    "figurelabels = ['A','B','C','D']\n",
    "\n",
    "\n",
    "green = [0.40,0.80,0.42]\n",
    "blue = [0.27,0.38,0.99]\n",
    "yellow = [0.96,0.73,0.23]\n",
    "darkblue = [0.18, 0.19, 0.69]\n",
    "lightyellow = [0.9763, 0.9831, 0.0538] \n",
    "grey = [0.75,0.75,0.75]\n",
    "white = [1,1,1]\n",
    "black = [0,0,0]\n",
    "\n",
    "# implement parula color map scheme from matlab \n",
    "cm_data = [[0.2081, 0.1663, 0.5292], [0.2116238095, 0.1897809524, 0.5776761905], \n",
    " [0.212252381, 0.2137714286, 0.6269714286], [0.2081, 0.2386, 0.6770857143], \n",
    " [0.1959047619, 0.2644571429, 0.7279], [0.1707285714, 0.2919380952, \n",
    "  0.779247619], [0.1252714286, 0.3242428571, 0.8302714286], \n",
    " [0.0591333333, 0.3598333333, 0.8683333333], [0.0116952381, 0.3875095238, \n",
    "  0.8819571429], [0.0059571429, 0.4086142857, 0.8828428571], \n",
    " [0.0165142857, 0.4266, 0.8786333333], [0.032852381, 0.4430428571, \n",
    "  0.8719571429], [0.0498142857, 0.4585714286, 0.8640571429], \n",
    " [0.0629333333, 0.4736904762, 0.8554380952], [0.0722666667, 0.4886666667, \n",
    "  0.8467], [0.0779428571, 0.5039857143, 0.8383714286], \n",
    " [0.079347619, 0.5200238095, 0.8311809524], [0.0749428571, 0.5375428571, \n",
    "  0.8262714286], [0.0640571429, 0.5569857143, 0.8239571429], \n",
    " [0.0487714286, 0.5772238095, 0.8228285714], [0.0343428571, 0.5965809524, \n",
    "  0.819852381], [0.0265, 0.6137, 0.8135], [0.0238904762, 0.6286619048, \n",
    "  0.8037619048], [0.0230904762, 0.6417857143, 0.7912666667], \n",
    " [0.0227714286, 0.6534857143, 0.7767571429], [0.0266619048, 0.6641952381, \n",
    "  0.7607190476], [0.0383714286, 0.6742714286, 0.743552381], \n",
    " [0.0589714286, 0.6837571429, 0.7253857143], \n",
    " [0.0843, 0.6928333333, 0.7061666667], [0.1132952381, 0.7015, 0.6858571429], \n",
    " [0.1452714286, 0.7097571429, 0.6646285714], [0.1801333333, 0.7176571429, \n",
    "  0.6424333333], [0.2178285714, 0.7250428571, 0.6192619048], \n",
    " [0.2586428571, 0.7317142857, 0.5954285714], [0.3021714286, 0.7376047619, \n",
    "  0.5711857143], [0.3481666667, 0.7424333333, 0.5472666667], \n",
    " [0.3952571429, 0.7459, 0.5244428571], [0.4420095238, 0.7480809524, \n",
    "  0.5033142857], [0.4871238095, 0.7490619048, 0.4839761905], \n",
    " [0.5300285714, 0.7491142857, 0.4661142857], [0.5708571429, 0.7485190476, \n",
    "  0.4493904762], [0.609852381, 0.7473142857, 0.4336857143], \n",
    " [0.6473, 0.7456, 0.4188], [0.6834190476, 0.7434761905, 0.4044333333], \n",
    " [0.7184095238, 0.7411333333, 0.3904761905], \n",
    " [0.7524857143, 0.7384, 0.3768142857], [0.7858428571, 0.7355666667, \n",
    "  0.3632714286], [0.8185047619, 0.7327333333, 0.3497904762], \n",
    " [0.8506571429, 0.7299, 0.3360285714], [0.8824333333, 0.7274333333, 0.3217], \n",
    " [0.9139333333, 0.7257857143, 0.3062761905], [0.9449571429, 0.7261142857, \n",
    "  0.2886428571], [0.9738952381, 0.7313952381, 0.266647619], \n",
    " [0.9937714286, 0.7454571429, 0.240347619], [0.9990428571, 0.7653142857, \n",
    "  0.2164142857], [0.9955333333, 0.7860571429, 0.196652381], \n",
    " [0.988, 0.8066, 0.1793666667], [0.9788571429, 0.8271428571, 0.1633142857], \n",
    " [0.9697, 0.8481380952, 0.147452381], [0.9625857143, 0.8705142857, 0.1309], \n",
    " [0.9588714286, 0.8949, 0.1132428571], [0.9598238095, 0.9218333333, \n",
    "  0.0948380952], [0.9661, 0.9514428571, 0.0755333333], \n",
    " [0.9763, 0.9831, 0.0538]]\n",
    "\n",
    "parula_map = LinearSegmentedColormap.from_list('parula', cm_data)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting all subject IDs from the data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subIDs = []\n",
    "for sub in GIT_PROCESSED_DATA_FOLDER:\n",
    "    if sub[0].isdigit():\n",
    "        subIDs.append(int(sub[0:4]))\n",
    "    else:\n",
    "        pass\n",
    "subIDs = np.unique(subIDs)\n",
    "print(subIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom subID\n",
    "subIDs = [1074]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the edgelists and creating the graphs \n",
    "* Also including the analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --------- Preparation ---------\n",
    "Plotting_bool = True # if you want to plot the graph\n",
    "save_bool = True # if you want to save the respective figure\n",
    "plot_edges_bool = False # if you want to plot the graph's edges\n",
    "save_centrality = False # if you want to save the centrality dataframe (node degree) as csv \n",
    "\n",
    "calculate_Partitioning = True # if you want to calculate the graph partitioning\n",
    "calculate_Hierarchy = False  # if you want to calculate the hierarchy index \n",
    "calculate_RC = False # if you want to calculate the rich club coefficient\n",
    "calculate_triang = False  # if you want to calculate the triangulation\n",
    "calculate_flow = False # if you want to calculate the max flow\n",
    "\n",
    "subcount = 0 # count subjects\n",
    "\n",
    "\n",
    "            \n",
    "# use if statements to avoid overwrite\n",
    "if calculate_Partitioning:\n",
    "    PartitioningDoc = pd.DataFrame()\n",
    "if calculate_Hierarchy:\n",
    "    HierarchyIndexDoc = pd.DataFrame()\n",
    "if calculate_RC:\n",
    "    RichClubDoc = pd.DataFrame()\n",
    "if calculate_triang:\n",
    "    gazes = pd.DataFrame(columns=['ColliderName', 'Samples', 'timeDiff', 'Index', 'HMD_x', 'HMD_y','HMD_z'])\n",
    "    noise = pd.DataFrame(columns=['ColliderName', 'Samples', 'timeDiff', 'Index', 'HMD_x', 'HMD_y','HMD_z'])\n",
    "if calculate_flow:\n",
    "    # ---- PREPARATION ----\n",
    "    # getting the graph of sub 1074 because it has every node\n",
    "    # afterwards creating a df with all possible node combinations\n",
    "\n",
    "    subject_folder_all = sorted([f for f in GIT_GRAPH_FOLDER \n",
    "                     if f.startswith('1074_edgelist')], key=str.lower)\n",
    "    # open the JSON file as dictionary\n",
    "    with open(GIT_GRAPH_PATH + subject_folder_all[0]) as f:\n",
    "        try:\n",
    "            edge_list = pd.read_csv(f)\n",
    "        except:\n",
    "                print(\"\\tCould not load subject \" + str(subject) + \" edgelist!\")\n",
    "\n",
    "\n",
    "    # create graph from edgelist\n",
    "    G_all = nx.Graph()\n",
    "    G_all = nx.from_pandas_edgelist(edge_list, 'Edge1', 'Edge2')\n",
    "\n",
    "    # Remove the NoHit Node\n",
    "    G_all.remove_node('NoHouse')\n",
    "\n",
    "    # Remove the NoHit Node\n",
    "    G_all.remove_node('NoHit')\n",
    "    # Setting the node coordinates of each node of the graph\n",
    "\n",
    "    # node list\n",
    "    nodelist_all = list(G_all.nodes)\n",
    "\n",
    "    all_combs = combinations(nodelist_all, 2)\n",
    "\n",
    "    Flow_df = pd.DataFrame(all_combs, columns=['Start', 'Target'])\n",
    "\n",
    "\n",
    "\n",
    "# --------- MAIN PART ---------\n",
    "# load the files \n",
    "for subject in subIDs:\n",
    "    subcount +=1\n",
    "    print('Subject ' + str(subject) + ' started - ' + str(subcount) + '/' + str(len(subIDs)))\n",
    "    \n",
    "    # get the data files according to the subject\n",
    "    subject_folder = sorted([f for f in GIT_GRAPH_FOLDER \n",
    "                             if f.startswith(str(subject)+'_edgelist')], key=str.lower)\n",
    "\n",
    "    if len(subject_folder) != 0:\n",
    "        \n",
    "        # open the JSON file as dictionary\n",
    "        with open(GIT_GRAPH_PATH + subject_folder[0]) as f:\n",
    "            try:\n",
    "                edge_list = pd.read_csv(f)\n",
    "            except:\n",
    "                    print(\"\\tCould not load subject \" + str(subject) + \" edgelist!\")\n",
    "\n",
    "    else:\n",
    "        print('Subject ' + str(subject) + ' has no data file!')\n",
    "        continue \n",
    "\n",
    "\n",
    "\n",
    "    # --------- GRAPH CREATION ---------\n",
    "\n",
    "    # create graph from edgelist\n",
    "    G = nx.Graph()\n",
    "    G = nx.from_pandas_edgelist(edge_list, 'Edge1', 'Edge2')\n",
    "\n",
    "    # Remove the NoHit Node\n",
    "    G.remove_node('NoHouse')\n",
    "    \n",
    "    # Remove the NoHit Node\n",
    "    G.remove_node('NoHit')\n",
    "    # Setting the node coordinates of each node of the graph\n",
    "\n",
    "\n",
    "    # node list\n",
    "    nodelist = list(G.nodes)\n",
    "    nodearray = np.array(G.nodes)\n",
    "    \n",
    "    \n",
    "    # coord dict\n",
    "    node_pos = {}\n",
    "\n",
    "    for node in nodelist:\n",
    "        # assign node coordinates\n",
    "        x = houselist['transformed_collidercenter_x'][houselist.target_collider_name==node].values[0]\n",
    "        y = houselist['transformed_collidercenter_y'][houselist.target_collider_name==node].values[0]\n",
    "        node_pos[node] = (x,y) \n",
    "\n",
    "    # set the graph's node coordinates attribute\n",
    "    nx.set_node_attributes(G, node_pos, 'coord')\n",
    "    \n",
    "    # Set flow capacity of every edge to 1\n",
    "    nx.set_edge_attributes(G, 1.0, 'capactiy')\n",
    "    \n",
    "    # degree dict and list of the graph\n",
    "    degree_dict = dict(G.degree)\n",
    "    degree_list = list(degree_dict.values())\n",
    "\n",
    "    # --------- ANALYSIS ---------\n",
    "\n",
    "    # --------- PARTITIONING ---------\n",
    "    if calculate_Partitioning == True: \n",
    "        \n",
    "        # PREPARATION: \n",
    "        \n",
    "        part_G = G\n",
    "        unconnected_components_amount = 0\n",
    "        not_connected_amount = 0\n",
    "        \n",
    "        # Removing all not connected nodes from the graph\n",
    "        # The amount needs to be saved in the Partitioning doc\n",
    "        not_connected_bool = [value == 0 for value in degree_dict.values()]\n",
    "        not_connected_nodes = nodearray[not_connected_bool]\n",
    "        not_connected_amount = len(not_connected_nodes)\n",
    "        \n",
    "        # remove not connected nodes and components\n",
    "        for node in not_connected_nodes: part_G.remove_node(node)\n",
    "            \n",
    "            \n",
    "        if len(dict(enumerate(nx.connected_components(part_G))).keys()) == 2:\n",
    "            # Also removing the unconnected components, i.e. subgraphs and saving their size\n",
    "            unconnected_components = dict(enumerate(nx.connected_components(part_G)))[1]\n",
    "            unconnected_components_amount = len(unconnected_components)\n",
    "            for component in unconnected_components: part_G.remove_node(component)\n",
    "        elif len(dict(enumerate(nx.connected_components(part_G))).keys()) > 2:\n",
    "            print('More than two subgraph components, continued!')\n",
    "            continue\n",
    "        \n",
    "\n",
    "        node_array_partitioning = np.array(part_G.nodes)\n",
    "        \n",
    "        # START Partitioning algorithm\n",
    "        # ---- Step 1 ----\n",
    "        \n",
    "        # get laplacian matrix and its eigenvalues + eigenvectors\n",
    "        laplacian_matrix = nx.laplacian_matrix(part_G)\n",
    "        laplacian_matrix = sparse.csr_matrix.toarray(laplacian_matrix)\n",
    "        # Eigenvalues and vectors\n",
    "        Eigenvalue, Eigenvector = np.linalg.eig(laplacian_matrix)\n",
    "        # sort Eigenvalues in ascending order and use index to sort eigenvectors\n",
    "        index_array = np.argsort(Eigenvalue)\n",
    "    \n",
    "        # check if smallest eigenvalue is 0 (or close to 0)\n",
    "        if Eigenvalue[index_array][0] < 1e-10:\n",
    "            #print('smallest Eigenvalue is 0')\n",
    "            # check if second smallest eigenvalue is larger 0 (this means the graph is fully connected)\n",
    "            if Eigenvalue[index_array][1] > 1e-10:\n",
    "                #print('Graph is fully connected')\n",
    "                \n",
    "                # create a dataframe and assign both the eigenvector sorted\n",
    "                house_eig_df = pd.DataFrame()\n",
    "                house_eig_df['House'] = node_array_partitioning\n",
    "                house_eig_df['Eigenvector'] = Eigenvector[:,index_array[1]]\n",
    "                \n",
    "                sorted_house_arrangement = house_eig_df.sort_values(by='Eigenvector', ascending=True).House.values\n",
    "                \n",
    "                \n",
    "                eig_pos = house_eig_df[house_eig_df.Eigenvector >= 0]\n",
    "                eig_neg = house_eig_df[house_eig_df.Eigenvector < 0]\n",
    "                \n",
    "                \n",
    "                # make sure to have Cluster continuity with top down though that\n",
    "                # the clusters are always devided into left and right part of the city \n",
    "                # Castle-TaskBuilding_56 is at the left side of the city and used as an anchor here\n",
    "                # Therefore this condition only holds for this specific data and is for visualization purposes\n",
    "                if 'Castle-TaskBuilding_56' in eig_pos.House.values:\n",
    "                    # create the subgraphs\n",
    "                    posG = part_G.subgraph(eig_pos.House)\n",
    "                    negG = part_G.subgraph(eig_neg.House)\n",
    "                else:\n",
    "                    # create the subgraphs\n",
    "                    negG = part_G.subgraph(eig_pos.House)\n",
    "                    posG = part_G.subgraph(eig_neg.House)\n",
    "                    \n",
    "                \n",
    "                # Calculate number of edges and how many were cut\n",
    "                totalEdges = part_G.number_of_edges()\n",
    "                    \n",
    "        \n",
    "                C1_Edges = posG.number_of_edges() \n",
    "                C2_Edges = negG.number_of_edges()\n",
    "                combinedEdges = C1_Edges + C2_Edges\n",
    "                Cut_Edges = totalEdges - combinedEdges\n",
    "                # Calculate number of nodes\n",
    "                total_nodes = part_G.number_of_nodes()\n",
    "                C1_nodes = posG.number_of_nodes()\n",
    "                C2_nodes = negG.number_of_nodes()\n",
    "                # Calculate the density\n",
    "                total_density = totalEdges/nchoosek(total_nodes,2)\n",
    "                C1_density = C1_Edges/nchoosek(C1_nodes,2)\n",
    "                C2_density = C2_Edges/nchoosek(C2_nodes,2)\n",
    "                \n",
    "                \n",
    "                # Adding the values to the partitioning documentation dataframe\n",
    "                partitioning_sub_df = pd.DataFrame()\n",
    "                partitioning_sub_df.loc[0, 'Subject'] = subject\n",
    "                partitioning_sub_df.loc[0, 'Unconnected Nodes'] = not_connected_amount\n",
    "                partitioning_sub_df.loc[0, 'Unconnected Component Nodes'] = unconnected_components_amount\n",
    "                partitioning_sub_df.loc[0, 'Eigenvalue'] = Eigenvalue[index_array][1]\n",
    "                partitioning_sub_df.loc[0, 'Complete Edges'] = totalEdges\n",
    "                partitioning_sub_df.loc[0, 'L Edges'] = C1_Edges\n",
    "                partitioning_sub_df.loc[0, 'R Edges'] = C2_Edges\n",
    "                partitioning_sub_df.loc[0, 'Cut Edges'] = Cut_Edges\n",
    "                partitioning_sub_df.loc[0, 'Total Nodes'] = total_nodes\n",
    "                partitioning_sub_df.loc[0, 'L Nodes'] = C1_nodes\n",
    "                partitioning_sub_df.loc[0, 'R Nodes'] = C2_nodes\n",
    "                partitioning_sub_df.loc[0, 'Complete Degree'] = (totalEdges*2)/total_nodes\n",
    "                partitioning_sub_df.loc[0, 'L Degree'] = C1_Edges/C1_nodes*2\n",
    "                partitioning_sub_df.loc[0, 'R Degree'] = C2_Edges/C2_nodes*2\n",
    "                partitioning_sub_df.loc[0, 'Complete Density'] = total_density\n",
    "                partitioning_sub_df.loc[0, 'L Density'] = C1_density\n",
    "                partitioning_sub_df.loc[0, 'R Density'] = C2_density               \n",
    "\n",
    "                \n",
    "                PartitioningDoc = PartitioningDoc.append(partitioning_sub_df)\n",
    "                \n",
    "                \n",
    "                plot_eig = house_eig_df.sort_values(by='Eigenvector').reset_index()\n",
    "                plot_eig_neg = plot_eig.Eigenvector[plot_eig.Eigenvector<0]\n",
    "                plot_eig_pos = plot_eig.Eigenvector[plot_eig.Eigenvector>=0]\n",
    "                \n",
    "                # ------- PLOTTING ---------\n",
    "                \n",
    "                if Plotting_bool == True:\n",
    "                    \n",
    "                    # ----- Preparation \n",
    "\n",
    "                    figgy = plt.figure(figsize=(15,10), constrained_layout=False)\n",
    "\n",
    "                    cMap = ListedColormap([white, blue, green])\n",
    "\n",
    "                    # create grid for different subplots                    \n",
    "                    gs = gridspec.GridSpec(ncols=2, nrows=2, \n",
    "                                              width_ratios=[1, 2.5],\n",
    "                                              height_ratios=[1, 1],\n",
    "                                              wspace=0.1,\n",
    "                                              hspace=0.3)\n",
    "\n",
    "\n",
    "                    # ----- plotting the spy matrix \n",
    "                    ax1 = figgy.add_subplot(gs[0])\n",
    "                    \n",
    "                    # Cut index\n",
    "                    cut_index = len(plot_eig.Eigenvector[plot_eig.Eigenvector<0])\n",
    "\n",
    "                    # sort the adjacency matrix according to the eigenvector\n",
    "                \n",
    "                    adj = sparse.csr_matrix.toarray(nx.adjacency_matrix(G, nodelist=sorted_house_arrangement))\n",
    "                         \n",
    "                    dilated_adj = binary_dilation(adj, np.ones((2, 2)), iterations=1).astype(adj.dtype)\n",
    "\n",
    "                    adj_colors = np.empty((dilated_adj.shape[0], dilated_adj.shape[1], 3))\n",
    "\n",
    "                    for row in range(dilated_adj.shape[0]):\n",
    "                        for col in range(dilated_adj.shape[1]):\n",
    "\n",
    "                            if dilated_adj[row,col] == 0:\n",
    "                                adj_colors[row,col,:] = white\n",
    "                            elif dilated_adj[row,col] == 1:\n",
    "                                if row <= cut_index and col <=cut_index:\n",
    "                                    adj_colors[row,col,:] = green\n",
    "                                elif row > cut_index and col > cut_index:\n",
    "                                    adj_colors[row,col,:] = blue\n",
    "                                elif ((row > cut_index) and not (col > cut_index)) or (not (row > cut_index) and (col > cut_index)):\n",
    "                                    adj_colors[row,col,:] = black\n",
    "                    \n",
    "                    \n",
    "\n",
    "                    plt.imshow(adj_colors)\n",
    "                    \n",
    "                    plt.xlim(0, len(G.nodes))\n",
    "                    plt.ylim(len(G.nodes), 0)\n",
    "\n",
    "\n",
    "                    # settings\n",
    "                    plt.xlabel('Matrix Entry', fontsize=fontsize, weight='bold')\n",
    "                    plt.ylabel('Matrix Entry', fontsize=fontsize, weight='bold')\n",
    "                    plt.rc('xtick', labelsize=fontsize-5) \n",
    "                    plt.rc('ytick', labelsize=fontsize-5)\n",
    "                    plt.xticks([0,100,200])\n",
    "                    plt.yticks([0,100,200])\n",
    "\n",
    "                    plt.plot([len(G.nodes),-0],[cut_index,cut_index], color=yellow, linewidth=4)\n",
    "                    plt.plot([cut_index,cut_index],[0,len(G.nodes)], color=yellow, linewidth=4)\n",
    "\n",
    "\n",
    "                    # ----- Plotting the graph on the map \n",
    "                    ax2 = figgy.add_subplot(gs[0:, -1])\n",
    "                    ax2.set_adjustable('box', share=False)\n",
    "                    ax2.set_frame_on(False)\n",
    "\n",
    "                    # plot the map\n",
    "                    plt.xlim(0, 4096)\n",
    "                    plt.ylim(0, 4096)\n",
    "\n",
    "                    plt.axis('off')\n",
    "                    plt.imshow(white_bg_img,aspect=ax2.get_aspect(),\n",
    "                             extent= ax2.get_xlim() + ax2.get_ylim(),\n",
    "                             zorder=1, alpha=0.8)\n",
    "\n",
    "                    # Draw the graph \n",
    "                    vmin = np.min(degree_list)\n",
    "                    vmax = np.max(degree_list)\n",
    "\n",
    "                    # plotting the clusters\n",
    "                    # positive cluster\n",
    "                    nx.draw_networkx_nodes(posG, node_color = blue, pos=node_pos, node_size=100)\n",
    "                    # negative cluster\n",
    "                    nx.draw_networkx_nodes(negG, node_color = green, pos=node_pos, node_size=100)\n",
    "\n",
    "\n",
    "                    if plot_edges_bool == True:\n",
    "                        nx.draw_networkx_edges(G, \n",
    "                                               node_pos, \n",
    "                                               edge_color='k', \n",
    "                                               alpha=0.5, \n",
    "                                               width=1,\n",
    "                                               style='dashed')\n",
    "\n",
    "\n",
    "\n",
    "                    ax2.set_xlim(0,3800)\n",
    "                    ax2.set_ylim(300,3700)  \n",
    "\n",
    "\n",
    "                    # ----- Plotting the eigenvector \n",
    "                    ax3 = figgy.add_subplot(gs[2], sharex=ax1)\n",
    "                    ax3.set_adjustable('box')\n",
    "\n",
    "                    plt.plot(plot_eig_neg, linewidth = 5, color =green)\n",
    "                    plt.plot(plot_eig_pos, linewidth = 5, color =blue)\n",
    "\n",
    "                    # settings\n",
    "                    plt.xlabel('Eigenvector Entry', fontsize=fontsize, weight='bold')\n",
    "                    plt.ylabel('Eigenvector Value', fontsize=fontsize, weight='bold')\n",
    "                    plt.yticks([-0.2,-0.1,0,0.1,0.2])\n",
    "                    \n",
    "                    plt.setp(ax1.get_xticklabels(), Fontsize=fontsize+5)\n",
    "                    plt.setp(ax1.get_yticklabels(), Fontsize=fontsize+5)\n",
    "\n",
    "                    plt.setp(ax3.get_xticklabels(), Fontsize=fontsize+5)\n",
    "                    plt.setp(ax3.get_yticklabels(), Fontsize=fontsize+5)\n",
    "\n",
    "                    # figure labels\n",
    "                    ax1.text(-100,-15,figurelabels[0],fontdict={'fontweight':fontweight,'fontsize':labelfontsize})\n",
    "                    ax2.text(-220,3760,figurelabels[1],fontdict={'fontweight':fontweight,'fontsize':labelfontsize})\n",
    "                    ax3.text(-100,0.235,figurelabels[2],fontdict={'fontweight':fontweight,'fontsize':labelfontsize})\n",
    "                        \n",
    "                    \n",
    "                    # save the graph as png \n",
    "                    if save_bool == True:\n",
    "                        # saving the subject info dataframe\n",
    "                        try:\n",
    "                            plt.savefig(GIT_GRAPH_PATH + str(subject) + \"_Cluster_Figure.png\",\n",
    "                                        dpi=100,\n",
    "                                        format=\"PNG\",\n",
    "                                        facecolor='white',\n",
    "                                        transparent=False, \n",
    "                                        bbox_inches = \"tight\")\n",
    "\n",
    "                            print(\"\\tCluster Figure PNG saved\")\n",
    "                        except:\n",
    "                            print(\"\\tCould not save subject \" + str(subject) + \" Cluster Figure as PNG!\")\n",
    "\n",
    "\n",
    "                    plt.close()\n",
    "          \n",
    "            else:\n",
    "                print('Graph is not fully connected')\n",
    "\n",
    "                \n",
    "                \n",
    "    # --------- HIERARCHY INDEX ---------\n",
    "    if calculate_Hierarchy == True: \n",
    "        # get the median degree as a reference\n",
    "        median_degree = np.median(degree_list)\n",
    "\n",
    "        # get a list of unique degree values\n",
    "        UniqueDegree = np.unique(degree_list)\n",
    "        UniqueDegreeMed = UniqueDegree[UniqueDegree >= median_degree]\n",
    "\n",
    "        # get the frequency of each degree value\n",
    "        DegreeFrequency = dict()\n",
    "\n",
    "        for degree in UniqueDegree:\n",
    "            DegreeFrequency[degree] = np.sum(degree_list==degree)\n",
    "\n",
    "        DegreeFrequencyMed = np.array(list(DegreeFrequency.values()))[UniqueDegree >= median_degree]\n",
    "\n",
    "        # do a linear fit of the log data of Unique Degree over Frequency\n",
    "        linear_model=np.polyfit(np.log(UniqueDegreeMed),np.log(DegreeFrequencyMed),1)\n",
    "        linear_model_fn=np.poly1d(linear_model)\n",
    "\n",
    "        # save the hierarchy index (the slope of the fit)\n",
    "        hierarchy_sub_df = pd.DataFrame()\n",
    "        hierarchy_sub_df.loc[0, 'Subject'] = subject\n",
    "        hierarchy_sub_df.loc[0, 'HierarchyIndex'] = -linear_model[0]\n",
    "\n",
    "        HierarchyIndexDoc = HierarchyIndexDoc.append(hierarchy_sub_df)\n",
    "\n",
    "        \n",
    "        # ------- PLOTTING ---------\n",
    "                \n",
    "        if Plotting_bool == True:\n",
    "\n",
    "            plt.figure(figsize=(15,10))\n",
    "            plt.scatter(np.log(UniqueDegree),np.log(list(DegreeFrequency.values())), )\n",
    "\n",
    "            x_s=np.arange(np.log(median_degree) ,max(np.log(UniqueDegree)+0.5))\n",
    "            plt.plot(x_s, linear_model_fn(x_s),color=green, linewidth=4)\n",
    "\n",
    "            # settings\n",
    "            plt.title('Hierarchy Index - Subject ' + str(subject), fontsize=fontsize)\n",
    "            plt.xlabel('Degree', fontsize=fontsize)\n",
    "            plt.ylabel('Frequency', fontsize=fontsize)\n",
    "            plt.xticks(fontsize=fontsize)\n",
    "            plt.yticks(fontsize=fontsize)\n",
    "\n",
    "            if save_bool == True:\n",
    "                    # saving the figure\n",
    "                    try:\n",
    "                        plt.savefig(GIT_GRAPH_PATH + str(subject) + \"_HierarchyIndex.png\",\n",
    "                                    dpi=200,\n",
    "                                    format=\"PNG\",\n",
    "                                    facecolor='white',\n",
    "                                    transparent=False, \n",
    "                                    bbox_inches = \"tight\")\n",
    "                    except:\n",
    "                        print(\"\\tCould not save subject \" + str(subject) + \" HierarchyIndex as PNG!\")\n",
    "\n",
    "\n",
    "    \n",
    "    # --------- RICH CLUB COEFFICIENT ---------\n",
    "    if calculate_RC == True:\n",
    "        \n",
    "        RichClub_sub = pd.DataFrame()    \n",
    "            \n",
    "        # calculate the rich club for the subject graph\n",
    "        RC = nx.rich_club_coefficient(G, normalized=False, seed=1)\n",
    "\n",
    "        # create a random graph for the rich club weighting with the same degree distribution\n",
    "        edges = random_graph.sample_simple_graph(degree_list)\n",
    "        randomG = nx.Graph()\n",
    "        randomG = nx.from_edgelist(edges)\n",
    "\n",
    "        # calculate the ric club for the random graph\n",
    "        RC_random = nx.rich_club_coefficient(randomG, normalized=False, seed=2)\n",
    "        \n",
    "        RichClub_sub[str(subject)] = np.array(list(RC.values()))/np.array(list(RC_random.values()))\n",
    "        #RichClub_sub = [i / j for i, j in zip(list(RC.values()), list(RC_random.values()))]\n",
    "        RichClub_sub.reset_index(drop=True,inplace=True)\n",
    "        #RichClubDoc = RichClubDoc.append(RichClub_sub)\n",
    "        \n",
    "        \n",
    "        if len(RichClubDoc) != 0 and (len(RichClubDoc) < len(RichClub_sub)):\n",
    "            RichClubDoc = RichClubDoc.reindex(range(max(len(RichClubDoc), len(RichClub_sub))))\n",
    "               \n",
    "        RichClubDoc[str(subject)] = RichClub_sub[str(subject)]\n",
    "        \n",
    "        \n",
    "        # -------- PLOTTING ---------\n",
    "        if Plotting_bool == True:\n",
    "            plt.figure(figsize=(10,7))\n",
    "            plt.plot(RichClub_sub[str(subject)],\n",
    "                     linewidth=3,\n",
    "                     color=green)\n",
    "\n",
    "            # settings\n",
    "            plt.title('Rich Club - Subject ' + str(subject), fontsize=fontsize)\n",
    "            plt.xlabel('Degree', fontsize=fontsize)\n",
    "            plt.ylabel('Rich Club (Real/Random)', fontsize=fontsize)\n",
    "            plt.xticks(fontsize=fontsize)\n",
    "            plt.yticks(fontsize=fontsize)\n",
    "            plt.ylim(0.8,2)\n",
    "    \n",
    "\n",
    "            # --------- SAVING ---------\n",
    "            if save_bool == True:\n",
    "                # saving the figure\n",
    "                try:\n",
    "                    plt.savefig(GIT_GRAPH_PATH + str(subject) + \"_RichClub.png\",\n",
    "                                format=\"PNG\",\n",
    "                                facecolor='white',\n",
    "                                transparent=False, \n",
    "                                bbox_inches = \"tight\")\n",
    "                except:\n",
    "                    print(\"\\tCould not save subject \" + str(subject) + \" RichCLub as PNG!\")\n",
    "    \n",
    "\n",
    "    # --------- TRIANGULATION ---------\n",
    "    if calculate_triang == True: \n",
    "        \n",
    "        # get the interpolation files according to the subject\n",
    "        interpolation_folder = sorted([f for f in GIT_PROCESSED_DATA_FOLDER \n",
    "                                 if f.startswith(str(subject)+'_interpolation')], key=str.lower)\n",
    "\n",
    "        if len(interpolation_folder) != 0:        \n",
    "            # open the JSON file as dictionary\n",
    "            with open(GIT_PROCESSED_DATA_PATH + interpolation_folder[0]) as f:\n",
    "                try:\n",
    "                    interpolation_data = pd.read_csv(f)\n",
    "                except:\n",
    "                    print(\"\\tCould not load subject \" + str(subject) + \" edgelist!\")\n",
    "\n",
    "        else:\n",
    "            print('Subject ' + str(subject) + ' has no interpolation file!')\n",
    "            continue \n",
    "\n",
    "        sub_gazes = pd.DataFrame(columns=gazes.columns)\n",
    "        sub_noise = pd.DataFrame(columns=gazes.columns)\n",
    "\n",
    "        sub_gazes = sub_gazes.append(interpolation_data[interpolation_data.timeDiff>0.2333])\n",
    "        \n",
    "        sub_noise = sub_noise.append(interpolation_data[interpolation_data.timeDiff<=0.2333])        \n",
    "\n",
    "\n",
    "\n",
    "        gazes = gazes.append(sub_gazes)\n",
    "        gazes.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        noise = noise.append(sub_noise)        \n",
    "        noise.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "    # ----- FLOW ANALYSIS -----\n",
    "    \n",
    "    if calculate_flow == True:\n",
    "\n",
    "        for flow_idx in range(len(Flow_df)):\n",
    "            \n",
    "            source = Flow_df.loc[flow_idx, 'Start']\n",
    "            sink = Flow_df.loc[flow_idx, 'Target']\n",
    "            \n",
    "            if (source in nodelist) & (sink in nodelist):\n",
    "            \n",
    "                flow_value = nx.maximum_flow_value(G, source, sink, capacity='capactiy')\n",
    "\n",
    "                Flow_df.loc[flow_idx, subject] = flow_value\n",
    "\n",
    "                print('\\tStatus: ' + str(int(flow_idx/len(Flow_df)*100)) + '%', end=\"\\r\")\n",
    "            else:\n",
    "                Flow_df.loc[flow_idx, subject] = np.nan\n",
    "        \n",
    "    print('Subject ' + str(subject) + ' done!')\n",
    "        \n",
    "    \n",
    "\n",
    "if save_bool == True: \n",
    "    # saving the subject info dataframe\n",
    "    try:\n",
    "        PartitioningDoc.to_csv(GIT_GRAPH_PATH\n",
    "                        + \"PartitioningDoc.csv\", \n",
    "                        index=False)\n",
    "        \n",
    "        print(\"Partitioning Dataframe saved\")\n",
    "        \n",
    "    except:\n",
    "        pass     \n",
    "    \n",
    "    try:\n",
    "\n",
    "        HierarchyIndexDoc.to_csv(GIT_GRAPH_PATH\n",
    "                        + \"HierarchyTable.csv\", \n",
    "                        index=False)\n",
    "        print(\"Hierarchy Dataframe saved\")\n",
    "    except:\n",
    "        pass   \n",
    "    \n",
    "    try:\n",
    "        RichClubDoc.to_csv(GIT_GRAPH_PATH\n",
    "                + \"RichClubDoc.csv\", \n",
    "                index=False)\n",
    "        print(\"Rich Club Dataframe saved\")\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    try:   \n",
    "        gazes.to_csv(GIT_GRAPH_PATH\n",
    "                                + \"all_gazes.csv\", \n",
    "                                index=False)\n",
    "\n",
    "        print(\"All gazes Dataframe saved\")\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "            \n",
    "    try:   \n",
    "        noise.to_csv(GIT_GRAPH_PATH\n",
    "                                + \"all_noise.csv\", \n",
    "                                index=False)\n",
    "\n",
    "        print(\"All noise Dataframe saved\")\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    \n",
    "    try:   \n",
    "        Flow_df.to_csv(GIT_GRAPH_PATH\n",
    "                                + \"Flow_df.csv\", \n",
    "                                index=False)\n",
    "\n",
    "        print(\"Flow_df Dataframe saved\")\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "print('Done')\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject Overviews\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Viewing Stats\n",
    "* requires to run triangulation from previous cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the JSON file as dictionary\n",
    "with open(GIT_PROCESSED_DATA_PATH + 'Subject_Data.csv') as f:\n",
    "    try:\n",
    "        subject_info = pd.read_csv(f)\n",
    "    except:\n",
    "            print(\"\\tCould not load subject info\")\n",
    "            \n",
    "subject_info['DataLoss BitMask'] = subject_info['DataLoss BitMask']*100\n",
    "subject_info['DataLoss NoHits'] = subject_info['DataLoss NoHits']*100\n",
    "subject_info['DataLoss Combined'] = subject_info['DataLoss Combined']*100\n",
    "subject_info['Removed rows (%)'] = subject_info['Removed rows (%)']*100\n",
    "            \n",
    "mean_stats = pd.DataFrame(columns=subject_info.columns)\n",
    "\n",
    "mean_stats.loc[0] = subject_info.mean().round(2)\n",
    "\n",
    "\n",
    "\n",
    "mean_stats.to_csv(GIT_GRAPH_PATH\n",
    "                + \"AverageSubViewingDoc.csv\", \n",
    "                index=False)\n",
    "\n",
    "print(\"AverageSubViewingDoc Dataframe saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "save_bool = False # True if you want to save the figure\n",
    "\n",
    "# load gazes and noise file\n",
    "gazes = pd.read_csv(GIT_GRAPH_PATH+ \"all_gazes.csv\")\n",
    "noise = pd.read_csv(GIT_GRAPH_PATH+ \"all_noise.csv\")\n",
    "\n",
    "\n",
    "all_views = np.concatenate((gazes.timeDiff.values, noise.timeDiff.values), axis=0)\n",
    "\n",
    "all_views[all_views>1.033] = 1.033\n",
    "\n",
    "all_views = all_views*1000\n",
    "\n",
    "# Data to plot\n",
    "labels = 'Gazes', 'Noise'\n",
    "sizes = [np.sum(gazes.timeDiff), np.sum(noise.timeDiff)]\n",
    "colors = [green, grey]\n",
    "explode = (0, 0, 0, 0)  # explode 1st slice\n",
    "\n",
    "\n",
    "\n",
    "figgy = plt.figure(figsize=(20,7))\n",
    "\n",
    "gs = gridspec.GridSpec(ncols=2, nrows=1, \n",
    "                       width_ratios=[1, 1],\n",
    "                       wspace=-0.15)\n",
    "\n",
    "ax1 = figgy.add_subplot(gs[0])\n",
    "plt.hist(all_views, 31, ec='k', color=blue)\n",
    "ax1.set_xlabel('Hitpoint Time (ms)', fontsize=fontsize+10, weight='bold')\n",
    "ax1.set_ylabel('Probability', fontsize=fontsize+10, weight='bold')\n",
    "ax1.set_xticks([33, 233, 433, 633, 833, 1033])\n",
    "ax1.set_yticks([180000, 360000, 540000])\n",
    "prob_ticks = [round(180000/len(all_views),2), round(360000/len(all_views),2), round(540000/len(all_views),2)]\n",
    "ax1.set_yticklabels(prob_ticks)\n",
    "\n",
    "plt.setp(ax1.get_xticklabels(), Fontsize=fontsize+5)\n",
    "plt.setp(ax1.get_yticklabels(), Fontsize=fontsize+5)\n",
    "\n",
    "plt.text(-150,585000,figurelabels[0],fontdict={'fontweight':fontweight,'fontsize':labelfontsize})\n",
    "\n",
    "\n",
    "\n",
    "ax2 = figgy.add_subplot(gs[1])\n",
    "plt.pie(sizes, labels=labels, colors=colors,\n",
    "autopct='%1.1f%%', shadow=False, startangle=120)\n",
    "plt.rcParams['font.size'] = labelfontsize-5\n",
    "\n",
    "\n",
    "ax2.text(-1.2,1.2,figurelabels[1],fontdict={'fontweight':fontweight,'fontsize':labelfontsize})\n",
    "\n",
    "# ---------- SAVING ---------\n",
    "\n",
    "if save_bool == True:\n",
    "    # saving the figure\n",
    "    try:\n",
    "        plt.savefig(GIT_GRAPH_PATH + \"Gaze_Stat_Figure.png\",\n",
    "                    dpi=200,\n",
    "                    format=\"PNG\",\n",
    "                    facecolor='white',\n",
    "                    transparent=False, \n",
    "                    bbox_inches = \"tight\")\n",
    "    except:\n",
    "        print(\"\\tCould not save Gaze Stat Figure as PNG!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitioning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the JSON file as dictionary\n",
    "with open(GIT_GRAPH_PATH + 'PartitioningDoc.csv') as f:\n",
    "    try:\n",
    "        PartitioningDoc = pd.read_csv(f)\n",
    "    except:\n",
    "            print(\"\\tCould not load PartitioningDoc\")\n",
    "            \n",
    "mean_part = pd.DataFrame(columns=PartitioningDoc.columns)\n",
    "\n",
    "mean_part.loc[0] = PartitioningDoc.mean().round(2)\n",
    "\n",
    "\n",
    "\n",
    "mean_part.to_csv(GIT_GRAPH_PATH\n",
    "                + \"AveragePartitioningDoc.csv\", \n",
    "                index=False)\n",
    "\n",
    "print(\"AveragePartitioningDoc Dataframe saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node Degree\n",
    "* Calculate the following figures:\n",
    "     1. Errorbar plot of all subjects\n",
    "     2. Imagescale plot of all subjects over houses with ascendingly ordered degree\n",
    "     3. Correlation of inter subject degree distributions \n",
    "     4. Errorbar plot of all houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bool = False # True if you want to save the figure\n",
    "\n",
    "# open the Node degree csv file as dictionary\n",
    "with open(GIT_GRAPH_PATH + 'centrality_df.csv') as f:\n",
    "    try:\n",
    "        centrality_df = pd.read_csv(f)\n",
    "    except:\n",
    "            print(\"\\tCould not load centrality_df!\")\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "# create a pure degree dataframe by removing mean and std values \n",
    "pure_degree = centrality_df.drop(['Mean', 'STD'], axis=1)\n",
    "pure_degree = pure_degree.drop(pure_degree[(pure_degree.Subject == 'Mean') | (pure_degree.Subject == 'STD')].index)\n",
    "\n",
    "# create lists for mean/std degree over subjects and houses \n",
    "mean_degree_subs = pure_degree.iloc[:, 1:].mean(axis=1).copy()\n",
    "std_degree_subs = pure_degree.iloc[:, 1:].std(axis=1).copy()\n",
    "mean_degree_houses = pure_degree.iloc[:, 1:].mean(axis=0).copy()\n",
    "std_degree_houses = pure_degree.iloc[:, 1:].std(axis=0).copy()\n",
    "\n",
    "# sort index \n",
    "sub_sort_index = np.argsort(mean_degree_subs)\n",
    "house_sort_index = np.argsort(mean_degree_houses)\n",
    "\n",
    "sorted_cent = pure_degree.iloc[:, 1:].copy()\n",
    "sorted_cent = sorted_cent.reindex(sorted_cent.mean(axis=1).sort_values(ascending=False).index,\n",
    "                                  axis=0)\n",
    "sorted_cent.reset_index(drop=True,inplace=True)\n",
    "sorted_cent = sorted_cent[pure_degree.columns[1:][house_sort_index]]\n",
    "sorted_cent.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# calculating the correlation coefficients\n",
    "correlation_matrix = pure_degree.iloc[:, 1:].T.corr().copy()\n",
    "# creating a mask to get the lower diagonal of the matrix\n",
    "correlation_matrix = correlation_matrix.mask(np.triu(np.ones(correlation_matrix.shape, dtype=np.bool_)))\n",
    "# squeeze non nans to list \n",
    "correlation_list = np.asarray(correlation_matrix).reshape(-1)\n",
    "correlation_list = correlation_list[~np.isnan(correlation_list)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------- PLOTTING ------------\n",
    "        \n",
    "\n",
    "\n",
    "# -------- NODE DEGREE INFO PLOT -----------\n",
    "\n",
    "\n",
    "\n",
    "# preparation\n",
    "\n",
    "subticks = list(np.array(range(0,26,5)) + 0.5)\n",
    "subticklabel = np.array(range(0,26,5))\n",
    "subticklabel = [\"%.d\" % x for x in subticklabel]\n",
    "\n",
    "houseticks = list(np.array(range(0,244,50)) + 0.5)\n",
    "houseticklabel = np.array(range(0,244,50))\n",
    "houseticklabel = [\"%.d\" % x for x in houseticklabel]\n",
    "\n",
    "\n",
    "figgy = plt.figure(figsize=(18,13))\n",
    "# create grid for different subplots\n",
    "gs = gridspec.GridSpec(ncols=2, nrows=2,\n",
    "                         width_ratios=[1, 1.7], wspace=0.25,\n",
    "                         hspace=0.25, height_ratios=[1, 1])\n",
    "\n",
    "# errorbar plot \n",
    "ax1 = figgy.add_subplot(gs[0])\n",
    "ax1.set_adjustable('box', share=True)\n",
    "# Customize minor tick labels\n",
    "ax1.set_yticklabels('')\n",
    "ax1.set_yticks(subticks,      minor=True)\n",
    "ax1.set_yticklabels(subticklabel, minor=True)\n",
    "\n",
    "plt.errorbar(mean_degree_subs[sub_sort_index],\n",
    "             np.arange(0.5, len(mean_degree_subs)+0.5),\n",
    "             xerr=std_degree_subs[sub_sort_index],\n",
    "             ecolor=grey,\n",
    "             mfc=blue,\n",
    "             linewidth = 3)\n",
    "\n",
    "plt.xlabel('Node Degree', fontsize=fontsize+5, weight=fontweight)\n",
    "plt.ylabel('Participant', fontsize=fontsize+5, weight=fontweight)\n",
    "plt.rc('xtick', labelsize=fontsize+5) \n",
    "plt.rc('ytick', labelsize=fontsize+5)\n",
    "plt.tick_params(top=False, bottom=False, left=False, right=False)\n",
    "plt.rc('xtick', labelsize=fontsize+5) \n",
    "plt.rc('ytick', labelsize=fontsize+5)\n",
    "\n",
    "\n",
    "\n",
    "# image scale plot\n",
    "ax2 = figgy.add_subplot(gs[1], sharey = ax1)\n",
    "\n",
    "plt.imshow(sorted_cent,\n",
    "           extent=[0, np.shape(pure_degree)[1], 0, np.shape(pure_degree)[0]],\n",
    "           cmap=parula_map)\n",
    "\n",
    "\n",
    "cbar = plt.colorbar(shrink=1, aspect=9)\n",
    "cbar.set_label('Node Degree', fontsize=fontsize+5, weight=fontweight)\n",
    "ax2.set_aspect('auto')\n",
    "ax2.set_adjustable('box', share=True)\n",
    "# Customize minor tick labels\n",
    "ax2.set_xticklabels('')\n",
    "ax2.set_xticks(houseticks,      minor=True)\n",
    "ax2.set_xticklabels(houseticklabel, minor=True)\n",
    "plt.tick_params(top=False, bottom=False, left=False, right=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# correlation histogram\n",
    "ax3 = figgy.add_subplot(gs[2])\n",
    "ax3.set_adjustable('box', share=True)\n",
    "\n",
    "plt.hist(correlation_list, ec='k', bins=7, color=blue)\n",
    "\n",
    "plt.xlabel('Correlation', fontsize=fontsize+5, weight=fontweight)\n",
    "plt.ylabel('Frequency', fontsize=fontsize+5, weight=fontweight)\n",
    "plt.rc('xtick', labelsize=fontsize+5) \n",
    "plt.rc('ytick', labelsize=fontsize+5)\n",
    "\n",
    "\n",
    "\n",
    "# -------------- Rectangle START --------------------\n",
    "\n",
    "# Mean and STD rectangle\n",
    "rect_loc = (plt.xlim()[0] + 0.02*plt.xlim()[1], plt.ylim()[1] - 0.24*plt.ylim()[1])\n",
    "mean_loc = (plt.xlim()[0] + 0.025*plt.xlim()[1], plt.ylim()[1] - 0.13*plt.ylim()[1])\n",
    "std_loc = (plt.xlim()[0] + 0.02*plt.xlim()[1], plt.ylim()[1] - 0.22*plt.ylim()[1])\n",
    "\n",
    "rect1 = plt.Rectangle(rect_loc,(0.17),(18), facecolor=white,edgecolor=\"black\",alpha=0.8)\n",
    "plt.gca().add_patch(rect1)\n",
    "\n",
    "mean_corr = round(np.mean(correlation_list),2)\n",
    "std_corr = round(np.std(correlation_list),2)\n",
    "# Mean Info\n",
    "plt.text(mean_loc[0]\n",
    "         ,mean_loc[1]\n",
    "         , \"Mean: \" + str(mean_corr)\n",
    "         ,fontsize = fontsize+2\n",
    "         ,zorder = 5\n",
    "         ,color = 'k'\n",
    "         ,fontweight = fontweight)\n",
    "# STD Info\n",
    "plt.text(std_loc[0]\n",
    "         ,std_loc[1]\n",
    "         , \" STD:   \" + str(std_corr)\n",
    "         ,fontsize = fontsize+2\n",
    "         ,zorder = 5\n",
    "         ,color = 'k'\n",
    "         ,fontweight = fontweight)\n",
    "\n",
    "\n",
    "\n",
    "# -------------- Rectangle END --------------------\n",
    "\n",
    "\n",
    "# errorbar plot for houses \n",
    "ax4 = figgy.add_subplot(gs[3], sharex = ax2)\n",
    "ax4.set_adjustable('box', share=True)\n",
    "ax4.set_aspect(5.25, anchor='SW')\n",
    "\n",
    "plt.errorbar(np.arange(0, len(mean_degree_houses)),\n",
    "             mean_degree_houses[house_sort_index],\n",
    "             yerr=std_degree_houses[house_sort_index],\n",
    "             ecolor=grey,\n",
    "             mfc=blue,\n",
    "             linewidth = 3)\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('House', fontsize=fontsize+5, weight=fontweight)\n",
    "plt.ylabel('Node Degree', fontsize=fontsize+5, weight=fontweight)\n",
    "plt.rc('xtick', labelsize=fontsize+5) \n",
    "plt.rc('ytick', labelsize=fontsize+5)\n",
    "\n",
    "\n",
    "# Figure Labels\n",
    "ax1.text(-3,25,figurelabels[0],fontdict={'fontweight':fontweight,'fontsize':labelfontsize})\n",
    "ax2.text(-40,25,figurelabels[1],fontdict={'fontweight':fontweight,'fontsize':labelfontsize})\n",
    "ax3.text(0.36,93,figurelabels[2],fontdict={'fontweight':fontweight,'fontsize':labelfontsize})\n",
    "ax4.text(-40,30,figurelabels[3],fontdict={'fontweight':fontweight,'fontsize':labelfontsize})\n",
    "\n",
    "\n",
    "# ---------- SAVING ---------\n",
    "\n",
    "if save_bool == True:\n",
    "    # saving the figure\n",
    "    try:\n",
    "        plt.savefig(GIT_GRAPH_PATH + \"NodeDegree_all.png\",\n",
    "                    dpi=200,\n",
    "                    format=\"PNG\",\n",
    "                    facecolor='white',\n",
    "                    transparent=False, \n",
    "                    bbox_inches = \"tight\")\n",
    "    except:\n",
    "        print(\"\\tCould not save NodeDegree Figure as PNG!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landmark Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_edges_bool = False\n",
    "save_bool = False\n",
    "\n",
    "\n",
    "# PREPARATION \n",
    "subIDs = [1074]\n",
    "\n",
    "# open the JSON file as dictionary\n",
    "with open(GIT_GRAPH_PATH + '1074_edgelist.csv') as f:\n",
    "    try:\n",
    "        edge_list = pd.read_csv(f)\n",
    "    except:\n",
    "            print(\"\\tCould not load subject \" + str(subject) + \" edgelist!\")\n",
    "\n",
    "\n",
    "# create graph from edgelist\n",
    "G = nx.Graph()\n",
    "G = nx.from_pandas_edgelist(edge_list, 'Edge1', 'Edge2')\n",
    "\n",
    "# Remove the NoHouse Node\n",
    "G.remove_node('NoHouse')\n",
    "# Remove the NoHit Node\n",
    "G.remove_node('NoHit')\n",
    "# Setting the node coordinates of each node of the graph\n",
    "\n",
    "\n",
    "# node list\n",
    "nodelist = list(G.nodes)\n",
    "nodearray = np.array(G.nodes)\n",
    "\n",
    "\n",
    "# coord dict\n",
    "node_pos = {}\n",
    "\n",
    "for node in nodelist:\n",
    "    # assign node coordinates\n",
    "    x = houselist['transformed_collidercenter_x'][houselist.target_collider_name==node].values[0]\n",
    "    y = houselist['transformed_collidercenter_y'][houselist.target_collider_name==node].values[0]\n",
    "    node_pos[node] = (x,y) \n",
    "\n",
    "# set the graph's node coordinates attribute\n",
    "nx.set_node_attributes(G, node_pos, 'coord')\n",
    "\n",
    "# degree list of the graph\n",
    "degree_list = list(dict(G.degree).values())\n",
    "    \n",
    "    \n",
    "\n",
    "fontsize = 15\n",
    "\n",
    "mean_degrees = centrality_df[centrality_df.Subject == 'Mean']\n",
    "mean_degrees = mean_degrees.drop(['Subject','Mean', 'STD'], axis=1)\n",
    "top10_houses = mean_degrees.sort_values(by=26, ascending=False, axis=1).columns[:10]\n",
    "\n",
    "\n",
    "\n",
    "top10_edgelist = edge_list.copy()\n",
    "top10_edgelist = \\\n",
    "    top10_edgelist[top10_edgelist['Edge1'].isin(top10_houses) | top10_edgelist['Edge2'].isin(top10_houses)]\n",
    "\n",
    "\n",
    "# create graph from edgelist\n",
    "top10_graph = nx.Graph()\n",
    "top10_graph = nx.from_pandas_edgelist(top10_edgelist, 'Edge1', 'Edge2')\n",
    "\n",
    "top10_graph.remove_node('NoHouse')\n",
    "top10_graph.remove_node('NoHit')\n",
    "\n",
    "top10_degree_list = list(dict(top10_graph.degree).values())\n",
    "\n",
    "# get the average degree over subjects and sort them according to the node order of the donor subject\n",
    "mean_dict = centrality_df[centrality_df['Subject'] == 'Mean'].to_dict('records')[0]\n",
    "mean_dict.pop('Mean')\n",
    "mean_dict.pop('STD')\n",
    "mean_dict.pop('Subject')\n",
    "\n",
    "sorted_mean_degrees_dict = dict()\n",
    "for node in nodelist:\n",
    "    sorted_mean_degrees_dict[node] = mean_dict[node]\n",
    "    \n",
    "sorted_mean_degrees = list(sorted_mean_degrees_dict.values())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# mean node degree distribution at first\n",
    "# mean node degree distribution at first\n",
    "mean_degree = round(centrality_df[centrality_df.Subject == 'Mean'].Mean.values[0], 2) \n",
    "std_degree =  round(centrality_df[centrality_df.Subject == 'Mean'].STD.values[0], 2)\n",
    "\n",
    "zero_sigma = centrality_df[centrality_df.Subject == 'Mean'].Mean.values[0]\n",
    "\n",
    "one_sigma = centrality_df[centrality_df.Subject == 'Mean'].Mean.values[0] \\\n",
    "                + centrality_df[centrality_df.Subject == 'Mean'].STD.values[0]\n",
    "\n",
    "two_sigma = centrality_df[centrality_df.Subject == 'Mean'].Mean.values[0] \\\n",
    "                + 2*centrality_df[centrality_df.Subject == 'Mean'].STD.values[0]\n",
    "\n",
    "\n",
    "top10_short = ['B154', 'B214', 'Silo49', 'TB35', 'B176', 'B97', 'B198', 'B166', 'B171', 'TB50']\n",
    "\n",
    "# -------- PLOTTING --------\n",
    "\n",
    "\n",
    "# -------- MEAN NODE DEGREE HISTOGRAM -----------\n",
    "\n",
    "\n",
    "\n",
    "figgy = plt.figure(figsize=(20,13))\n",
    "# create grid for different subplots\n",
    "gs = gridspec.GridSpec(ncols=2, nrows=2,\n",
    "                         width_ratios=[1, 1], wspace=0.25,\n",
    "                         hspace=0.23, height_ratios=[1, 1.5])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ax1 = figgy.add_subplot(gs[0])\n",
    "\n",
    "#plot\n",
    "hist_plotty = plt.hist(centrality_df.loc[len(centrality_df)-2][1:], ec='k', color=blue)\n",
    "\n",
    "\n",
    "# lines for sigma distance\n",
    "# 0 sigma\n",
    "plt.plot(np.ones(12)*zero_sigma,np.arange(0,12,1),linestyle='--', marker='o', color='k')\n",
    "zero_loc = (zero_sigma, 15)\n",
    "\n",
    "plt.text(zero_loc[0]\n",
    "         ,zero_loc[1]\n",
    "         , \"Mean: \" + str(round(zero_sigma, 2))\n",
    "         , ha=\"center\"\n",
    "         , va=\"center\"\n",
    "         ,fontsize = fontsize+1\n",
    "         ,zorder = 5\n",
    "         ,color = 'k'\n",
    "         ,fontweight = 'bold')\n",
    "\n",
    "# 1 sigma\n",
    "plt.plot(np.ones(17)*one_sigma,np.arange(0,17,1),linestyle='--', marker='o', color='k')\n",
    "one_loc = (one_sigma, 20)\n",
    "\n",
    "plt.text(one_loc[0]\n",
    "         ,one_loc[1]\n",
    "         , \"1$\\sigma$: \" + str(round(one_sigma, 2))\n",
    "         , ha=\"center\"\n",
    "         , va=\"center\"\n",
    "         ,fontsize = fontsize+1\n",
    "         ,zorder = 5\n",
    "         ,color = 'k'\n",
    "         ,fontweight = 'bold')\n",
    "# 2 sigma\n",
    "plt.plot(np.ones(12)*two_sigma,np.arange(0,12,1),linestyle='--', marker='o', color='k')\n",
    "two_loc = (two_sigma, 15)\n",
    "\n",
    "plt.text(two_loc[0]\n",
    "         ,two_loc[1]\n",
    "         , \"2$\\sigma$: \" + str(round(two_sigma, 2))\n",
    "         , ha=\"center\"\n",
    "         , va=\"center\"\n",
    "         ,fontsize = fontsize+1\n",
    "         ,zorder = 5\n",
    "         ,color = 'k'\n",
    "         ,fontweight = 'bold')\n",
    "\n",
    "\n",
    "# Mean and STD rectangle\n",
    "rect_loc = (plt.xlim()[1] - 0.3*plt.xlim()[1], plt.ylim()[1] - 0.3*plt.ylim()[1])\n",
    "mean_loc = (plt.xlim()[1] - 0.29*plt.xlim()[1], plt.ylim()[1] - 0.15*plt.ylim()[1])\n",
    "std_loc = (plt.xlim()[1] - 0.29*plt.xlim()[1], plt.ylim()[1] - 0.26*plt.ylim()[1])\n",
    "\n",
    "rect1 = plt.Rectangle(rect_loc,(6),(14), facecolor=white,edgecolor=\"black\",alpha=0.8)\n",
    "plt.gca().add_patch(rect1)\n",
    "# Mean Info\n",
    "plt.text(mean_loc[0]\n",
    "         ,mean_loc[1]\n",
    "         , \"Mean: \" + str(mean_degree)\n",
    "         ,fontsize = fontsize+4\n",
    "         ,zorder = 5\n",
    "         ,color = 'k'\n",
    "         ,fontweight = 'bold')\n",
    "# STD Info\n",
    "plt.text(std_loc[0]\n",
    "         ,std_loc[1]\n",
    "         , \"STD:   \" + str(std_degree)\n",
    "         ,fontsize = fontsize+4\n",
    "         ,zorder = 5\n",
    "         ,color = 'k'\n",
    "         ,fontweight = 'bold')\n",
    "\n",
    "\n",
    "# further settings\n",
    "plt.xticks([0,5,10,15,20], fontsize=fontsize+5)\n",
    "plt.yticks([10,30,50], fontsize=fontsize+5)\n",
    "plt.xlabel('Node Degree', fontsize=fontsize+5, weight='bold')\n",
    "plt.ylabel('Frequency', fontsize=fontsize+5, weight='bold')\n",
    "plt.rc('xtick', labelsize=fontsize+5) \n",
    "plt.rc('ytick', labelsize=fontsize+5)\n",
    "\n",
    "\n",
    "# Box Plot\n",
    "ax2 = figgy.add_subplot(gs[1])\n",
    "bp = plt.boxplot(centrality_df[top10_houses])\n",
    "\n",
    "for box in bp['boxes']:\n",
    "    box.set(linewidth=4, color=blue)\n",
    "\n",
    "for medians in bp['medians']:\n",
    "    medians.set(linewidth=3, color=green)\n",
    "    \n",
    "plt.xlabel('House Name', fontsize=fontsize+5, weight='bold')\n",
    "plt.ylabel('Node Degree', fontsize=fontsize+5, weight='bold')\n",
    "\n",
    "ax2.set_xticklabels(top10_short, fontsize=fontsize)\n",
    "\n",
    "plt.yticks([10,20,30,40,50], fontsize=fontsize+5)\n",
    "\n",
    "\n",
    "\n",
    "# Average Graph\n",
    "\n",
    "ax3 = figgy.add_subplot(gs[2])\n",
    "\n",
    "# plot the map\n",
    "plt.xlim(0, 4096)\n",
    "plt.ylim(0, 4096)\n",
    "ax3.set_frame_on(False)\n",
    "plt.axis('off')\n",
    "plt.imshow(white_bg_img,aspect=ax3.get_aspect(),\n",
    "         extent= ax3.get_xlim() + ax3.get_ylim(),\n",
    "         zorder=1, alpha=0.8)\n",
    "\n",
    "# Draw the graph \n",
    "vmin = np.min(sorted_mean_degrees)\n",
    "vmax = np.max(sorted_mean_degrees)\n",
    "\n",
    "nx.draw_networkx_nodes(G,\n",
    "                       node_pos, \n",
    "                       alpha = 1, \n",
    "                       node_size = 60, \n",
    "                       node_color=sorted_mean_degrees, \n",
    "                       cmap=parula_map)\n",
    "\n",
    "if plot_edges_bool == True:\n",
    "    nx.draw_networkx_edges(G, \n",
    "                           node_pos, \n",
    "                           edge_color='k', \n",
    "                           alpha=0.5, \n",
    "                           width=1,\n",
    "                           style='dashed')\n",
    "    \n",
    "\n",
    "ax3.set_xlim(0,3800)\n",
    "ax3.set_ylim(300,3700) \n",
    "            \n",
    "            \n",
    "sm = plt.cm.ScalarMappable(cmap=parula_map, norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm, ticks=[0,5,10,15,20])\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "cbar.set_label('Node Degree', size=20, weight='bold')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Top 10 Houses Graph Plot\n",
    "\n",
    "ax4 = figgy.add_subplot(gs[3])\n",
    "\n",
    "# plot the map\n",
    "plt.xlim(0, 4096)\n",
    "plt.ylim(0, 4096)\n",
    "ax4.set_frame_on(False)\n",
    "plt.axis('off')\n",
    "plt.imshow(white_bg_img,aspect=ax4.get_aspect(),\n",
    "         extent= ax4.get_xlim() + ax4.get_ylim(),\n",
    "         zorder=1, alpha=0.8)\n",
    "\n",
    "# Draw the graph \n",
    "vmin = np.min(degree_list)\n",
    "vmax = np.max(degree_list)\n",
    "\n",
    "node_sizes = np.ones(len(top10_degree_list))*20 # standard node size\n",
    "\n",
    "node_df = pd.DataFrame(top10_graph.nodes)\n",
    "\n",
    "node_sizes[node_df.isin(top10_houses).T.values[0]] = 120\n",
    "\n",
    "\n",
    "nx.draw_networkx_nodes(top10_graph,\n",
    "                       node_pos, \n",
    "                       alpha = 1, \n",
    "                       node_size = node_sizes, \n",
    "                       node_color=top10_degree_list, \n",
    "                       cmap=parula_map)\n",
    "\n",
    "\n",
    "nx.draw_networkx_edges(top10_graph, \n",
    "                       node_pos, \n",
    "                       edge_color='k', \n",
    "                       alpha=0.5, \n",
    "                       width=1,\n",
    "                       style='solid')\n",
    "\n",
    "\n",
    "\n",
    "ax4.set_xlim(0,3800)\n",
    "ax4.set_ylim(300,3700) \n",
    "\n",
    "\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=parula_map, norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm)\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "cbar.set_label('Node Degree', size=20, weight='bold')\n",
    "\n",
    "# Figure Labels\n",
    "ax1.text(-3,60,figurelabels[0],fontdict={'fontweight':fontweight,'fontsize':labelfontsize})\n",
    "ax2.text(-0.79,51,figurelabels[1],fontdict={'fontweight':fontweight,'fontsize':labelfontsize})\n",
    "ax3.text(-600,3800,figurelabels[2],fontdict={'fontweight':fontweight,'fontsize':labelfontsize})\n",
    "ax4.text(-600,3800,figurelabels[3],fontdict={'fontweight':fontweight,'fontsize':labelfontsize})\n",
    "\n",
    "\n",
    "# ---------- SAVING ---------\n",
    "\n",
    "if save_bool == True:\n",
    "    # saving the figure\n",
    "    try:\n",
    "        plt.savefig(GIT_GRAPH_PATH + \"Landmark_Plot.png\",\n",
    "                    dpi=200,\n",
    "                    format=\"PNG\",\n",
    "                    facecolor='white',\n",
    "                    transparent=False, \n",
    "                    bbox_inches = \"tight\")\n",
    "    except:\n",
    "        print(\"\\tCould not save Landmark Plot as PNG!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "centrality_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchy Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bool = False\n",
    "\n",
    "# open the Node degree csv file as dictionary\n",
    "with open(GIT_GRAPH_PATH + 'centrality_df.csv') as f:\n",
    "    try:\n",
    "        centrality_df = pd.read_csv(f)\n",
    "    except:\n",
    "            print(\"\\tCould not load centrality_df!\")\n",
    "            \n",
    "HierarchyIndexDoc = pd.read_csv('/Users/lessmann/Documents/Uni/GitHub/GTA_ET/Results/Graphs/HierarchyTable.csv')\n",
    "\n",
    "\n",
    "\n",
    "# PREPARATION\n",
    "\n",
    "subject_degreelist = centrality_df[centrality_df.Subject == str(subIDs[0])].copy()\n",
    "subject_degreelist = np.array(subject_degreelist.drop(['Subject', 'Mean', 'STD'], axis=1).values[0])\n",
    "subject_degreelist = subject_degreelist[~np.isnan(subject_degreelist)]\n",
    "\n",
    "mean_hier = round(np.mean(HierarchyIndexDoc.HierarchyIndex), 2)\n",
    "std_hier = round(np.std(HierarchyIndexDoc.HierarchyIndex), 2)\n",
    "\n",
    "median_degree = np.median(subject_degreelist)\n",
    "\n",
    "# get a list of unique degree values\n",
    "UniqueDegree = np.unique(subject_degreelist)\n",
    "UniqueDegreeMed = UniqueDegree[UniqueDegree >= median_degree]\n",
    "\n",
    "# get the frequency of each degree value\n",
    "DegreeFrequency = dict()\n",
    "\n",
    "for degree in UniqueDegree:\n",
    "    DegreeFrequency[degree] = np.sum(subject_degreelist==degree)\n",
    "\n",
    "DegreeFrequencyMed = np.array(list(DegreeFrequency.values()))[UniqueDegree >= median_degree]\n",
    "\n",
    "# do a linear fit of the log data of Unique Degree over Frequency\n",
    "linear_model=np.polyfit(np.log(UniqueDegreeMed),np.log(DegreeFrequencyMed),1)\n",
    "linear_model_fn=np.poly1d(linear_model)\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "# ---- PLOTTING -----  \n",
    "            \n",
    "\n",
    "figgy = plt.figure(figsize=(15,5), constrained_layout=False)\n",
    "\n",
    "# create grid for different subplots                    \n",
    "gs = gridspec.GridSpec(ncols=2, nrows=1, \n",
    "                          wspace=0.23)\n",
    "\n",
    "ax1 = figgy.add_subplot(gs[0])\n",
    "\n",
    "plt.scatter(np.log(UniqueDegree),np.log(list(DegreeFrequency.values())), )\n",
    "\n",
    "x_s=np.arange(np.log(median_degree) ,max(np.log(UniqueDegree)+0.5))\n",
    "plt.plot(x_s, linear_model_fn(x_s),color=green, linewidth=4)\n",
    "\n",
    "# settings\n",
    "plt.xlabel('Degree', fontsize=fontsize, weight='bold')\n",
    "plt.ylabel('Frequency', fontsize=fontsize, weight='bold')\n",
    "plt.rc('xtick', labelsize=fontsize) \n",
    "plt.rc('ytick', labelsize=fontsize)\n",
    "\n",
    "\n",
    "\n",
    "ax2 = figgy.add_subplot(gs[1])\n",
    "\n",
    "plt.hist(HierarchyIndexDoc.HierarchyIndex, ec='k', bins=10, color=blue, align=\"mid\")\n",
    "\n",
    "# Mean and STD rectangle\n",
    "rect_loc = (plt.xlim()[1] - 0.155*plt.xlim()[1], plt.ylim()[1] - 0.24*plt.ylim()[1])\n",
    "mean_loc = (plt.xlim()[1] - 0.145*plt.xlim()[1], plt.ylim()[1] - 0.12*plt.ylim()[1])\n",
    "std_loc = (plt.xlim()[1] - 0.145*plt.xlim()[1], plt.ylim()[1] - 0.19*plt.ylim()[1])\n",
    "\n",
    "rect1 = plt.Rectangle(rect_loc,(0.6),(2), facecolor=white,edgecolor=\"black\",alpha=0.8)\n",
    "plt.gca().add_patch(rect1)\n",
    "# Mean Info\n",
    "plt.text(mean_loc[0]\n",
    "         ,mean_loc[1]\n",
    "         , \"Mean: \" + str(mean_hier)\n",
    "         ,fontsize = fontsize\n",
    "         ,zorder = 5\n",
    "         ,color = 'k'\n",
    "         ,fontweight = 'bold')\n",
    "# STD Info\n",
    "plt.text(std_loc[0]\n",
    "         ,std_loc[1]\n",
    "         , \"STD:  \" + str(std_hier)\n",
    "         ,fontsize = fontsize\n",
    "         ,zorder = 5\n",
    "         ,color = 'k'\n",
    "         ,fontweight = 'bold')\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('Hierarchy Index', fontsize=fontsize, weight='bold')\n",
    "plt.ylabel('Frequency', fontsize=fontsize, weight='bold')\n",
    "plt.rc('xtick', labelsize=fontsize) \n",
    "plt.rc('ytick', labelsize=fontsize)\n",
    "\n",
    "\n",
    "# Figure Labels\n",
    "ax1.text(-0.6,3.52,figurelabels[0],fontdict={'fontweight':fontweight,'fontsize':labelfontsize})\n",
    "ax2.text(2.1,9.4,figurelabels[1],fontdict={'fontweight':fontweight,'fontsize':labelfontsize})\n",
    "\n",
    "# ---------- SAVING ---------\n",
    "\n",
    "if save_bool == True:\n",
    "    # saving the figure\n",
    "    try:\n",
    "        plt.savefig(GIT_GRAPH_PATH + \"Hierarchy_Figure.png\",\n",
    "                    dpi=200,\n",
    "                    format=\"PNG\",\n",
    "                    facecolor='white',\n",
    "                    transparent=False, \n",
    "                    bbox_inches = \"tight\")\n",
    "    except:\n",
    "        print(\"\\tCould not save Hierarchy Figure as PNG!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rich Club Coefficient\n",
    "* Requires running the Node Degree Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bool = False # if you want to save and overwrite \n",
    "\n",
    "# load the RC documentation\n",
    "with open(GIT_GRAPH_PATH + 'RichClubDoc.csv') as f:\n",
    "    try:\n",
    "        RichClubDoc = pd.read_csv(f)\n",
    "    except:\n",
    "            print(\"\\tCould not load RichClubDoc!\")\n",
    "            \n",
    "            \n",
    "RichClubHouses_df = pd.DataFrame(columns=['House', 'Frequency'])\n",
    "RichClubHouses_df.House = pure_degree.columns[1:]\n",
    "\n",
    "one_sigma = centrality_df[centrality_df.Subject == 'Mean'].Mean.values[0] \\\n",
    "                + centrality_df[centrality_df.Subject == 'Mean'].STD.values[0]\n",
    "\n",
    "two_sigma = centrality_df[centrality_df.Subject == 'Mean'].Mean.values[0] \\\n",
    "                + 2*centrality_df[centrality_df.Subject == 'Mean'].STD.values[0]\n",
    "\n",
    "\n",
    "temp_degree = pure_degree.iloc[:,1:] > one_sigma\n",
    "RichClubHouses_df.Frequency = temp_degree.sum().values\n",
    "\n",
    "sorted_rich_dict = dict()\n",
    "for node in nodelist:\n",
    "    sorted_rich_dict[node] = RichClubHouses_df.Frequency[RichClubHouses_df.House == node].values[0]\n",
    "    \n",
    "sorted_rich = list(sorted_rich_dict.values())\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "figgy = plt.figure(figsize=(16,7), constrained_layout=False)\n",
    "\n",
    "# create grid for different subplots                    \n",
    "gs = gridspec.GridSpec(ncols=2, nrows=1, \n",
    "                          wspace=0.16,\n",
    "                          width_ratios=[1, 1.3])\n",
    "\n",
    "ax1 = figgy.add_subplot(gs[0])\n",
    "\n",
    "\n",
    "for sub in RichClubDoc.columns:\n",
    "    plt.plot(RichClubDoc[sub][0:20], linestyle=':', linewidth=1)\n",
    "\n",
    "meanRC = RichClubDoc.mean(axis=1)   \n",
    "plt.plot(meanRC[:20], linewidth=7, color=green)    \n",
    "\n",
    "#plt.title('Rich Club - All', fontsize=fontsize, weight='bold')\n",
    "plt.xlabel('Node Degree', fontsize=fontsize, weight='bold')\n",
    "plt.ylabel('Rich Club (Real/Random)', fontsize=fontsize, weight='bold')\n",
    "plt.xticks([0,5,10,15], fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.ylim(0.901,1.5)\n",
    "plt.xlim(0,round(one_sigma))\n",
    "\n",
    "\n",
    "ax2 = figgy.add_subplot(gs[1])\n",
    "\n",
    "# plot the map\n",
    "plt.xlim(0, 4096)\n",
    "plt.ylim(0, 4096)\n",
    "ax2.set_frame_on(False)\n",
    "plt.axis('off')\n",
    "plt.imshow(white_bg_img,aspect=ax3.get_aspect(),\n",
    "         extent= ax2.get_xlim() + ax2.get_ylim(),\n",
    "         zorder=1, alpha=0.8)\n",
    "\n",
    "# Draw the graph \n",
    "vmin = RichClubHouses_df.Frequency.min()\n",
    "vmax = RichClubHouses_df.Frequency.max()\n",
    "\n",
    "size = [np.exp(i/6)*4 for i in sorted_rich]\n",
    "\n",
    "nx.draw_networkx_nodes(G,\n",
    "                       node_pos, \n",
    "                       alpha = 1, \n",
    "                       node_size = size, \n",
    "                       node_color=sorted_rich, \n",
    "                       cmap=parula_map)\n",
    "\n",
    "    \n",
    "ax2.set_xlim(0,3800)\n",
    "ax2.set_ylim(300,3700) \n",
    "    \n",
    "sm = plt.cm.ScalarMappable(cmap=parula_map, norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm)\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "cbar.set_label('Node Degree', size=20)\n",
    "\n",
    "# Figure Labels\n",
    "ax1.text(-2.2,1.522,figurelabels[0],fontdict={'fontweight':fontweight,'fontsize':labelfontsize})\n",
    "ax2.text(-500,3800,figurelabels[1],fontdict={'fontweight':fontweight,'fontsize':labelfontsize})\n",
    "\n",
    "\n",
    "# ---------- SAVING ---------\n",
    "\n",
    "if save_bool == True:\n",
    "    # saving the figure\n",
    "    try:\n",
    "        plt.savefig(GIT_GRAPH_PATH + \"RichClub_All.png\",\n",
    "                    dpi=200,\n",
    "                    format=\"PNG\",\n",
    "                    facecolor='white',\n",
    "                    transparent=False,\n",
    "                    bbox_inches = \"tight\")\n",
    "    except:\n",
    "        print(\"\\tCould not save RichCLub_All as PNG!\")\n",
    "\n",
    "\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triangulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform gaze locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load gazes file\n",
    "gazes = pd.read_csv(GIT_GRAPH_PATH+ \"all_gazes.csv\")\n",
    "\n",
    "\n",
    "# transform coordinates\n",
    "gazes = TransformHelper.apply_perspective_transform_matrix(transform_matrix,\n",
    "                                                                img_size=(4096,4096),\n",
    "                                                                dataframe=gazes,\n",
    "                                                                df_x_name=\"HMD_x\",\n",
    "                                                                df_y_name=\"HMD_z\",\n",
    "                                                                transform_x_name=\"transformed_HMD_x\",\n",
    "                                                                transform_y_name=\"transformed_HMD_y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- Preparation ---------\n",
    "\n",
    "# load the city map image\n",
    "white_bg_img = cv2.imread(\"./ressources/map_white.png\")\n",
    "\n",
    "\n",
    "#RichClubHouses = RichClubHouses_df.sort_values(by='Frequency', ascending=False)[:10].House.values\n",
    "sigma2 = RichClubHouses_df.Frequency.mean()+2*RichClubHouses_df.Frequency.std()\n",
    "RichClubHouses = RichClubHouses_df[RichClubHouses_df.Frequency>sigma2].sort_values(by='Frequency', ascending=False).House.values\n",
    "\n",
    "\n",
    "Rich_gazes = gazes[gazes['ColliderName'].isin(RichClubHouses)]\n",
    "Rich_gazes = Rich_gazes.reset_index(drop=True)\n",
    "\n",
    "    \n",
    "rows, cols, colorchannels = np.shape(white_bg_img)\n",
    "\n",
    "EdgesRows = list(range(0, rows, 16))\n",
    "EdgesCols = list(range(0, cols, 16))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Locations = np.zeros((int(rows/16),int(cols/16)))\n",
    "\n",
    "\n",
    "# loop to check which location has been visited\n",
    "for gaze_idx in range(len(gazes)-1):\n",
    "    \n",
    "    x = round(gazes.transformed_HMD_x[gaze_idx]/16)\n",
    "    y = round(gazes.transformed_HMD_y[gaze_idx]/16)\n",
    "    \n",
    "    if Locations[y,x] == 0:\n",
    "        Locations[y,x] = 1\n",
    "        Locations[y,x] = int(Locations[y,x])\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "# loop to check where Rich Club Houses where visible\n",
    "for Rich_idx in range(len(Rich_gazes)-1):\n",
    "    \n",
    "\n",
    "    x = round(Rich_gazes.transformed_HMD_x[Rich_idx]/16)\n",
    "    y = round(Rich_gazes.transformed_HMD_y[Rich_idx]/16)\n",
    "    \n",
    "    if Locations[y,x] == 0:\n",
    "        Locations[y,x] = 1\n",
    "        Locations[y,x] = int(Locations[y,x])\n",
    "    else:\n",
    "        Locations[y,x] += 1\n",
    "        Locations[y,x] = int(Locations[y,x])\n",
    "    \n",
    "\n",
    "Locations[Locations>=3] = 3\n",
    "\n",
    "Locations = expand(Locations, upscale=16)\n",
    "\n",
    "Locations[Locations == 0] = np.nan   \n",
    "        \n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- PLOTTING ---------   \n",
    "save_bool = True\n",
    "\n",
    "#discrete color scheme\n",
    "cMap = ListedColormap([darkblue, green, lightyellow])\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20,15))\n",
    "    \n",
    "ax = plt.subplot2grid((10, 10), (0, 0), colspan=9,rowspan=10)\n",
    "plt.xlim(0, 4096)\n",
    "plt.ylim(0, 4096)\n",
    "ax.set_frame_on(False)\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "# Here, for plot visibility, I am doing a inverse Canny Edge Detection \n",
    "# to only plot the binary edge image of the map\n",
    "plt.imshow(cv2.bitwise_not(cv2.Canny(white_bg_img, threshold1=30, threshold2=100)),\n",
    "         aspect=ax.get_aspect(),\n",
    "         extent= ax.get_xlim() + ax.get_ylim(),\n",
    "         zorder=1, alpha=0.25)\n",
    "\n",
    "plt.gray()\n",
    "\n",
    "\n",
    "\n",
    "triang = plt.imshow(Locations,\n",
    "           alpha = 1,\n",
    "           cmap=cMap)\n",
    "\n",
    "cbar = plt.colorbar(triang)\n",
    "cbar.ax.get_yaxis().set_ticks([])\n",
    "\n",
    "for j, lab in enumerate(['0','1','2']):\n",
    "    cbar.ax.text(1.5,\n",
    "                 (2 * j + 1)/2 ,\n",
    "                 lab,\n",
    "                 ha='center',\n",
    "                 va='center',\n",
    "                 fontsize=fontsize+10)\n",
    "    \n",
    "cbar.set_label('Visible gaze-graph-defined landmarks', size=fontsize+5, labelpad=20, weight='bold')\n",
    "    \n",
    "\n",
    "ax.set_xlim(0,3800)\n",
    "ax.set_ylim(300,3700) \n",
    "\n",
    "    \n",
    "# ---------- SAVING ---------    \n",
    "\n",
    "if save_bool == True:\n",
    "    # saving the figure\n",
    "    try:\n",
    "        plt.savefig(GIT_GRAPH_PATH + \"Triangulation_All.png\",\n",
    "                    dpi=200,\n",
    "                    format=\"PNG\",\n",
    "                    transparent=False,\n",
    "                    facecolor='white',\n",
    "                    bbox_inches = \"tight\")\n",
    "    except:\n",
    "        print(\"\\tCould not save Triangulation_All as PNG!\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
