{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subject Data PreProcessing\n",
    "* find subject data\n",
    "* concatenate the inter-session data\n",
    "* concatenate the intra-session data\n",
    "* Clean and condense the data\n",
    "* Create graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO\n",
    "* DONE - Adapt the cleaning cell to also consider empty data points and mark them as noData in the DataFrame\n",
    "    * DONE - Make sure that the timestamps are consistent!\n",
    "    * DONE - Check for possible condition for noData points, e.g. unsufficient eye-openness\n",
    "    * DONE - Adapt script to rename all colliders to NoHouse that are no house (house list required)\n",
    "    * DONE - adjust nan dataframes to also add sessions\n",
    "    * DONE - check for Graffities and replace them with building name\n",
    "    * IN PROGRESS - Check for Garage Colliders\n",
    "* DONE - Condense data by replacing identical successive collider hits with (collidername, amount if hits)\n",
    "    * DONE - confirm that the gaze-noise ratio is correct\n",
    "* DONE - Account for lost data by interpolation! \n",
    "* DONE - Write gaze definition cell by assigning 21 consecutive hits to a gaze caused by an actual fixation. Mark hits<21 as noise \n",
    "* DONE - Create unweighted undirected graphs\n",
    "    * Remove all noHouse hits \n",
    "    * Remove all self repetitions \n",
    "    * Check the exact procedure \n",
    "\n",
    "* IN PROGRESS - Save Subject Data within separate file \n",
    "* DONE - Create figure comparison with paper figures \n",
    "* IN PROGRESS - Write written summary for P&S of procedure \n",
    "* IN PROGRESS - Save graphs \n",
    "* IN PROGRESS - Create Centrality Measure Dataframe for all subjects \n",
    "* IN PROGRESS - Write Interpolation Variant for 1 sample hits \n",
    "* IN PROGRESS - Implement new houselist with name assignments \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General configuration\n",
    "import os\n",
    "\n",
    "# data_directory: str\n",
    "#     Path to a directory to store data.\n",
    "data_directory = '.'\n",
    "\n",
    "# install_missing_packages: bool\n",
    "#     A flag indicating if missing packages should be automatically installed\n",
    "install_missing_packages = True\n",
    "\n",
    "# use_conda: bool\n",
    "#     A flag indicating if conda should be used for software installation.\n",
    "#     If False, pip will be used. The default is to use conda if jupyter\n",
    "#     is run in a conda environment.\n",
    "use_conda = 'CONDA_EXE' in os.environ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for missing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "def check_package(package, pip_pkg: str = None, conda_pkg: str = None):\n",
    "    \"\"\"Check if a given package is installed. If missing install\n",
    "    it (if global flag `install_missing_packages` is True) either with\n",
    "    pip or with conda (depending on `use_conda`).\n",
    "    \"\"\"\n",
    "    if importlib.util.find_spec(package) is not None:\n",
    "        return  # ok, package is already installed\n",
    "\n",
    "    if not install_missing_packages:\n",
    "        raise RuntimeError(f\"{package} is not installed!\")\n",
    "\n",
    "    if use_conda:\n",
    "        import conda.cli\n",
    "        conda.cli.main('conda', 'install',  '-y', conda_pkg or package)\n",
    "    else:\n",
    "        import subprocess\n",
    "        import sys            \n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', pip_pkg or package])\n",
    "        \n",
    "# This is to exit cells without error tracebacks (cosmetic purpose)\n",
    "class StopExecution(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the required environment (skip if already done)\n",
    "\n",
    "Running the following cell will create a file graphs.yml that can be used to setup a conda environment containing the required packages. If you already downloaded the file from my GitHub, skip the next cell and create the env directly from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting graphs.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile graphs.yml\n",
    "name: graphs\n",
    "channels:\n",
    "  - conda-forge\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - python=3.6\n",
    "  - jupyter\n",
    "  - imageio\n",
    "  - imageio-ffmpeg\n",
    "  - matplotlib\n",
    "  - scikit-image\n",
    "  - opencv\n",
    "  - networkx\n",
    "  - pandas\n",
    "  - statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Creation\n",
    "To create the environment, open the terminal, go to the directory where you stored the graphs.yml file (the directory of the notebook) and type\n",
    "conda env create -f graphs.yml\n",
    "After running this command you have to activate the environment (Linux/MacOS: conda activate graphs, Windows: activate graphs) and then reopen the notebook in that environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and directory information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import glob\n",
    "import scipy.cluster.vq as clusters\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from pandas.plotting import autocorrelation_plot as AC_plot \n",
    "from statsmodels.graphics import tsaplots\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from skimage.filters import gaussian\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "\n",
    "OG_DATA_PATH = './'\n",
    "THEORETICAL_DATA_PATH = './Data Exploration/'\n",
    "THEORETICAL_PROCESSED_DATA_PATH = './Results/'\n",
    "THEORETICAL_GRAPH_PATH = './Results/Graphs/'\n",
    "RESSOURCES_PATH = './Ressources/'\n",
    "\n",
    "# Reset the Datapath since the data is not yet on Git, comment out if data is on Git \n",
    "DATA_PATH = '/Volumes/EXTENSION/Uni/Study Project/Data Exploration/'\n",
    "\n",
    "PROCESSED_DATA_PATH = '/Volumes/EXTENSION/Uni/Study Project/Results/'\n",
    "GRAPH_DATA_PATH = '/Volumes/EXTENSION/Uni/Study Project/Results/Graphs/'\n",
    "# Getting the Folder without hidden files in ascending order \n",
    "DATA_FOLDER = sorted([f for f in os.listdir(DATA_PATH) if not f.startswith('.')], key=str.lower)\n",
    "PROCESSED_DATA_FOLDER = sorted([f for f in os.listdir(PROCESSED_DATA_PATH) if not f.startswith('.')], key=str.lower)\n",
    "\n",
    "\n",
    "\n",
    "#houselist \n",
    "house_file = RESSOURCES_PATH + 'building_collider_list.csv'\n",
    "try:\n",
    "    houselist = pd.read_csv(house_file)\n",
    "except:\n",
    "    print('HouseList could not be loaded!')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting all subject IDs from the data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1005 1008 1010 1011 1013 1017 1018 1019 1021 1023 1079 1080]\n"
     ]
    }
   ],
   "source": [
    "subIDs = []\n",
    "for sub in DATA_FOLDER:\n",
    "    if sub[0].isdigit():\n",
    "        subIDs.append(int(sub[0:4]))\n",
    "    else:\n",
    "        pass\n",
    "subIDs = np.unique(subIDs)\n",
    "print(subIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom subID\n",
    "subIDs = [1005]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the data\n",
    "* Loop through all subjects\n",
    "* extract the session data\n",
    "* combine the data\n",
    "* save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 1005 started - 1/1 subjects\n",
      "\tTotal Sessionfiles: 3 - Exploration Session 1\n",
      "\tEXP: 1, ET: 1 normalized - Length: 112825\n",
      "\tEXP: 1, ET: 2 normalized - Length: 116639\n",
      "\tEXP: 1, ET: 3 normalized - Length: 115089\n",
      "\tTotal Sessionfiles: 3 - Exploration Session 2\n",
      "\tEXP: 2, ET: 1 normalized - Length: 112574\n",
      "\tEXP: 2, ET: 2 normalized - Length: 110534\n",
      "\tEXP: 2, ET: 3 normalized - Length: 113598\n",
      "\tTotal Sessionfiles: 3 - Exploration Session 3\n",
      "\tEXP: 3, ET: 1 normalized - Length: 112756\n",
      "\tEXP: 3, ET: 2 normalized - Length: 116218\n",
      "\tEXP: 3, ET: 3 normalized - Length: 109903\n",
      "\tTotal Sessionfiles: 3 - Exploration Session 4\n",
      "\tEXP: 4, ET: 1 normalized - Length: 114298\n",
      "\tEXP: 4, ET: 2 normalized - Length: 115273\n",
      "\tEXP: 4, ET: 3 normalized - Length: 114570\n",
      "\tTotal Sessionfiles: 3 - Exploration Session 5\n",
      "\tEXP: 5, ET: 1 normalized - Length: 111347\n",
      "\tEXP: 5, ET: 2 normalized - Length: 111123\n",
      "\tEXP: 5, ET: 3 normalized - Length: 114144\n",
      "\t1005 exploration saved\n",
      "\t1005 - Stats: \n",
      "\tRemoved Body Hits: 53805 Removed Graffities: 51788 Replaced 1st NoHouse hits: 110132\n",
      "\tPortion of insufficient data quality (BitMask): 3.32%\n",
      "\tNoHits: 1.53%\n",
      "\tNoHouse: 61.33%\n",
      "\tTotal missing data: 4.85%\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# --------- Preparation ---------\n",
    "\n",
    "Session_save_bool = False # set to True if you want to save each individual session as csv\n",
    "Exploration_save_bool = False # set to True if you want to save the complete exploration as csv\n",
    "Subject_Info_save_bool = False # set to True if you want to save the subject data as csv\n",
    "subcount = 0\n",
    "graffity_replaced_count = 0\n",
    "removed_body_hits = 0\n",
    "removed_nohouse_hits = 0\n",
    "\n",
    "landmarks = ['Castle-TaskBuilding_56',\n",
    "             'Church-TaskBuilding_16',\n",
    "             'HighSilo-TaskBuilding_49',\n",
    "             'Windmill-TaskBuilding_10_1',\n",
    "             'crane_1',\n",
    "             'crane_2']\n",
    "\n",
    "garages_to_stay = ['Garage_185', \n",
    "                   'Garage_224', \n",
    "                   'Garage_235',  \n",
    "                   'Garage_86', \n",
    "                   'Garage_98']\n",
    "\n",
    "#garages_to_buildings = ['Garage_26', \n",
    "#                        'Garage_46', \n",
    "#                        'Garage_71', \n",
    "#                        'Garage_72']\n",
    "#\n",
    "#collider_merging = {'building01_LOD0': 'Building_157',\n",
    "#                    'building01_LOD1': 'Building_157',\n",
    "#                    'building02_LOD0': 'Building_171',\n",
    "#                    'Building_115': 'Building_116',\n",
    "#                    'Garage_26' : 'TaskBuilding_26', \n",
    "#                    'Garage_46': 'TaskBuilding_46', \n",
    "#                    'Garage_71': 'Building_71', \n",
    "#                    'Garage_72': 'Building_72'}\n",
    "#\n",
    "\n",
    "# column name list for dataframe\n",
    "col_names =  ['Session',\n",
    "              'timeStampDataPointStart',\n",
    "              'timeStampDataPointEnd',\n",
    "              'hitObjectColliderName', \n",
    "              'ordinalOfHit',\n",
    "              'BitMask',\n",
    "              'hitPointOnObject.x',\n",
    "              'hitPointOnObject.y',\n",
    "              'hitPointOnObject.z',\n",
    "              'hitObjectColliderBoundsCenter.x',\n",
    "              'hitObjectColliderBoundsCenter.y',\n",
    "              'hitObjectColliderBoundsCenter.z',\n",
    "              'transformed_collidercenter_x',\n",
    "              'transformed_collidercenter_y'\n",
    "              'hmdPosition.x',\n",
    "              'hmdPosition.y',\n",
    "              'hmdPosition.z']\n",
    "\n",
    "\n",
    "NoHit_dict = {'hitObjectColliderName': 'NoHit',\n",
    "              'ordinalOfHit': '1'}\n",
    "\n",
    "\n",
    "subject_cols = ['SubjectID',\n",
    "                'Sessions',\n",
    "                'ET_Sessions',\n",
    "                'Total Rows Combined',\n",
    "                'Removed Body Hits', \n",
    "                'Removed Graffiti Hits', \n",
    "                'Replaced NoHouse Hits',\n",
    "                'DataLoss BitMask', \n",
    "                'DataLoss NoHits',\n",
    "                'DataLoss Combined']\n",
    "\n",
    "subject_data_df = pd.DataFrame(columns=subject_cols)\n",
    "\n",
    "\n",
    "# --------------------------- MAIN PART ---------------------------\n",
    "\n",
    "\n",
    "# --------- first layer - subject loop ---------\n",
    "\n",
    "for subject in subIDs:\n",
    "    subcount +=1\n",
    "    print('Subject ' \n",
    "          + str(subject) \n",
    "          + ' started - ' \n",
    "          + str(subcount) \n",
    "          + '/' \n",
    "          + str(len(subIDs)) \n",
    "          + ' subjects')\n",
    "    \n",
    "    # Create empty dataframe for later concatenation\n",
    "    complete_exploration_df = pd.DataFrame(columns = col_names)\n",
    "    \n",
    "    # get the data files according to the subject, ignoring OnQuit files\n",
    "    subject_folder = sorted([f for f in DATA_FOLDER \n",
    "                             if f.startswith(str(subject)+'_Expl_S_') and f.endswith(\"OnQuit.json\") == False], \n",
    "                            key=str.lower) \n",
    "    \n",
    "    # the following works as long as the data name format is as follows:\n",
    "    # 'subjectID'_Expl_S_'SessionNumber'_ET_'EyeTrackingSessionNumber'_'UnixTimestamp'.json\n",
    "    folder_files = list()\n",
    "       \n",
    "    # loop through the subject folder and save all numbers\n",
    "    for file in subject_folder:\n",
    "        folder_files.append(re.findall(r'\\d+', file))\n",
    "    \n",
    "    # Extract all SubIDs (only one), SessionNumbers, ET_SessionNumbers (and Timestamps)\n",
    "    try:\n",
    "        SubID, SessionNumbers, ET_SessionNumbers, UnixTimestamp1, UnixTimeStamp2 = map(list, zip(*folder_files))\n",
    "    except:\n",
    "        print('\\tSubject ' \n",
    "              + str(subject)\n",
    "              + ' Filename is not valid!')\n",
    "    \n",
    "    session_number = int(max(SessionNumbers)) # the maximum session number of the particular subject\n",
    "    ET_session_number = int(max(ET_SessionNumbers)) # the maximum ET session number of the particular subject\n",
    "    \n",
    "    \n",
    "    # only continue if there are 15 files, aka 5 exploration sessions with 3 ET Sessions each \n",
    "    \n",
    "    if session_number == 5: #and ET_session_number == 3:\n",
    "    \n",
    "# --------- second layer - exploration session loop ---------\n",
    "\n",
    "        # loop over exploration sessions\n",
    "        for EXP_session in range(session_number):\n",
    "            # to avoid start at 0\n",
    "            EXP_session +=1 \n",
    "\n",
    "            # extract the exploration data\n",
    "            subject_data = sorted([f for f in DATA_FOLDER if f.startswith(str(subject) + '_Expl_S_' + str(EXP_session)) \n",
    "                                   and f.endswith(\"OnQuit.json\") == False], key=str.lower)\n",
    "\n",
    "\n",
    "            # hitpoint dataframe \n",
    "            complete_hitpoints_df = pd.DataFrame(columns = col_names)\n",
    "\n",
    "            print(\"\\tTotal Sessionfiles: \"\n",
    "                  + str(len(subject_data))\n",
    "                  + \" - Exploration Session \"\n",
    "                  + str(EXP_session))\n",
    "\n",
    "            s = 0 # session count\n",
    "\n",
    "    # --------- third layer - eye tracking session loop ---------\n",
    "\n",
    "            # loop over separate eye tracking sessions\n",
    "            for ET_session in subject_data:\n",
    "                s+=1\n",
    "\n",
    "                # open the JSON file as dictionary\n",
    "                with open(DATA_PATH + ET_session) as f:\n",
    "                    try:\n",
    "                        subject_session = json.loads(f.read())\n",
    "                    except:\n",
    "                        print(\"\\tJSON file \" + ET_session + \" is not valid!\")\n",
    "\n",
    "                hitpoints_df = pd.DataFrame(columns = col_names)\n",
    "                hitpoint_list = list() # create hitpoint list\n",
    "\n",
    "                # start timestamp of the session \n",
    "                start_time = subject_session['trials'][0]['timeTrialMeasurementStarted']\n",
    "\n",
    "                # amount of datapoints \n",
    "                Len_subses = len(subject_session['trials'][0]['dataPoints'])\n",
    "\n",
    "                # for loop appending each data point rayCastHit Data\n",
    "                # afterwards adding the timestamp to the dict \n",
    "                # if there is (1) no raycast hit appending NoHit Dict\n",
    "\n",
    "                # --------------- First order hits! ---------------\n",
    "                for each in subject_session['trials'][0]['dataPoints']:\n",
    "\n",
    "                    # ----- account for noHits ----- \n",
    "                    if each['rayCastHitsCombinedEyes'] == []:\n",
    "                        hitpoint_list.append(NoHit_dict)\n",
    "                        # set index for new entry\n",
    "                        idx = len(hitpoint_list)-1\n",
    "                        hitpoint_list[idx]['Session'] = EXP_session\n",
    "                        hitpoint_list[idx]['timeStampDataPointStart'] = each['timeStampDataPointStart'] - start_time\n",
    "                        hitpoint_list[idx]['timeStampDataPointEnd'] = each['timeStampDataPointEnd'] - start_time\n",
    "                        hitpoint_list[idx]['BitMask'] = each['combinedGazeValidityBitmask']\n",
    "                        # hmdPosition\n",
    "                        hitpoint_list[idx]['hmdPosition.x'] = each['hmdPosition']['x']\n",
    "                        hitpoint_list[idx]['hmdPosition.y'] = each['hmdPosition']['y']\n",
    "                        hitpoint_list[idx]['hmdPosition.z'] = each['hmdPosition']['z']\n",
    "\n",
    "                    else: \n",
    "                        # ----- append data point -----\n",
    "                        hitpoint_list.append(each['rayCastHitsCombinedEyes'][0])\n",
    "                        # set index for new entry\n",
    "                        idx = len(hitpoint_list)-1\n",
    "                        \n",
    "                        current_collider = hitpoint_list[idx]['hitObjectColliderName']\n",
    "\n",
    "                        # add new coordinates\n",
    "                        \n",
    "                        # add Session, timestamp and bitmask\n",
    "                        hitpoint_list[idx]['Session'] = EXP_session\n",
    "                        hitpoint_list[idx]['timeStampDataPointStart'] = each['timeStampDataPointStart'] - start_time\n",
    "                        hitpoint_list[idx]['timeStampDataPointEnd'] = each['timeStampDataPointEnd'] - start_time\n",
    "                        hitpoint_list[idx]['BitMask'] = each['combinedGazeValidityBitmask']  \n",
    "                        # hmdPosition\n",
    "                        hitpoint_list[idx]['hmdPosition.x'] = each['hmdPosition']['x']\n",
    "                        hitpoint_list[idx]['hmdPosition.y'] = each['hmdPosition']['y']\n",
    "                        hitpoint_list[idx]['hmdPosition.z'] = each['hmdPosition']['z']\n",
    "\n",
    "                        \n",
    "                        # ----- CONDITIONS FOR CLEANING -----\n",
    "                        \n",
    "                        # ----- Merging obsolete colliders -----\n",
    "                        if current_collider in collider_merging.keys():\n",
    "                            merged_collider = collider_merging[current_collider]\n",
    "                            hitpoint_list[idx]['hitObjectColliderName'] = merged_collider\n",
    "                            \n",
    "                            # change collider coordinates\n",
    "                            hitpoint_list[idx]['hitObjectColliderBoundsCenter.x'] = \\\n",
    "                                houselist[merged_collider]['ColliderBoundsCenter.x']\n",
    "                            hitpoint_list[idx]['hitObjectColliderBoundsCenter.y'] = \\\n",
    "                                houselist[merged_collider]['ColliderBoundsCenter.y']\n",
    "                            hitpoint_list[idx]['hitObjectColliderBoundsCenter.z'] = \\\n",
    "                                houselist[merged_collider]['ColliderBoundsCenter.z']    \n",
    "                            hitpoint_list[idx]['transformed_collidercenter_x'] = \\\n",
    "                                houselist[merged_collider]['transformed_collidercenter_x']\n",
    "                            hitpoint_list[idx]['transformed_collidercenter_y'] = \\\n",
    "                                houselist[merged_collider]['transformed_collidercenter_y']\n",
    "                            \n",
    "                        # ----- NoHouse Hits -----\n",
    "                        # check if the collider name is a member of the houselist - if not: rename to NoHouse \n",
    "                        elif current_collider not in houselist.keys() \\\n",
    "                        and current_collider != 'Body' \\\n",
    "                        and (current_collider.startswith('Graffity_')) == False:\n",
    "                            hitpoint_list[idx]['hitObjectColliderName'] = 'NoHouse'\n",
    "                            \n",
    "                        else:\n",
    "                            try:\n",
    "                                hitpoint_list[idx]['hitObjectColliderBoundsCenter.x'] = \\\n",
    "                                    houselist[current_collider]['ColliderBoundsCenter.x']\n",
    "                                hitpoint_list[idx]['hitObjectColliderBoundsCenter.y'] = \\\n",
    "                                    houselist[current_collider]['ColliderBoundsCenter.y']\n",
    "                                hitpoint_list[idx]['hitObjectColliderBoundsCenter.z'] = \\\n",
    "                                    houselist[current_collider]['ColliderBoundsCenter.z']    \n",
    "                                hitpoint_list[idx]['transformed_collidercenter_x'] = \\\n",
    "                                    houselist[current_collider]['transformed_collidercenter_x']\n",
    "                                hitpoint_list[idx]['transformed_collidercenter_y'] = \\\n",
    "                                    houselist[current_collider]['transformed_collidercenter_y']\n",
    "                            except:\n",
    "                                pass\n",
    "\n",
    "\n",
    "\n",
    "             # --------------- Second order hits! ---------------\n",
    "                    # redo if there is a second ordinal hit\n",
    "                    try: \n",
    "                        # append data point of second raycast hit if it exists\n",
    "                        hitpoint_list.append(each['rayCastHitsCombinedEyes'][1])\n",
    "                        # set index for new entry\n",
    "                        idx = len(hitpoint_list)-1\n",
    "                        \n",
    "                        current_collider = hitpoint_list[idx]['hitObjectColliderName']\n",
    "\n",
    "                        # add Session, timestamp and bitmask\n",
    "                        hitpoint_list[idx]['Session'] = EXP_session\n",
    "                        hitpoint_list[idx]['timeStampDataPointStart'] = each['timeStampDataPointStart'] - start_time\n",
    "                        hitpoint_list[idx]['timeStampDataPointEnd'] = each['timeStampDataPointEnd'] - start_time\n",
    "                        hitpoint_list[idx]['BitMask'] = each['combinedGazeValidityBitmask']\n",
    "\n",
    "                        # check for different conditions:\n",
    "                        \n",
    "                                                \n",
    "                        # ----- Merging obsolete colliders -----\n",
    "                        if current_collider in collider_merging.keys():\n",
    "                            merged_collider = collider_merging[current_collider]\n",
    "                            hitpoint_list[idx]['hitObjectColliderName'] = merged_collider\n",
    "                            \n",
    "                            # change collider coordinates\n",
    "                            hitpoint_list[idx]['hitObjectColliderBoundsCenter.x'] = \\\n",
    "                                houselist[merged_collider]['ColliderBoundsCenter.x']\n",
    "                            hitpoint_list[idx]['hitObjectColliderBoundsCenter.y'] = \\\n",
    "                                houselist[merged_collider]['ColliderBoundsCenter.y']\n",
    "                            hitpoint_list[idx]['hitObjectColliderBoundsCenter.z'] = \\\n",
    "                                houselist[merged_collider]['ColliderBoundsCenter.z']    \n",
    "                            hitpoint_list[idx]['transformed_collidercenter_x'] = \\\n",
    "                                houselist[merged_collider]['transformed_collidercenter_x']\n",
    "                            hitpoint_list[idx]['transformed_collidercenter_y'] = \\\n",
    "                                houselist[merged_collider]['transformed_collidercenter_y']\n",
    "\n",
    "                        # ----- NoHouse Hits -----\n",
    "                        # check if the collider name is a member of the houselist - if not: rename to NoHouse \n",
    "                        elif current_collider not in houselist.keys() \\\n",
    "                        and current_collider != 'Body' \\\n",
    "                        and (current_collider.startswith('Graffity_')) == False:\n",
    "                            hitpoint_list[idx]['hitObjectColliderName'] = 'NoHouse'\n",
    "                        \n",
    "                        else:\n",
    "                            try:\n",
    "                                hitpoint_list[idx]['hitObjectColliderBoundsCenter.x'] = \\\n",
    "                                    houselist[current_collider]['ColliderBoundsCenter.x']\n",
    "                                hitpoint_list[idx]['hitObjectColliderBoundsCenter.y'] = \\\n",
    "                                    houselist[current_collider]['ColliderBoundsCenter.y']\n",
    "                                hitpoint_list[idx]['hitObjectColliderBoundsCenter.z'] = \\\n",
    "                                    houselist[current_collider]['ColliderBoundsCenter.z']    \n",
    "                                hitpoint_list[idx]['transformed_collidercenter_x'] = \\\n",
    "                                    houselist[current_collider]['transformed_collidercenter_x']\n",
    "                                hitpoint_list[idx]['transformed_collidercenter_y'] = \\\n",
    "                                    houselist[current_collider]['transformed_collidercenter_y']\n",
    "                            except:\n",
    "                                pass\n",
    "                            \n",
    "                        # if the first order hit was a NoHouse hit, but the second was not\n",
    "                        if hitpoint_list[idx-1]['hitObjectColliderName'] == 'NoHouse' \\\n",
    "                        and hitpoint_list[idx]['hitObjectColliderName'] != 'NoHouse':\n",
    "                            removed_nohouse_hits += 1\n",
    "\n",
    "                            hitpoint_list[idx]['ordinalOfHit'] = 1\n",
    "\n",
    "\n",
    "                            # and remove the first order hit\n",
    "                            del hitpoint_list[idx-1]\n",
    "\n",
    "                            idx -= 1 # reset index for safety\n",
    "\n",
    "                        # ----- Body Hits -----\n",
    "                        # check if there is a 1 order Body hit, if yes: replace it with second order hit\n",
    "                        elif hitpoint_list[idx-1]['hitObjectColliderName'] == 'Body':\n",
    "                            # if second order hit is not a body hit, replace first order hit\n",
    "                            if hitpoint_list[idx]['hitObjectColliderName'] != 'Body':\n",
    "                                removed_body_hits += 1\n",
    "\n",
    "                                hitpoint_list[idx]['ordinalOfHit'] = 1 \n",
    "\n",
    "\n",
    "                                # and remove the second order hit\n",
    "                                del hitpoint_list[idx-1]\n",
    "                                idx -= 1 # reset index for safety\n",
    "\n",
    "                            # if second order hit is a body hit, replace first order hit with NoHit\n",
    "                            else:\n",
    "                                removed_body_hits += 1\n",
    "\n",
    "                                # replace the first order hit data\n",
    "                                hitpoint_list[idx-1]['hitObjectColliderName'] = 'NoHit'\n",
    "                                hitpoint_list[idx-1]['hitPointOnObject.x'] = 'NaN'\n",
    "                                hitpoint_list[idx-1]['hitPointOnObject.y'] = 'NaN'\n",
    "                                hitpoint_list[idx-1]['hitPointOnObject.z'] = 'NaN'\n",
    "                                hitpoint_list[idx-1]['hitObjectColliderBoundsCenter.x'] = 'NaN'\n",
    "                                hitpoint_list[idx-1]['hitObjectColliderBoundsCenter.y'] = 'NaN'\n",
    "                                hitpoint_list[idx-1]['hitObjectColliderBoundsCenter.z'] = 'NaN'\n",
    "                                hitpoint_list[idx-1]['transformed_collidercenter_x'] = 'NaN'\n",
    "                                hitpoint_list[idx-1]['transformed_collidercenter_y'] = 'NaN'\n",
    "\n",
    "                                # and remove the second order hit\n",
    "                                del hitpoint_list[idx]\n",
    "\n",
    "\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                # REMOVING REMAINING GRAFFITY AND BODY HITS\n",
    "                for index in range(len(hitpoint_list)):\n",
    "                    if hitpoint_list[index]['hitObjectColliderName'] == 'Body':\n",
    "                        removed_body_hits += 1\n",
    "                        hitpoint_list[index]['hitObjectColliderName'] = 'NoHit'\n",
    "                        hitpoint_list[index]['hitPointOnObject.x'] = 'NaN'\n",
    "                        hitpoint_list[index]['hitPointOnObject.y'] = 'NaN'\n",
    "                        hitpoint_list[index]['hitPointOnObject.z'] = 'NaN'\n",
    "                        hitpoint_list[index]['hitObjectColliderBoundsCenter.x'] = 'NaN'\n",
    "                        hitpoint_list[index]['hitObjectColliderBoundsCenter.y'] = 'NaN'\n",
    "                        hitpoint_list[index]['hitObjectColliderBoundsCenter.z'] = 'NaN'\n",
    "                        hitpoint_list[idx-1]['transformed_collidercenter_x'] = 'NaN'\n",
    "                        hitpoint_list[idx-1]['transformed_collidercenter_y'] = 'NaN'\n",
    "\n",
    "                    # check if there are Graffity Hits and rename them as the building they are on\n",
    "                    if hitpoint_list[index]['hitObjectColliderName'].startswith('Graffity_'):\n",
    "                        building_number = re.search(r'\\d+', hitpoint_list[index]['hitObjectColliderName']).group()\n",
    "                        graffity_to_building = []\n",
    "\n",
    "\n",
    "                        # if the number is between 0 and 9, remove the 0\n",
    "                        building_number = str(int(building_number))\n",
    "\n",
    "                        for house in houselist.keys():\n",
    "                            #check if the exact building number is in the houselist to replace graffity name\n",
    "                            # additionally check that it's not a landmark or a garage to stay\n",
    "                            if house.endswith('_' + building_number) \\\n",
    "                            and house not in landmarks \\\n",
    "                            and house not in garages_to_stay:\n",
    "                                # check if the house name is already in the list\n",
    "                                if house in graffity_to_building:\n",
    "                                    pass\n",
    "                                else:\n",
    "                                    graffity_to_building.append(house)\n",
    "\n",
    "                        if len(graffity_to_building) == 1:\n",
    "                            hitpoint_list[index]['hitObjectColliderName'] = graffity_to_building[0]\n",
    "                            graffity_replaced_count += 1\n",
    "                        else:\n",
    "                            print('Multiple houses with the same number! - Index: ' \n",
    "                                  + str(index)\n",
    "                                  + ', ' \n",
    "                                  + str(graffity_to_building))\n",
    "\n",
    "\n",
    "\n",
    "                # normalize the hitpoint dictionary to get dataframe\n",
    "                hitpoints_df = pd.json_normalize(hitpoint_list)\n",
    "\n",
    "                print(\"\\tEXP: \" \n",
    "                      + str(EXP_session) \n",
    "                      + \", ET: \" + str(s) \n",
    "                      + \" normalized - Length: \" \n",
    "                      + str(len(hitpoints_df)))\n",
    "\n",
    "                complete_hitpoints_df = complete_hitpoints_df.append(hitpoints_df)\n",
    "\n",
    "\n",
    "            \n",
    "            # --------- Saving each Session ---------\n",
    "\n",
    "            # If you want to save each session separately, set 'Session_save_bool' to True\n",
    "            if Session_save_bool == True:\n",
    "                try:\n",
    "                    if len(subject_data) > 0:\n",
    "                        complete_hitpoints_df.to_csv(PROCESSED_DATA_PATH\n",
    "                                                     + str(subject)\n",
    "                                                     + \"_CompleteSession\"\n",
    "                                                     + str(EXP_session)\n",
    "                                                     + \"_Hitpoints.csv\", \n",
    "                                                     index=False)\n",
    "                        print(\"\\t\"\n",
    "                              + str(subject)\n",
    "                              + \" session \"\n",
    "                              + str(EXP_session)\n",
    "                              + \" saved \")\n",
    "                    else: \n",
    "                        print(\"\\t\"\n",
    "                              + str(subject)\n",
    "                              + \" - Session \"\n",
    "                              + str(EXP_session)\n",
    "                              + \" is empty!\")\n",
    "                except:\n",
    "                    print(\"\\tCould not save subject \"\n",
    "                          + str(subject)\n",
    "                          + \" session \"\n",
    "                          + str(EXP_session)\n",
    "                          + \"!\")\n",
    "\n",
    "\n",
    "\n",
    "            # fill the complete exploration dataframe with the separate session data (combining the sessions)\n",
    "            complete_exploration_df = complete_exploration_df.append(complete_hitpoints_df)\n",
    "\n",
    "    # --------- Saving the Exploration ---------\n",
    "\n",
    "        # If you want to save the exploration file, set 'Exploration_save_bool' to True\n",
    "        if Exploration_save_bool == True:\n",
    "            # saving the complete exploration\n",
    "            try:\n",
    "                complete_exploration_df.to_csv(PROCESSED_DATA_PATH \n",
    "                                               + str(subject) \n",
    "                                               + \"_CompleteExploration_Hitpoints.csv\", \n",
    "                                                index=False)\n",
    "\n",
    "                print(\"\\t\" + str(subject) + \" exploration saved\")\n",
    "            except:\n",
    "                print(\"\\tCould not save subject \" + str(subject) + \" exploration data!\")\n",
    "\n",
    "\n",
    "        print(\"\\t\" + str(subject) + \" - Stats: \")\n",
    "        print(\"\\tRemoved Body Hits: \" \n",
    "              + str(removed_body_hits) \n",
    "              + ' Removed Graffities: ' \n",
    "              + str(graffity_replaced_count) \n",
    "              + ' Replaced 1st NoHouse hits: ' \n",
    "              + str(removed_nohouse_hits))\n",
    "\n",
    "\n",
    "        # Some information about the data\n",
    "        bit_prop = np.sum(complete_exploration_df['BitMask'] != 3) \\\n",
    "            / len(complete_exploration_df)\n",
    "        noHit_prop = np.sum(complete_exploration_df['hitObjectColliderName'] == 'NoHit') \\\n",
    "            / len(complete_exploration_df)\n",
    "        noHouse_prop = np.sum(complete_exploration_df['hitObjectColliderName'] == 'NoHouse') \\\n",
    "            / len(complete_exploration_df)\n",
    "\n",
    "        print(\"\\tPortion of insufficient data quality (BitMask): \" \n",
    "              + str(\"{:.2f}\".format(100*bit_prop)) \n",
    "              + '%') \n",
    "        print(\"\\tNoHits: \" \n",
    "              + str(\"{:.2f}\".format(100*noHit_prop)) \n",
    "              + '%')\n",
    "        print(\"\\tNoHouse: \" \n",
    "              + str(\"{:.2f}\".format(100*noHouse_prop)) \n",
    "              + '%')\n",
    "        print(\"\\tTotal missing data: \" \n",
    "              + str(\"{:.2f}\".format(100*(bit_prop + noHit_prop))) \n",
    "              + '%') \n",
    "    \n",
    "    \n",
    "        # fill the subject info dataframe\n",
    "        subject_data_df.loc[subcount-1, 'SubjectID'] = subject\n",
    "        subject_data_df.loc[subcount-1, 'Sessions'] = session_number\n",
    "        subject_data_df.loc[subcount-1, 'ET_Sessions'] = ET_session_number\n",
    "        subject_data_df.loc[subcount-1, 'Total Rows Combined'] = len(complete_exploration_df)\n",
    "        subject_data_df.loc[subcount-1, 'Removed Body Hits'] = removed_body_hits\n",
    "        subject_data_df.loc[subcount-1, 'Removed Graffiti Hits'] = graffity_replaced_count\n",
    "        subject_data_df.loc[subcount-1, 'Replaced NoHouse Hits'] = removed_nohouse_hits\n",
    "        subject_data_df.loc[subcount-1, 'DataLoss BitMask'] = bit_prop\n",
    "        subject_data_df.loc[subcount-1, 'DataLoss NoHits'] = noHit_prop\n",
    "        subject_data_df.loc[subcount-1, 'DataLoss Combined'] = bit_prop + noHit_prop\n",
    "    \n",
    "\n",
    "    \n",
    "    # Else exception if the subject data is not complete\n",
    "    else:\n",
    "        print('Subject ' \n",
    "              + str(subject) \n",
    "              + ' has {} Sessions and {} Eye Tracking Sessions'.format(session_number, ET_session_number) \n",
    "              + '!')\n",
    "\n",
    "# If wanted, save the subject information \n",
    "if Subject_Info_save_bool == True:\n",
    "    try:\n",
    "        subject_data_df.to_csv(PROCESSED_DATA_PATH \n",
    "                                       + \"Subject_Data.csv\", \n",
    "                                        index=False)\n",
    "\n",
    "        print(\"Subject Data saved\")\n",
    "    except:\n",
    "        print(\"Could not save subject data!\")\n",
    "        \n",
    "              \n",
    "              \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source_collider_name</th>\n",
       "      <th>target_collider_name</th>\n",
       "      <th>ColliderBoundsCenter.x</th>\n",
       "      <th>ColliderBoundsCenter.y</th>\n",
       "      <th>ColliderBoundsCenter.z</th>\n",
       "      <th>transformed_collidercenter_x</th>\n",
       "      <th>transformed_collidercenter_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Building_100</td>\n",
       "      <td>Building_100</td>\n",
       "      <td>27.202402</td>\n",
       "      <td>4.637518</td>\n",
       "      <td>66.574875</td>\n",
       "      <td>2160.852245</td>\n",
       "      <td>2321.450565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Building_101</td>\n",
       "      <td>Building_101</td>\n",
       "      <td>29.179993</td>\n",
       "      <td>9.017884</td>\n",
       "      <td>109.739998</td>\n",
       "      <td>2168.810296</td>\n",
       "      <td>2499.573289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Building_102</td>\n",
       "      <td>Building_102</td>\n",
       "      <td>10.699999</td>\n",
       "      <td>9.022681</td>\n",
       "      <td>135.199997</td>\n",
       "      <td>2092.451899</td>\n",
       "      <td>2604.853246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Building_103</td>\n",
       "      <td>Building_103</td>\n",
       "      <td>44.767456</td>\n",
       "      <td>6.790395</td>\n",
       "      <td>161.120209</td>\n",
       "      <td>2232.877085</td>\n",
       "      <td>2711.561031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Building_104</td>\n",
       "      <td>Building_104</td>\n",
       "      <td>148.502731</td>\n",
       "      <td>5.281566</td>\n",
       "      <td>50.124672</td>\n",
       "      <td>2660.648524</td>\n",
       "      <td>2252.769625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>249</td>\n",
       "      <td>crane_1</td>\n",
       "      <td>crane_1</td>\n",
       "      <td>-101.114072</td>\n",
       "      <td>19.279706</td>\n",
       "      <td>-24.529291</td>\n",
       "      <td>1631.882345</td>\n",
       "      <td>1946.305511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>250</td>\n",
       "      <td>crane_2</td>\n",
       "      <td>crane_2</td>\n",
       "      <td>-317.305069</td>\n",
       "      <td>25.279850</td>\n",
       "      <td>-164.529755</td>\n",
       "      <td>739.380449</td>\n",
       "      <td>1369.138826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>251</td>\n",
       "      <td>Building_191</td>\n",
       "      <td>Building_191</td>\n",
       "      <td>-363.551361</td>\n",
       "      <td>3.137159</td>\n",
       "      <td>151.427521</td>\n",
       "      <td>543.725122</td>\n",
       "      <td>2675.546576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>252</td>\n",
       "      <td>Church-TaskBuilding_16</td>\n",
       "      <td>Church-TaskBuilding_16</td>\n",
       "      <td>280.184875</td>\n",
       "      <td>19.870625</td>\n",
       "      <td>-90.926231</td>\n",
       "      <td>3202.008624</td>\n",
       "      <td>1671.525322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>253</td>\n",
       "      <td>Building_combined_115_116</td>\n",
       "      <td>Building_combined_115_116</td>\n",
       "      <td>181.197006</td>\n",
       "      <td>2.886840</td>\n",
       "      <td>-47.747000</td>\n",
       "      <td>2795.310638</td>\n",
       "      <td>1849.466877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>254 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0       source_collider_name       target_collider_name  \\\n",
       "0             0               Building_100               Building_100   \n",
       "1             1               Building_101               Building_101   \n",
       "2             2               Building_102               Building_102   \n",
       "3             3               Building_103               Building_103   \n",
       "4             4               Building_104               Building_104   \n",
       "..          ...                        ...                        ...   \n",
       "249         249                    crane_1                    crane_1   \n",
       "250         250                    crane_2                    crane_2   \n",
       "251         251               Building_191               Building_191   \n",
       "252         252     Church-TaskBuilding_16     Church-TaskBuilding_16   \n",
       "253         253  Building_combined_115_116  Building_combined_115_116   \n",
       "\n",
       "     ColliderBoundsCenter.x  ColliderBoundsCenter.y  ColliderBoundsCenter.z  \\\n",
       "0                 27.202402                4.637518               66.574875   \n",
       "1                 29.179993                9.017884              109.739998   \n",
       "2                 10.699999                9.022681              135.199997   \n",
       "3                 44.767456                6.790395              161.120209   \n",
       "4                148.502731                5.281566               50.124672   \n",
       "..                      ...                     ...                     ...   \n",
       "249             -101.114072               19.279706              -24.529291   \n",
       "250             -317.305069               25.279850             -164.529755   \n",
       "251             -363.551361                3.137159              151.427521   \n",
       "252              280.184875               19.870625              -90.926231   \n",
       "253              181.197006                2.886840              -47.747000   \n",
       "\n",
       "     transformed_collidercenter_x  transformed_collidercenter_y  \n",
       "0                     2160.852245                   2321.450565  \n",
       "1                     2168.810296                   2499.573289  \n",
       "2                     2092.451899                   2604.853246  \n",
       "3                     2232.877085                   2711.561031  \n",
       "4                     2660.648524                   2252.769625  \n",
       "..                            ...                           ...  \n",
       "249                   1631.882345                   1946.305511  \n",
       "250                    739.380449                   1369.138826  \n",
       "251                    543.725122                   2675.546576  \n",
       "252                   3202.008624                   1671.525322  \n",
       "253                   2795.310638                   1849.466877  \n",
       "\n",
       "[254 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houselist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 1005 started - 1/1 subjects\n",
      "\tTotal Sessionfiles: 3 - Exploration Session 1\n",
      "\tEXP: 1, ET: 1 normalized - Length: 112825\n",
      "\tEXP: 1, ET: 2 normalized - Length: 116639\n",
      "\tEXP: 1, ET: 3 normalized - Length: 115089\n",
      "\tTotal Sessionfiles: 3 - Exploration Session 2\n",
      "\tEXP: 2, ET: 1 normalized - Length: 112574\n",
      "\tEXP: 2, ET: 2 normalized - Length: 110534\n",
      "\tEXP: 2, ET: 3 normalized - Length: 113598\n",
      "\tTotal Sessionfiles: 3 - Exploration Session 3\n",
      "\tEXP: 3, ET: 1 normalized - Length: 112756\n",
      "\tEXP: 3, ET: 2 normalized - Length: 116218\n",
      "\tEXP: 3, ET: 3 normalized - Length: 109903\n",
      "\tTotal Sessionfiles: 3 - Exploration Session 4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-a2f751636616>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                             \u001b[0mhitpoint_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hitObjectColliderName'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m                                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollider_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_collider_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                             \u001b[0;31m# change collider coordinates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/graphs/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5138\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5139\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/graphs/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2876\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2877\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2878\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2880\u001b[0m         \u001b[0;31m# Do we have a slicer (on rows)?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/graphs/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   3539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3540\u001b[0m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3541\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3542\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_col_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/graphs/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36miget\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    992\u001b[0m         return SingleBlockManager(\n\u001b[1;32m    993\u001b[0m             block.make_block_same_class(\n\u001b[0;32m--> 994\u001b[0;31m                 \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             ),\n\u001b[1;32m    996\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/graphs/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mmake_block_same_class\u001b[0;34m(self, values, placement, ndim)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/graphs/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim)\u001b[0m\n\u001b[1;32m   2376\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2378\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2380\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/graphs/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_ndim\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m             raise ValueError(\n\u001b[1;32m    131\u001b[0m                 \u001b[0;34mf\"Wrong number of items passed {len(self.values)}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --------- Preparation ---------\n",
    "\n",
    "Session_save_bool = False # set to True if you want to save each individual session as csv\n",
    "Exploration_save_bool = False # set to True if you want to save the complete exploration as csv\n",
    "Subject_Info_save_bool = False # set to True if you want to save the subject data as csv\n",
    "subcount = 0\n",
    "graffity_replaced_count = 0\n",
    "removed_body_hits = 0\n",
    "removed_nohouse_hits = 0\n",
    "\n",
    "landmarks = ['Castle-TaskBuilding_56',\n",
    "             'Church-TaskBuilding_16',\n",
    "             'HighSilo-TaskBuilding_49',\n",
    "             'Windmill-TaskBuilding_10_1',\n",
    "             'crane_1',\n",
    "             'crane_2']\n",
    "\n",
    "garages_to_stay = ['Garage_185', \n",
    "                   'Garage_224', \n",
    "                   'Garage_235',  \n",
    "                   'Garage_86', \n",
    "                   'Garage_98']\n",
    "\n",
    "#garages_to_buildings = ['Garage_26', \n",
    "#                        'Garage_46', \n",
    "#                        'Garage_71', \n",
    "#                        'Garage_72']\n",
    "#\n",
    "#collider_merging = {'building01_LOD0': 'Building_157',\n",
    "#                    'building01_LOD1': 'Building_157',\n",
    "#                    'building02_LOD0': 'Building_171',\n",
    "#                    'Building_115': 'Building_116',\n",
    "#                    'Garage_26' : 'TaskBuilding_26', \n",
    "#                    'Garage_46': 'TaskBuilding_46', \n",
    "#                    'Garage_71': 'Building_71', \n",
    "#                    'Garage_72': 'Building_72'}\n",
    "#\n",
    "\n",
    "# column name list for dataframe\n",
    "col_names =  ['Session',\n",
    "              'timeStampDataPointStart',\n",
    "              'timeStampDataPointEnd',\n",
    "              'hitObjectColliderName', \n",
    "              'ordinalOfHit',\n",
    "              'BitMask',\n",
    "              'hitPointOnObject.x',\n",
    "              'hitPointOnObject.y',\n",
    "              'hitPointOnObject.z',\n",
    "              'hitObjectColliderBoundsCenter.x',\n",
    "              'hitObjectColliderBoundsCenter.y',\n",
    "              'hitObjectColliderBoundsCenter.z',\n",
    "              'transformed_collidercenter_x',\n",
    "              'transformed_collidercenter_y'\n",
    "              'hmdPosition.x',\n",
    "              'hmdPosition.y',\n",
    "              'hmdPosition.z']\n",
    "\n",
    "\n",
    "NoHit_dict = {'hitObjectColliderName': 'NoHit',\n",
    "              'ordinalOfHit': '1'}\n",
    "\n",
    "\n",
    "subject_cols = ['SubjectID',\n",
    "                'Sessions',\n",
    "                'ET_Sessions',\n",
    "                'Total Rows Combined',\n",
    "                'Removed Body Hits', \n",
    "                'Removed Graffiti Hits', \n",
    "                'Replaced NoHouse Hits',\n",
    "                'DataLoss BitMask', \n",
    "                'DataLoss NoHits',\n",
    "                'DataLoss Combined']\n",
    "\n",
    "subject_data_df = pd.DataFrame(columns=subject_cols)\n",
    "\n",
    "\n",
    "# --------------------------- MAIN PART ---------------------------\n",
    "\n",
    "\n",
    "# --------- first layer - subject loop ---------\n",
    "\n",
    "for subject in subIDs:\n",
    "    subcount +=1\n",
    "    print('Subject ' \n",
    "          + str(subject) \n",
    "          + ' started - ' \n",
    "          + str(subcount) \n",
    "          + '/' \n",
    "          + str(len(subIDs)) \n",
    "          + ' subjects')\n",
    "    \n",
    "    # Create empty dataframe for later concatenation\n",
    "    complete_exploration_df = pd.DataFrame(columns = col_names)\n",
    "    \n",
    "    # get the data files according to the subject, ignoring OnQuit files\n",
    "    subject_folder = sorted([f for f in DATA_FOLDER \n",
    "                             if f.startswith(str(subject)+'_Expl_S_') and f.endswith(\"OnQuit.json\") == False], \n",
    "                            key=str.lower) \n",
    "    \n",
    "    # the following works as long as the data name format is as follows:\n",
    "    # 'subjectID'_Expl_S_'SessionNumber'_ET_'EyeTrackingSessionNumber'_'UnixTimestamp'.json\n",
    "    folder_files = list()\n",
    "       \n",
    "    # loop through the subject folder and save all numbers\n",
    "    for file in subject_folder:\n",
    "        folder_files.append(re.findall(r'\\d+', file))\n",
    "    \n",
    "    # Extract all SubIDs (only one), SessionNumbers, ET_SessionNumbers (and Timestamps)\n",
    "    try:\n",
    "        SubID, SessionNumbers, ET_SessionNumbers, UnixTimestamp1, UnixTimeStamp2 = map(list, zip(*folder_files))\n",
    "    except:\n",
    "        print('\\tSubject ' \n",
    "              + str(subject)\n",
    "              + ' Filename is not valid!')\n",
    "    \n",
    "    session_number = int(max(SessionNumbers)) # the maximum session number of the particular subject\n",
    "    ET_session_number = int(max(ET_SessionNumbers)) # the maximum ET session number of the particular subject\n",
    "    \n",
    "    \n",
    "    # only continue if there are 15 files, aka 5 exploration sessions with 3 ET Sessions each \n",
    "    \n",
    "    if session_number == 5: #and ET_session_number == 3:\n",
    "    \n",
    "# --------- second layer - exploration session loop ---------\n",
    "\n",
    "        # loop over exploration sessions\n",
    "        for EXP_session in range(session_number):\n",
    "            # to avoid start at 0\n",
    "            EXP_session +=1 \n",
    "\n",
    "            # extract the exploration data\n",
    "            subject_data = sorted([f for f in DATA_FOLDER if f.startswith(str(subject) + '_Expl_S_' + str(EXP_session)) \n",
    "                                   and f.endswith(\"OnQuit.json\") == False], key=str.lower)\n",
    "\n",
    "\n",
    "            # hitpoint dataframe \n",
    "            complete_hitpoints_df = pd.DataFrame(columns = col_names)\n",
    "\n",
    "            print(\"\\tTotal Sessionfiles: \"\n",
    "                  + str(len(subject_data))\n",
    "                  + \" - Exploration Session \"\n",
    "                  + str(EXP_session))\n",
    "\n",
    "            s = 0 # session count\n",
    "\n",
    "    # --------- third layer - eye tracking session loop ---------\n",
    "\n",
    "            # loop over separate eye tracking sessions\n",
    "            for ET_session in subject_data:\n",
    "                s+=1\n",
    "\n",
    "                # open the JSON file as dictionary\n",
    "                with open(DATA_PATH + ET_session) as f:\n",
    "                    try:\n",
    "                        subject_session = json.loads(f.read())\n",
    "                    except:\n",
    "                        print(\"\\tJSON file \" + ET_session + \" is not valid!\")\n",
    "\n",
    "                hitpoints_df = pd.DataFrame(columns = col_names)\n",
    "                hitpoint_list = list() # create hitpoint list\n",
    "\n",
    "                # start timestamp of the session \n",
    "                start_time = subject_session['trials'][0]['timeTrialMeasurementStarted']\n",
    "\n",
    "                # amount of datapoints \n",
    "                Len_subses = len(subject_session['trials'][0]['dataPoints'])\n",
    "\n",
    "                # for loop appending each data point rayCastHit Data\n",
    "                # afterwards adding the timestamp to the dict \n",
    "                # if there is (1) no raycast hit appending NoHit Dict\n",
    "\n",
    "                # --------------- First order hits! ---------------\n",
    "                for each in subject_session['trials'][0]['dataPoints']:\n",
    "\n",
    "                    # ----- account for noHits ----- \n",
    "                    if each['rayCastHitsCombinedEyes'] == []:\n",
    "                        hitpoint_list.append(NoHit_dict)\n",
    "                        # set index for new entry\n",
    "                        idx = len(hitpoint_list)-1\n",
    "                        hitpoint_list[idx]['Session'] = EXP_session\n",
    "                        hitpoint_list[idx]['timeStampDataPointStart'] = each['timeStampDataPointStart'] - start_time\n",
    "                        hitpoint_list[idx]['timeStampDataPointEnd'] = each['timeStampDataPointEnd'] - start_time\n",
    "                        hitpoint_list[idx]['BitMask'] = each['combinedGazeValidityBitmask']\n",
    "                        # hmdPosition\n",
    "                        hitpoint_list[idx]['hmdPosition.x'] = each['hmdPosition']['x']\n",
    "                        hitpoint_list[idx]['hmdPosition.y'] = each['hmdPosition']['y']\n",
    "                        hitpoint_list[idx]['hmdPosition.z'] = each['hmdPosition']['z']\n",
    "\n",
    "                    else: \n",
    "                        # ----- append data point -----\n",
    "                        hitpoint_list.append(each['rayCastHitsCombinedEyes'][0])\n",
    "                        # set index for new entry\n",
    "                        idx = len(hitpoint_list)-1\n",
    "                        \n",
    "                        current_collider = hitpoint_list[idx]['hitObjectColliderName']\n",
    "\n",
    "                        # add new coordinates\n",
    "                        \n",
    "                        # add Session, timestamp and bitmask\n",
    "                        hitpoint_list[idx]['Session'] = EXP_session\n",
    "                        hitpoint_list[idx]['timeStampDataPointStart'] = each['timeStampDataPointStart'] - start_time\n",
    "                        hitpoint_list[idx]['timeStampDataPointEnd'] = each['timeStampDataPointEnd'] - start_time\n",
    "                        hitpoint_list[idx]['BitMask'] = each['combinedGazeValidityBitmask']  \n",
    "                        # hmdPosition\n",
    "                        hitpoint_list[idx]['hmdPosition.x'] = each['hmdPosition']['x']\n",
    "                        hitpoint_list[idx]['hmdPosition.y'] = each['hmdPosition']['y']\n",
    "                        hitpoint_list[idx]['hmdPosition.z'] = each['hmdPosition']['z']\n",
    "\n",
    "                        \n",
    "                        # ----- CONDITIONS FOR CLEANING -----\n",
    "                        \n",
    "                        # ----- Merging obsolete colliders -----\n",
    "                        if current_collider in list(houselist.source_collider_name):\n",
    "    \n",
    "                            collider_data = houselist[houselist.source_collider_name==current_collider]\n",
    "\n",
    "                            \n",
    "                            hitpoint_list[idx]['hitObjectColliderName'] = \\\n",
    "                                list(collider_data.target_collider_name)[0]\n",
    "                            \n",
    "                            # change collider coordinates\n",
    "                            hitpoint_list[idx]['hitObjectColliderBoundsCenter.x'] = \\\n",
    "                                list(collider_data['ColliderBoundsCenter.x'])[0]\n",
    "                            hitpoint_list[idx]['hitObjectColliderBoundsCenter.y'] = \\\n",
    "                                list(collider_data['ColliderBoundsCenter.y'])[0]\n",
    "                            hitpoint_list[idx]['hitObjectColliderBoundsCenter.z'] = \\\n",
    "                                list(collider_data['ColliderBoundsCenter.z'])[0]    \n",
    "                            hitpoint_list[idx]['transformed_collidercenter_x'] = \\\n",
    "                                list(collider_data['transformed_collidercenter_x'])[0]\n",
    "                            hitpoint_list[idx]['transformed_collidercenter_y'] = \\\n",
    "                                list(collider_data['transformed_collidercenter_y'])[0]\n",
    "\n",
    "                        # ----- NoHouse Hits -----\n",
    "                        # check if the collider name is a member of the houselist - if not: rename to NoHouse \n",
    "                        elif current_collider not in list(houselist.source_collider_name) \\\n",
    "                        and current_collider != 'Body' \\\n",
    "                        and (current_collider.startswith('Graffity_')) == False:\n",
    "                            hitpoint_list[idx]['hitObjectColliderName'] = 'NoHouse'\n",
    "                            \n",
    "                        else:\n",
    "                            try:\n",
    "                                hitpoint_list[idx]['hitObjectColliderBoundsCenter.x'] = \\\n",
    "                                    list(collider_data['ColliderBoundsCenter.x'])[0]\n",
    "                                hitpoint_list[idx]['hitObjectColliderBoundsCenter.y'] = \\\n",
    "                                    list(collider_data['ColliderBoundsCenter.y'])[0]\n",
    "                                hitpoint_list[idx]['hitObjectColliderBoundsCenter.z'] = \\\n",
    "                                    list(collider_data['ColliderBoundsCenter.z'])[0]   \n",
    "                                hitpoint_list[idx]['transformed_collidercenter_x'] = \\\n",
    "                                    list(collider_data['transformed_collidercenter_x'])[0]\n",
    "                                hitpoint_list[idx]['transformed_collidercenter_y'] = \\\n",
    "                                    list(collider_data['transformed_collidercenter_y'])[0]\n",
    "                            except:\n",
    "                                pass\n",
    "\n",
    "\n",
    "             # --------------- Second order hits! ---------------\n",
    "                    # redo if there is a second ordinal hit\n",
    "                    try: \n",
    "                        # append data point of second raycast hit if it exists\n",
    "                        hitpoint_list.append(each['rayCastHitsCombinedEyes'][1])\n",
    "                        # set index for new entry\n",
    "                        idx = len(hitpoint_list)-1\n",
    "                        \n",
    "                        current_collider = hitpoint_list[idx]['hitObjectColliderName']\n",
    "\n",
    "                        # add Session, timestamp and bitmask\n",
    "                        hitpoint_list[idx]['Session'] = EXP_session\n",
    "                        hitpoint_list[idx]['timeStampDataPointStart'] = each['timeStampDataPointStart'] - start_time\n",
    "                        hitpoint_list[idx]['timeStampDataPointEnd'] = each['timeStampDataPointEnd'] - start_time\n",
    "                        hitpoint_list[idx]['BitMask'] = each['combinedGazeValidityBitmask']\n",
    "\n",
    "                        # check for different conditions:\n",
    "                        \n",
    "                                                \n",
    "                        # ----- Merging obsolete colliders -----\n",
    "                        if current_collider in list(houselist.source_collider_name):\n",
    "    \n",
    "                            collider_data = houselist[houselist.source_collider_name==current_collider]\n",
    "\n",
    "                            \n",
    "                            hitpoint_list[idx]['hitObjectColliderName'] = \\\n",
    "                                list(collider_data.target_collider_name)[0]\n",
    "                            \n",
    "                            # change collider coordinates\n",
    "                            hitpoint_list[idx]['hitObjectColliderBoundsCenter.x'] = \\\n",
    "                                list(collider_data['ColliderBoundsCenter.x'])[0]\n",
    "                            hitpoint_list[idx]['hitObjectColliderBoundsCenter.y'] = \\\n",
    "                                list(collider_data['ColliderBoundsCenter.y'])[0]\n",
    "                            hitpoint_list[idx]['hitObjectColliderBoundsCenter.z'] = \\\n",
    "                                list(collider_data['ColliderBoundsCenter.z'])[0]    \n",
    "                            hitpoint_list[idx]['transformed_collidercenter_x'] = \\\n",
    "                                list(collider_data['transformed_collidercenter_x'])[0]\n",
    "                            hitpoint_list[idx]['transformed_collidercenter_y'] = \\\n",
    "                                list(collider_data['transformed_collidercenter_y'])[0]\n",
    "\n",
    "                        # ----- NoHouse Hits -----\n",
    "                        # check if the collider name is a member of the houselist - if not: rename to NoHouse \n",
    "                        elif current_collider not in list(houselist.source_collider_name) \\\n",
    "                        and current_collider != 'Body' \\\n",
    "                        and (current_collider.startswith('Graffity_')) == False:\n",
    "                            hitpoint_list[idx]['hitObjectColliderName'] = 'NoHouse'\n",
    "                            \n",
    "                        else:\n",
    "                            try:\n",
    "                                hitpoint_list[idx]['hitObjectColliderBoundsCenter.x'] = \\\n",
    "                                    list(collider_data['ColliderBoundsCenter.x'])[0]\n",
    "                                hitpoint_list[idx]['hitObjectColliderBoundsCenter.y'] = \\\n",
    "                                    list(collider_data['ColliderBoundsCenter.y'])[0]\n",
    "                                hitpoint_list[idx]['hitObjectColliderBoundsCenter.z'] = \\\n",
    "                                    list(collider_data['ColliderBoundsCenter.z'])[0]   \n",
    "                                hitpoint_list[idx]['transformed_collidercenter_x'] = \\\n",
    "                                    list(collider_data['transformed_collidercenter_x'])[0]\n",
    "                                hitpoint_list[idx]['transformed_collidercenter_y'] = \\\n",
    "                                    list(collider_data['transformed_collidercenter_y'])[0]\n",
    "                            except:\n",
    "                                pass\n",
    "                            \n",
    "                        # if the first order hit was a NoHouse hit, but the second was not\n",
    "                        if hitpoint_list[idx-1]['hitObjectColliderName'] == 'NoHouse' \\\n",
    "                        and hitpoint_list[idx]['hitObjectColliderName'] != 'NoHouse':\n",
    "                            removed_nohouse_hits += 1\n",
    "\n",
    "                            hitpoint_list[idx]['ordinalOfHit'] = 1\n",
    "\n",
    "\n",
    "                            # and remove the first order hit\n",
    "                            del hitpoint_list[idx-1]\n",
    "\n",
    "                            idx -= 1 # reset index for safety\n",
    "\n",
    "                        # ----- Body Hits -----\n",
    "                        # check if there is a 1 order Body hit, if yes: replace it with second order hit\n",
    "                        elif hitpoint_list[idx-1]['hitObjectColliderName'] == 'Body':\n",
    "                            # if second order hit is not a body hit, replace first order hit\n",
    "                            if hitpoint_list[idx]['hitObjectColliderName'] != 'Body':\n",
    "                                removed_body_hits += 1\n",
    "\n",
    "                                hitpoint_list[idx]['ordinalOfHit'] = 1 \n",
    "\n",
    "\n",
    "                                # and remove the second order hit\n",
    "                                del hitpoint_list[idx-1]\n",
    "                                idx -= 1 # reset index for safety\n",
    "\n",
    "                            # if second order hit is a body hit, replace first order hit with NoHit\n",
    "                            else:\n",
    "                                removed_body_hits += 1\n",
    "\n",
    "                                # replace the first order hit data\n",
    "                                hitpoint_list[idx-1]['hitObjectColliderName'] = 'NoHit'\n",
    "                                hitpoint_list[idx-1]['hitPointOnObject.x'] = 'NaN'\n",
    "                                hitpoint_list[idx-1]['hitPointOnObject.y'] = 'NaN'\n",
    "                                hitpoint_list[idx-1]['hitPointOnObject.z'] = 'NaN'\n",
    "                                hitpoint_list[idx-1]['hitObjectColliderBoundsCenter.x'] = 'NaN'\n",
    "                                hitpoint_list[idx-1]['hitObjectColliderBoundsCenter.y'] = 'NaN'\n",
    "                                hitpoint_list[idx-1]['hitObjectColliderBoundsCenter.z'] = 'NaN'\n",
    "                                hitpoint_list[idx-1]['transformed_collidercenter_x'] = 'NaN'\n",
    "                                hitpoint_list[idx-1]['transformed_collidercenter_y'] = 'NaN'\n",
    "\n",
    "                                # and remove the second order hit\n",
    "                                del hitpoint_list[idx]\n",
    "\n",
    "\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                # REMOVING REMAINING GRAFFITY AND BODY HITS\n",
    "                for index in range(len(hitpoint_list)):\n",
    "                    if hitpoint_list[index]['hitObjectColliderName'] == 'Body':\n",
    "                        removed_body_hits += 1\n",
    "                        hitpoint_list[index]['hitObjectColliderName'] = 'NoHit'\n",
    "                        hitpoint_list[index]['hitPointOnObject.x'] = 'NaN'\n",
    "                        hitpoint_list[index]['hitPointOnObject.y'] = 'NaN'\n",
    "                        hitpoint_list[index]['hitPointOnObject.z'] = 'NaN'\n",
    "                        hitpoint_list[index]['hitObjectColliderBoundsCenter.x'] = 'NaN'\n",
    "                        hitpoint_list[index]['hitObjectColliderBoundsCenter.y'] = 'NaN'\n",
    "                        hitpoint_list[index]['hitObjectColliderBoundsCenter.z'] = 'NaN'\n",
    "                        hitpoint_list[idx-1]['transformed_collidercenter_x'] = 'NaN'\n",
    "                        hitpoint_list[idx-1]['transformed_collidercenter_y'] = 'NaN'\n",
    "\n",
    "                    # check if there are Graffity Hits and rename them as the building they are on\n",
    "                    if hitpoint_list[index]['hitObjectColliderName'].startswith('Graffity_'):\n",
    "                        building_number = re.search(r'\\d+', hitpoint_list[index]['hitObjectColliderName']).group()\n",
    "                        graffity_to_building = []\n",
    "\n",
    "\n",
    "                        # if the number is between 0 and 9, remove the 0\n",
    "                        building_number = str(int(building_number))\n",
    "\n",
    "                        for house in list(houselist.target_collider_name):\n",
    "                            #check if the exact building number is in the houselist to replace graffity name\n",
    "                            # additionally check that it's not a landmark or a garage to stay\n",
    "                            if house.endswith('_' + building_number) \\\n",
    "                            and house not in landmarks \\\n",
    "                            and house not in garages_to_stay:\n",
    "                                # check if the house name is already in the list\n",
    "                                if house in graffity_to_building:\n",
    "                                    pass\n",
    "                                else:\n",
    "                                    graffity_to_building.append(house)\n",
    "\n",
    "                        if len(graffity_to_building) == 1:\n",
    "                            hitpoint_list[index]['hitObjectColliderName'] = graffity_to_building[0]\n",
    "                            graffity_replaced_count += 1\n",
    "                        else:\n",
    "                            print('Multiple houses with the same number! - Index: ' \n",
    "                                  + str(index)\n",
    "                                  + ', ' \n",
    "                                  + str(graffity_to_building))\n",
    "\n",
    "\n",
    "\n",
    "                # normalize the hitpoint dictionary to get dataframe\n",
    "                hitpoints_df = pd.json_normalize(hitpoint_list)\n",
    "\n",
    "                print(\"\\tEXP: \" \n",
    "                      + str(EXP_session) \n",
    "                      + \", ET: \" + str(s) \n",
    "                      + \" normalized - Length: \" \n",
    "                      + str(len(hitpoints_df)))\n",
    "\n",
    "                complete_hitpoints_df = complete_hitpoints_df.append(hitpoints_df)\n",
    "\n",
    "\n",
    "            \n",
    "            # --------- Saving each Session ---------\n",
    "\n",
    "            # If you want to save each session separately, set 'Session_save_bool' to True\n",
    "            if Session_save_bool == True:\n",
    "                try:\n",
    "                    if len(subject_data) > 0:\n",
    "                        complete_hitpoints_df.to_csv(PROCESSED_DATA_PATH\n",
    "                                                     + str(subject)\n",
    "                                                     + \"_CompleteSession\"\n",
    "                                                     + str(EXP_session)\n",
    "                                                     + \"_Hitpoints.csv\", \n",
    "                                                     index=False)\n",
    "                        print(\"\\t\"\n",
    "                              + str(subject)\n",
    "                              + \" session \"\n",
    "                              + str(EXP_session)\n",
    "                              + \" saved \")\n",
    "                    else: \n",
    "                        print(\"\\t\"\n",
    "                              + str(subject)\n",
    "                              + \" - Session \"\n",
    "                              + str(EXP_session)\n",
    "                              + \" is empty!\")\n",
    "                except:\n",
    "                    print(\"\\tCould not save subject \"\n",
    "                          + str(subject)\n",
    "                          + \" session \"\n",
    "                          + str(EXP_session)\n",
    "                          + \"!\")\n",
    "\n",
    "\n",
    "\n",
    "            # fill the complete exploration dataframe with the separate session data (combining the sessions)\n",
    "            complete_exploration_df = complete_exploration_df.append(complete_hitpoints_df)\n",
    "\n",
    "    # --------- Saving the Exploration ---------\n",
    "\n",
    "        # If you want to save the exploration file, set 'Exploration_save_bool' to True\n",
    "        if Exploration_save_bool == True:\n",
    "            # saving the complete exploration\n",
    "            try:\n",
    "                complete_exploration_df.to_csv(PROCESSED_DATA_PATH \n",
    "                                               + str(subject) \n",
    "                                               + \"_CompleteExploration_Hitpoints.csv\", \n",
    "                                                index=False)\n",
    "\n",
    "                print(\"\\t\" + str(subject) + \" exploration saved\")\n",
    "            except:\n",
    "                print(\"\\tCould not save subject \" + str(subject) + \" exploration data!\")\n",
    "\n",
    "\n",
    "        print(\"\\t\" + str(subject) + \" - Stats: \")\n",
    "        print(\"\\tRemoved Body Hits: \" \n",
    "              + str(removed_body_hits) \n",
    "              + ' Removed Graffities: ' \n",
    "              + str(graffity_replaced_count) \n",
    "              + ' Replaced 1st NoHouse hits: ' \n",
    "              + str(removed_nohouse_hits))\n",
    "\n",
    "\n",
    "        # Some information about the data\n",
    "        bit_prop = np.sum(complete_exploration_df['BitMask'] != 3) \\\n",
    "            / len(complete_exploration_df)\n",
    "        noHit_prop = np.sum(complete_exploration_df['hitObjectColliderName'] == 'NoHit') \\\n",
    "            / len(complete_exploration_df)\n",
    "        noHouse_prop = np.sum(complete_exploration_df['hitObjectColliderName'] == 'NoHouse') \\\n",
    "            / len(complete_exploration_df)\n",
    "\n",
    "        print(\"\\tPortion of insufficient data quality (BitMask): \" \n",
    "              + str(\"{:.2f}\".format(100*bit_prop)) \n",
    "              + '%') \n",
    "        print(\"\\tNoHits: \" \n",
    "              + str(\"{:.2f}\".format(100*noHit_prop)) \n",
    "              + '%')\n",
    "        print(\"\\tNoHouse: \" \n",
    "              + str(\"{:.2f}\".format(100*noHouse_prop)) \n",
    "              + '%')\n",
    "        print(\"\\tTotal missing data: \" \n",
    "              + str(\"{:.2f}\".format(100*(bit_prop + noHit_prop))) \n",
    "              + '%') \n",
    "    \n",
    "    \n",
    "        # fill the subject info dataframe\n",
    "        subject_data_df.loc[subcount-1, 'SubjectID'] = subject\n",
    "        subject_data_df.loc[subcount-1, 'Sessions'] = session_number\n",
    "        subject_data_df.loc[subcount-1, 'ET_Sessions'] = ET_session_number\n",
    "        subject_data_df.loc[subcount-1, 'Total Rows Combined'] = len(complete_exploration_df)\n",
    "        subject_data_df.loc[subcount-1, 'Removed Body Hits'] = removed_body_hits\n",
    "        subject_data_df.loc[subcount-1, 'Removed Graffiti Hits'] = graffity_replaced_count\n",
    "        subject_data_df.loc[subcount-1, 'Replaced NoHouse Hits'] = removed_nohouse_hits\n",
    "        subject_data_df.loc[subcount-1, 'DataLoss BitMask'] = bit_prop\n",
    "        subject_data_df.loc[subcount-1, 'DataLoss NoHits'] = noHit_prop\n",
    "        subject_data_df.loc[subcount-1, 'DataLoss Combined'] = bit_prop + noHit_prop\n",
    "    \n",
    "\n",
    "    \n",
    "    # Else exception if the subject data is not complete\n",
    "    else:\n",
    "        print('Subject ' \n",
    "              + str(subject) \n",
    "              + ' has {} Sessions and {} Eye Tracking Sessions'.format(session_number, ET_session_number) \n",
    "              + '!')\n",
    "\n",
    "# If wanted, save the subject information \n",
    "if Subject_Info_save_bool == True:\n",
    "    try:\n",
    "        subject_data_df.to_csv(PROCESSED_DATA_PATH \n",
    "                                       + \"Subject_Data.csv\", \n",
    "                                        index=False)\n",
    "\n",
    "        print(\"Subject Data saved\")\n",
    "    except:\n",
    "        print(\"Could not save subject data!\")\n",
    "        \n",
    "              \n",
    "              \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Session</th>\n",
       "      <th>timeStampDataPointStart</th>\n",
       "      <th>timeStampDataPointEnd</th>\n",
       "      <th>hitObjectColliderName</th>\n",
       "      <th>ordinalOfHit</th>\n",
       "      <th>BitMask</th>\n",
       "      <th>hitPointOnObject.x</th>\n",
       "      <th>hitPointOnObject.y</th>\n",
       "      <th>hitPointOnObject.z</th>\n",
       "      <th>hitObjectColliderBoundsCenter.x</th>\n",
       "      <th>hitObjectColliderBoundsCenter.y</th>\n",
       "      <th>hitObjectColliderBoundsCenter.z</th>\n",
       "      <th>transformed_collidercenter_x</th>\n",
       "      <th>transformed_collidercenter_yhmdPosition.x</th>\n",
       "      <th>hmdPosition.y</th>\n",
       "      <th>hmdPosition.z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Session, timeStampDataPointStart, timeStampDataPointEnd, hitObjectColliderName, ordinalOfHit, BitMask, hitPointOnObject.x, hitPointOnObject.y, hitPointOnObject.z, hitObjectColliderBoundsCenter.x, hitObjectColliderBoundsCenter.y, hitObjectColliderBoundsCenter.z, transformed_collidercenter_x, transformed_collidercenter_yhmdPosition.x, hmdPosition.y, hmdPosition.z]\n",
       "Index: []"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hitpoints_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'hitPointOnObject': {'x': -63.77029800415039,\n",
       "   'y': 1.750000238418579,\n",
       "   'z': 43.977806091308594},\n",
       "  'hitObjectColliderName': 218    TaskBuilding_35\n",
       "  Name: target_collider_name, dtype: object,\n",
       "  'hitObjectColliderBoundsCenter': {'x': -72.5422592163086,\n",
       "   'y': 6.850490093231201,\n",
       "   'z': 53.217681884765625},\n",
       "  'ordinalOfHit': 1,\n",
       "  'Session': 1,\n",
       "  'timeStampDataPointStart': 0.0024797916412353516,\n",
       "  'timeStampDataPointEnd': 0.00942373275756836,\n",
       "  'BitMask': 3,\n",
       "  'hmdPosition.x': -59.17207336425781,\n",
       "  'hmdPosition.y': 2.448460578918457,\n",
       "  'hmdPosition.z': 34.78295135498047}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hitpoint_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_collider = 'Building_100'\n",
    "\n",
    "if current_collider in list(houselist.source_collider_name):\n",
    "    \n",
    "    collider_data = houselist[houselist.source_collider_name==current_collider]\n",
    "    \n",
    "    collider_data.target_collider_name[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condense the data and create gaze lists\n",
    "* Do Runlength Encoding on the colliderName column to reduce the data size\n",
    "\n",
    "### Interpolation of the data to minimize cut clustering (based on Walter, 2021)\n",
    "* Interpolation criteria:\n",
    "    * there are <=21 consecutive NoHit Samples\n",
    "    * they are surrounded by two clusters on the same collider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 1005 started - 1/1\n",
      "\tInterpolation successful! - Removed rows: 5112, 9.4%\n",
      "\t1005 dataframe saved\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-2e88af21b9d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;31m# fill the subject data df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m     \u001b[0msub_loc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubject_data_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubject_data_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SubjectID'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msubject\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m     \u001b[0msubject_data_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msub_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Condensed Size\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterpolated_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0msubject_data_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msub_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Removed rows\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremoved_hits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/graphs/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4099\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4101\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# --------- Preparation ---------\n",
    "RLE_save_bool = False # if you want to save the condensed dataframe\n",
    "Interpolation_save_bool = True # if you want to save the condensed dataframe\n",
    "Subject_Info_save_bool = False # set to True if you want to save the subject data as csv\n",
    "\n",
    "# column names for the condensed df\n",
    "condense_col_names = ['Session', \n",
    "                      'ColliderName',\n",
    "                      'Samples',]\n",
    "\n",
    "# column names for the interpolation df\n",
    "interpol_col_names = ['ColliderName',\n",
    "                      'Samples',\n",
    "                      'Index']\n",
    "\n",
    "subcount = 0 # count subjects\n",
    "\n",
    "\n",
    "# open the subject data csv\n",
    "with open(THEORETICAL_PROCESSED_DATA_PATH + \"Subject_Data.csv\") as f:\n",
    "    try:\n",
    "        subject_data_df = pd.read_csv(f)\n",
    "    except:\n",
    "        print(\"Subject Data file could not be loaded!\")\n",
    "\n",
    "\n",
    "\n",
    "# --------- MAIN PART ---------\n",
    "# load the files \n",
    "for subject in subIDs:\n",
    "    subcount +=1\n",
    "    print('Subject ' + str(subject) + ' started - ' + str(subcount) + '/' + str(len(subIDs)))\n",
    "    \n",
    "    # get the data files according to the subject\n",
    "    subject_folder = sorted([f for f in PROCESSED_DATA_FOLDER \n",
    "                             if f.startswith(str(subject)+'_CompleteExploration_Hitpoints')], key=str.lower)\n",
    "    \n",
    "    if len(subject_folder) != 0:\n",
    "    \n",
    "        # open the JSON file as dictionary\n",
    "        with open(PROCESSED_DATA_PATH + subject_folder[0]) as f:\n",
    "            try:\n",
    "                data = pd.read_csv(f)\n",
    "            except:\n",
    "                print(\"\\tCSV file \" + subject_folder[0] + \" is not valid!\")\n",
    "    else:\n",
    "        print('Subject ' + str(subject) + 'has no data file!')\n",
    "        continue \n",
    "           \n",
    "    data = data[data.ordinalOfHit==1]\n",
    "    data.reset_index(inplace=True, drop=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # --------- CONDENSE PART ---------\n",
    "    # dataframe for counting successive appearances\n",
    "    condense_df = pd.DataFrame(index=range(len(data)), columns=condense_col_names)\n",
    "    condense_df.Session = data.Session\n",
    "    condense_df.ColliderName = data.hitObjectColliderName\n",
    "    # count successive appearances by comparing with shifted df + cumsum + cumcount\n",
    "    condense_df['Samples'] = \\\n",
    "    data['hitObjectColliderName'].groupby((data['hitObjectColliderName'] \n",
    "                                           != data['hitObjectColliderName'].shift()).cumsum()).cumcount() + 1\n",
    "\n",
    "    \n",
    "    # use the condense_df to sum up unique countings\n",
    "    condense_count = (data['hitObjectColliderName'] != data['hitObjectColliderName'].shift()).cumsum()\n",
    "    ColliderNames_df = pd.DataFrame()\n",
    "    Samples_df = pd.DataFrame()\n",
    "\n",
    "    # find the respective collidername by searching for the first (and possibly only) appearance\n",
    "    ColliderNames_df['ColliderName'] = condense_df[condense_df.Samples==1].ColliderName\n",
    "    ColliderNames_df.reset_index(inplace=True, drop=True)\n",
    "    # count the actual successive appearances by grouping by the unique countings in condense_count\n",
    "    Samples_df['Samples'] = condense_df.groupby(condense_count).ColliderName.count()\n",
    "    Samples_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    \n",
    "    # join the Dataframes \n",
    "    condense_RLE_df = ColliderNames_df.join(Samples_df)\n",
    "    \n",
    "    \n",
    "    # --------- INTERPOLATION PART ---------\n",
    "    condense_data = condense_RLE_df.copy() #copy for safety\n",
    "    \n",
    "    current_collider = 'X' # the reference collidername for interpolation\n",
    "    last_hits = 0 # the reference hit sum for interpolation \n",
    "    \n",
    "    interpolated_data = pd.DataFrame(columns=interpol_col_names) # create empty df for interpolation\n",
    "    \n",
    "    # loop through the condense dataframe and search for the following conditions:\n",
    "    # 1. ColliderName is 'NoHit' and the Sample Size is <=21: add the sample size to the sample variable\n",
    "    # 2. ColliderName is 'NoHit' and the Sample Size is >21: append the NoHit Row to the new Interpolation df\n",
    "    # 3. ColliderName is NOT the current collider: append the Row to the new Interpolation df \n",
    "    #    and set to current collider\n",
    "    # 4. ColliderName IS the current collider: add the sample size to the collider row in the interpolation df\n",
    "    \n",
    "    for index, collider in enumerate(condense_data.ColliderName):\n",
    "        print(\"\\tInterpolation Status: \" + str(\"{:.1f}\".format(100*index/len(condense_data))) + '%', end=\"\\r\")\n",
    "\n",
    "        if collider == 'NoHit': # we need to check also for the current collidername \n",
    "            if condense_data.Samples[index] <= 21:\n",
    "                last_hits += condense_data.Samples[index]\n",
    "            else:\n",
    "                interpolated_data = interpolated_data.append(condense_data.iloc[[index]], ignore_index=True)\n",
    "                interpolated_data.loc[len(interpolated_data)-1, 'Index'] = index\n",
    "                last_hits = 0\n",
    "                current_collider = 'X'\n",
    "\n",
    "        elif collider != current_collider:\n",
    "            if last_hits > 0:\n",
    "                interpolated_data = interpolated_data.append({'ColliderName': 'NoHit',\\\n",
    "                                                              'Samples': last_hits,\\\n",
    "                                                              'Index': index-1}, \\\n",
    "                                                              ignore_index=True)\n",
    "                \n",
    "                \n",
    "            interpolated_data = interpolated_data.append(condense_data.iloc[[index]], ignore_index=True)\n",
    "            interpolated_data.loc[len(interpolated_data)-1, 'Index'] = index\n",
    "            last_hits = 0\n",
    "            current_collider = condense_data.ColliderName[index]\n",
    "        else:\n",
    "            interpolated_data.loc[len(interpolated_data)-1, 'Samples'] += last_hits + condense_data.Samples[index]\n",
    "            last_hits = 0\n",
    "\n",
    "    \n",
    "    removed_hits = len(condense_data) - len(interpolated_data)\n",
    "    prop = removed_hits/len(condense_data)\n",
    "    \n",
    "    \n",
    "    if removed_hits != len(condense_data):\n",
    "        print(\"\\tInterpolation successful! - Removed rows: \" \n",
    "              + str(removed_hits) \n",
    "              + ', ' \n",
    "              + str(\"{:.1f}\".format(100*prop))\n",
    "              + '%')\n",
    "    else:\n",
    "        print('Something went wrong with the interpolation')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # --------- SAVING ---------\n",
    "    # If you want to save the exploration file, set 'RLE_save_bool' to True\n",
    "    if RLE_save_bool == True:\n",
    "        # saving the condensed dataframe\n",
    "        try:\n",
    "            condense_RLE_df.to_csv(THEORETICAL_PROCESSED_DATA_PATH \n",
    "                                           + str(subject) \n",
    "                                           + \"_condense_RLE_df.csv\", \n",
    "                                            index=False)\n",
    "            \n",
    "            print(\"\\t\" + str(subject) + \" dataframe saved\")\n",
    "        except:\n",
    "            print(\"\\tCould not save subject \" + str(subject) + \" condensed dataframe!\")\n",
    "            \n",
    "    if Interpolation_save_bool == True:\n",
    "        # saving the interpolation dataframe\n",
    "        try:\n",
    "            interpolated_data.to_csv(THEORETICAL_PROCESSED_DATA_PATH \n",
    "                                           + str(subject) \n",
    "                                           + \"_interpolation_df.csv\", \n",
    "                                            index=False)\n",
    "            \n",
    "            print(\"\\t\" + str(subject) + \" dataframe saved\")\n",
    "        except:\n",
    "            print(\"\\tCould not save subject \" + str(subject) + \" interpolation dataframe!\")\n",
    "            \n",
    "    \n",
    "    # fill the subject data df\n",
    "    sub_loc = subject_data_df[subject_data_df['SubjectID'] == subject].index[0]\n",
    "    subject_data_df.loc[sub_loc, \"Condensed Size\"] = len(interpolated_data)\n",
    "    subject_data_df.loc[sub_loc, \"Removed rows\"] = removed_hits\n",
    "    subject_data_df.loc[sub_loc, \"Removed rows (%)\"] = prop\n",
    "    \n",
    "    \n",
    "if Subject_Info_save_bool == True:\n",
    "    # saving the subject info dataframe\n",
    "    try:\n",
    "        subject_data_df.to_csv(PROCESSED_DATA_PATH\n",
    "                                       + \"Subject_Data.csv\", \n",
    "                                        index=False)\n",
    "\n",
    "        print(\"Subject Info dataframe saved\")\n",
    "    except:\n",
    "        print(\"\\tCould not save subject \" + str(subject) + \" interpolation dataframe!\")\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Subject Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean/STD Eye Tracking Sessions: 3.71/0.7\n",
      "Mean/STD Total Rows: 1705211.71/18773.62\n",
      "Mean/STD DataLoss Combined: 5.52%/3.39%\n",
      "Mean/STD Condensed Size and Removed Rows: 49295.43/6739.1 - 4610.57/810.06(8.54%/0.95%)\n"
     ]
    }
   ],
   "source": [
    "with open(PROCESSED_DATA_PATH + 'subject_data.csv') as f:\n",
    "    try:\n",
    "        subject_data_df = pd.read_csv(f)\n",
    "    except:\n",
    "            print(\"\\tCould not load subject data!\")\n",
    "            \n",
    "mean_ET_Sessions = round(np.mean(subject_data_df.ET_Sessions),2)\n",
    "std_ET_Sessions = round(np.std(subject_data_df.ET_Sessions),2)\n",
    "\n",
    "mean_rows = round(np.mean(subject_data_df[\"Total Rows Combined\"]),2)\n",
    "std_rows = round(np.std(subject_data_df[\"Total Rows Combined\"]),2)\n",
    "\n",
    "mean_rows = round(np.mean(subject_data_df[\"Total Rows Combined\"]),2)\n",
    "std_rows = round(np.std(subject_data_df[\"Total Rows Combined\"]),2)\n",
    "\n",
    "mean_dataloss = round(100*np.mean(subject_data_df[\"DataLoss Combined\"]),2)\n",
    "std_dataloss = round(100*np.std(subject_data_df[\"DataLoss Combined\"]),2)\n",
    "\n",
    "mean_condensed_size = round(np.mean(subject_data_df[\"Condensed Size\"]), 2)\n",
    "std_condensed_size = round(np.std(subject_data_df[\"Condensed Size\"]),2)\n",
    "\n",
    "mean_removed_rows = round(np.mean(subject_data_df[\"Removed rows\"]),2)\n",
    "std_removed_rows = round(np.std(subject_data_df[\"Removed rows\"]),2)\n",
    "\n",
    "mean_removed_rows_per = round(100*np.mean(subject_data_df[\"Removed rows (%)\"]),2)\n",
    "std_removed_rows_per = round(100*np.std(subject_data_df[\"Removed rows (%)\"]),2)\n",
    "\n",
    "            \n",
    "print('Mean/STD Eye Tracking Sessions: {}/{}'.format(mean_ET_Sessions, std_ET_Sessions))\n",
    "print('Mean/STD Total Rows: {}/{}'.format(mean_rows, std_rows))\n",
    "print('Mean/STD DataLoss Combined: {}%/{}%'.format(mean_dataloss, std_dataloss))\n",
    "print('Mean/STD Condensed Size and Removed Rows: {}/{} - {}/{}({}%/{}%)'.format(mean_condensed_size, \\\n",
    "                                                                                std_condensed_size, \\\n",
    "                                                                                mean_removed_rows, \\\n",
    "                                                                                std_removed_rows, \\\n",
    "                                                                                mean_removed_rows_per, \\\n",
    "                                                                                std_removed_rows_per))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the JSON file as dictionary\n",
    "with open(THEORETICAL_PROCESSED_DATA_PATH + '1005_interpolation_df.csv') as f:\n",
    "    try:\n",
    "        interpolated_data = pd.read_csv(f)\n",
    "    except:\n",
    "            print(\"\\tCould not save subject \" + str(subject) + \" condensed dataframe!\")\n",
    "            \n",
    "# open the JSON file as dictionary\n",
    "#with open(PROCESSED_DATA_PATH + '1023_Condense_RLE_df.csv') as f:\n",
    "#    try:\n",
    "#        condense_RLE_df = pd.read_csv(f)\n",
    "#    except:\n",
    "#            print(\"\\tCould not save subject \" + str(subject) + \" condensed dataframe!\")\n",
    "#            \n",
    "#            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'condense_RLE_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-63ccfb616108>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgazes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcondense_RLE_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcondense_RLE_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSamples\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcondense_RLE_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcondense_RLE_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSamples\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgazes_interpolated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterpolated_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterpolated_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSamples\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnoise_interpolated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterpolated_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterpolated_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSamples\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'condense_RLE_df' is not defined"
     ]
    }
   ],
   "source": [
    "gazes = condense_RLE_df[condense_RLE_df.Samples>21].Samples.sum()\n",
    "noise = condense_RLE_df[condense_RLE_df.Samples<21].Samples.sum()\n",
    "\n",
    "gazes_interpolated = interpolated_data[interpolated_data.Samples>21].Samples.sum()\n",
    "noise_interpolated = interpolated_data[interpolated_data.Samples<21].Samples.sum()\n",
    "\n",
    "\n",
    "\n",
    "# Data to plot\n",
    "labels = 'Gazes', 'Noise'\n",
    "sizes = [gazes, noise]\n",
    "colors = ['orange', 'gray']\n",
    "explode = (0, 0, 0, 0)  # explode 1st slice\n",
    "\n",
    "# Data to plot after interpolation\n",
    "labels_interpolated = 'Gazes', 'Noise'\n",
    "sizes_interpolated = [gazes_interpolated, noise_interpolated]\n",
    "colors_interpolated = ['lightgreen', 'gray']\n",
    "explode_interpolated = (0, 0, 0, 0)  # explode 1st slice\n",
    "\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,2,1)\n",
    "plt.pie(sizes, labels=labels, colors=colors,\n",
    "autopct='%1.1f%%', shadow=False, startangle=140)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.pie(sizes_interpolated, labels=labels_interpolated, colors=colors_interpolated,\n",
    "autopct='%1.1f%%', shadow=False, startangle=140)\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most viewed building after interpolation is currently 1.59 sigma away from the mean!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ColliderName\n",
       "TaskBuilding_40    3578\n",
       "TaskBuilding_1     3657\n",
       "TaskBuilding_25    3703\n",
       "TaskBuilding_14    3802\n",
       "TaskBuilding_19    3879\n",
       "Building_136       3946\n",
       "Building_198       3954\n",
       "TaskBuilding_29    4138\n",
       "Building_176       4141\n",
       "TaskBuilding_27    4468\n",
       "Building_210       4993\n",
       "church             5008\n",
       "TaskBuilding_50    6048\n",
       "TaskBuilding_35    6786\n",
       "NoHit              8221\n",
       "Name: Samples, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gazes_interpolated = interpolated_data[interpolated_data.Samples>21]\n",
    "\n",
    "ColliderAppearances = gazes_interpolated.groupby('ColliderName').Samples.sum()\n",
    "\n",
    "Colliders_onlyHouses = ColliderAppearances.copy()\n",
    "Colliders_onlyHouses = Colliders_onlyHouses.drop(labels=['NoHouse'])\n",
    "Colliders_onlyHouses = Colliders_onlyHouses.sort_values()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sorted_interpolation = interpolated_data.groupby('ColliderName').Samples.sum().sort_values()\n",
    "\n",
    "building14distance = round((sorted_interpolation['TaskBuilding_14'] \\\n",
    "                            - sorted_interpolation[0:-1].mean()) \\\n",
    "                           / sorted_interpolation[0:-1].std(),2)\n",
    "\n",
    "print('The most viewed building after interpolation is currently {} sigma away from the mean!'.format(building14distance))\n",
    "ColliderAppearances.sort_values()[-16:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.1530242 , 0.03133377, 0.02260452, 0.01312736, 0.0136241 ,\n",
       "        0.00834414, 0.00725019, 0.00636833, 0.00694321, 0.00474974,\n",
       "        0.00405765, 0.00319254, 0.00310324, 0.00351626, 0.0023944 ,\n",
       "        0.00198696, 0.00173022, 0.00209859, 0.00125581, 0.00125581,\n",
       "        0.00106046, 0.00106604, 0.00118325, 0.00084837, 0.00070325,\n",
       "        0.00066418, 0.00084837, 0.00052465, 0.00046883, 0.0005693 ,\n",
       "        0.01010226]),\n",
       " array([1.0, 4.225806451612903, 7.451612903225806, 10.677419354838708,\n",
       "        13.903225806451612, 17.129032258064516, 20.354838709677416,\n",
       "        23.58064516129032, 26.806451612903224, 30.032258064516128,\n",
       "        33.25806451612903, 36.483870967741936, 39.70967741935483,\n",
       "        42.93548387096774, 46.16129032258064, 49.387096774193544,\n",
       "        52.61290322580645, 55.83870967741935, 59.064516129032256,\n",
       "        62.29032258064516, 65.51612903225806, 68.74193548387096,\n",
       "        71.96774193548387, 75.19354838709677, 78.41935483870967,\n",
       "        81.64516129032258, 84.87096774193547, 88.09677419354838,\n",
       "        91.32258064516128, 94.54838709677419, 97.77419354838709, 101.0],\n",
       "       dtype=object),\n",
       " <BarContainer object of 31 artists>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "interpolation_til_100 = interpolated_data.copy()\n",
    "interpolation_til_100 = interpolation_til_100.Samples\n",
    "interpolation_til_100[interpolation_til_100>100] = 101\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.title('Interpolated Samples, values above 100 in one bin')\n",
    "plt.hist(interpolation_til_100, bins= 31, density=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Creation\n",
    "* The graph creation involves the following steps:\n",
    "    * creating the edge list\n",
    "        * Remove non Fixations (SampleSize <= 21) \n",
    "        * Remove all noHouse hits \n",
    "        * Remove all noHit hits \n",
    "        * Remove all self repetitions\n",
    "        * Shift the edgelist by one row and create chronology \n",
    "    * Use NetworkX to build the graph\n",
    "    * Plot the graph onto the city map (using map coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 1005 started - 1/1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'TaskBuilding_35'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/Applications/anaconda3/envs/graphs/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'TaskBuilding_35'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-79efcd15d7fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnodelist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;31m# assign node coordinates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhouselist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'transformed_collidercenter_x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhouselist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'transformed_collidercenter_y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mnode_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/graphs/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/graphs/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'TaskBuilding_35'"
     ]
    }
   ],
   "source": [
    "# --------- Preparation ---------\n",
    "Plotting_bool = True # if you want to plot the graph\n",
    "EdgeList_save_bool = True # if you want to save the edge list \n",
    "Graph_save_bool = True # if you want to save the graph as a networkx graph\n",
    "Graph_save_img_bool = True # if you want to save the graph as an image\n",
    "plot_edges_bool = False # if you want to plot the graph's edges\n",
    "\n",
    "subcount = 0 # count subjects\n",
    "\n",
    "# implement parula color map scheme from matlab \n",
    "cm_data = [[0.2081, 0.1663, 0.5292], [0.2116238095, 0.1897809524, 0.5776761905], \n",
    " [0.212252381, 0.2137714286, 0.6269714286], [0.2081, 0.2386, 0.6770857143], \n",
    " [0.1959047619, 0.2644571429, 0.7279], [0.1707285714, 0.2919380952, \n",
    "  0.779247619], [0.1252714286, 0.3242428571, 0.8302714286], \n",
    " [0.0591333333, 0.3598333333, 0.8683333333], [0.0116952381, 0.3875095238, \n",
    "  0.8819571429], [0.0059571429, 0.4086142857, 0.8828428571], \n",
    " [0.0165142857, 0.4266, 0.8786333333], [0.032852381, 0.4430428571, \n",
    "  0.8719571429], [0.0498142857, 0.4585714286, 0.8640571429], \n",
    " [0.0629333333, 0.4736904762, 0.8554380952], [0.0722666667, 0.4886666667, \n",
    "  0.8467], [0.0779428571, 0.5039857143, 0.8383714286], \n",
    " [0.079347619, 0.5200238095, 0.8311809524], [0.0749428571, 0.5375428571, \n",
    "  0.8262714286], [0.0640571429, 0.5569857143, 0.8239571429], \n",
    " [0.0487714286, 0.5772238095, 0.8228285714], [0.0343428571, 0.5965809524, \n",
    "  0.819852381], [0.0265, 0.6137, 0.8135], [0.0238904762, 0.6286619048, \n",
    "  0.8037619048], [0.0230904762, 0.6417857143, 0.7912666667], \n",
    " [0.0227714286, 0.6534857143, 0.7767571429], [0.0266619048, 0.6641952381, \n",
    "  0.7607190476], [0.0383714286, 0.6742714286, 0.743552381], \n",
    " [0.0589714286, 0.6837571429, 0.7253857143], \n",
    " [0.0843, 0.6928333333, 0.7061666667], [0.1132952381, 0.7015, 0.6858571429], \n",
    " [0.1452714286, 0.7097571429, 0.6646285714], [0.1801333333, 0.7176571429, \n",
    "  0.6424333333], [0.2178285714, 0.7250428571, 0.6192619048], \n",
    " [0.2586428571, 0.7317142857, 0.5954285714], [0.3021714286, 0.7376047619, \n",
    "  0.5711857143], [0.3481666667, 0.7424333333, 0.5472666667], \n",
    " [0.3952571429, 0.7459, 0.5244428571], [0.4420095238, 0.7480809524, \n",
    "  0.5033142857], [0.4871238095, 0.7490619048, 0.4839761905], \n",
    " [0.5300285714, 0.7491142857, 0.4661142857], [0.5708571429, 0.7485190476, \n",
    "  0.4493904762], [0.609852381, 0.7473142857, 0.4336857143], \n",
    " [0.6473, 0.7456, 0.4188], [0.6834190476, 0.7434761905, 0.4044333333], \n",
    " [0.7184095238, 0.7411333333, 0.3904761905], \n",
    " [0.7524857143, 0.7384, 0.3768142857], [0.7858428571, 0.7355666667, \n",
    "  0.3632714286], [0.8185047619, 0.7327333333, 0.3497904762], \n",
    " [0.8506571429, 0.7299, 0.3360285714], [0.8824333333, 0.7274333333, 0.3217], \n",
    " [0.9139333333, 0.7257857143, 0.3062761905], [0.9449571429, 0.7261142857, \n",
    "  0.2886428571], [0.9738952381, 0.7313952381, 0.266647619], \n",
    " [0.9937714286, 0.7454571429, 0.240347619], [0.9990428571, 0.7653142857, \n",
    "  0.2164142857], [0.9955333333, 0.7860571429, 0.196652381], \n",
    " [0.988, 0.8066, 0.1793666667], [0.9788571429, 0.8271428571, 0.1633142857], \n",
    " [0.9697, 0.8481380952, 0.147452381], [0.9625857143, 0.8705142857, 0.1309], \n",
    " [0.9588714286, 0.8949, 0.1132428571], [0.9598238095, 0.9218333333, \n",
    "  0.0948380952], [0.9661, 0.9514428571, 0.0755333333], \n",
    " [0.9763, 0.9831, 0.0538]]\n",
    "\n",
    "parula_map = LinearSegmentedColormap.from_list('parula', cm_data)\n",
    "\n",
    "# load the city map image\n",
    "white_bg_img = cv2.imread(\"./ressources/map_white.png\")\n",
    "\n",
    "\n",
    "\n",
    "# --------- MAIN PART ---------\n",
    "# load the files \n",
    "for subject in subIDs:\n",
    "    subcount +=1\n",
    "    print('Subject ' + str(subject) + ' started - ' + str(subcount) + '/' + str(len(subIDs)))\n",
    "    \n",
    "    # get the data files according to the subject\n",
    "    subject_folder = sorted([f for f in PROCESSED_DATA_FOLDER \n",
    "                             if f.startswith(str(subject)+'_interpolation_df')], key=str.lower)\n",
    "\n",
    "    # open the JSON file as dictionary\n",
    "    with open(PROCESSED_DATA_PATH + subject_folder[0]) as f:\n",
    "        try:\n",
    "            interpolated_data = pd.read_csv(f)\n",
    "        except:\n",
    "                print(\"\\tCould not load subject \" + str(subject) + \" interpolation dataframe!\")\n",
    "\n",
    "\n",
    "        edge_list = pd.DataFrame(columns=['Edge1','Edge2'])\n",
    "\n",
    "\n",
    "\n",
    "        # --------- EDGE LIST CREATION ---------\n",
    "\n",
    "        # filter out Clusters with <=21 hits, 'NoHouse' hits, 'NoHit' hits and self repititions (with unique)\n",
    "        transition = interpolated_data[interpolated_data.Samples>21]\n",
    "        transition = transition[transition.ColliderName!='NoHouse']\n",
    "        transition = transition[transition.ColliderName!='NoHit']\n",
    "        unique_count = transition.ColliderName.groupby((transition['ColliderName'] \n",
    "                                                != transition['ColliderName'].shift()).cumsum()).cumcount() + 1\n",
    "\n",
    "        # Assign filtered gaze hits to the edge list \n",
    "        edge_list.Edge1 = transition[unique_count==1].ColliderName\n",
    "        edge_list.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        # shift the gaze hits by one and add the last entry of Edge1 to the first of Edge 2\n",
    "        edge_list.Edge2[1:len(edge_list)-1] = edge_list.Edge1[0:len(edge_list)-2]\n",
    "        edge_list.loc[0, 'Edge2'] = edge_list.Edge1[len(edge_list)-1]\n",
    "        edge_list.loc[len(edge_list)-1, 'Edge2'] = edge_list.Edge1[0]\n",
    "\n",
    "        # --------- GRAPH CREATION ---------\n",
    "\n",
    "        # create graph from edgelist\n",
    "        G = nx.Graph()\n",
    "        G = nx.from_pandas_edgelist(edge_list, 'Edge1', 'Edge2')\n",
    "\n",
    "\n",
    "        # Setting the node coordinates of each node of the graph\n",
    "\n",
    "\n",
    "        # node list\n",
    "        nodelist = list(G.nodes)\n",
    "\n",
    "        # coord dict\n",
    "        node_pos = {}\n",
    "\n",
    "        for node in nodelist:\n",
    "            # assign node coordinates\n",
    "            x = houselist[node]['transformed_collidercenter_x']\n",
    "            y = houselist[node]['transformed_collidercenter_y']\n",
    "            node_pos[node] = (x,y) \n",
    "\n",
    "        # set the graph's node coordinates attribute\n",
    "        nx.set_node_attributes(G, node_pos, 'coord')\n",
    "\n",
    "\n",
    "        # --------- ANALYSIS ---------\n",
    "\n",
    "        # create degree list of the graph \n",
    "\n",
    "        centrality_df = pd.DataFrame(list(G.degree), columns=['node','degree'])\n",
    "        centrality_df['betweenness'] = list(G.betweenness_centrality)\n",
    "\n",
    "\n",
    "        mean_degree = np.mean(degree_df['degree'])\n",
    "        std_degree = np.std(degree_df['degree'])\n",
    "        max_degree = max(degree_df['degree'])\n",
    "\n",
    "        print('\\tMean/Std Degree: ' + str(\"{:.2f}\".format(mean_degree)) + '/' + str(\"{:.2f}\".format(std_degree)))\n",
    "        print('\\tMaxmimum Degree of ' \n",
    "              + str(\"{:.2f}\".format(max_degree)) \n",
    "              + ' is ' +\n",
    "              \"{:.2f}\".format((max_degree-mean_degree)/std_degree)\n",
    "              + ' sigma away from the mean')\n",
    "\n",
    "\n",
    "\n",
    "        # --------- PLOTTING ---------    \n",
    "\n",
    "        if Plotting_bool == True:\n",
    "\n",
    "            # plot the map\n",
    "            fig = plt.figure(figsize=(20,15))\n",
    "            ax = plt.subplot2grid((10, 10), (0, 0), colspan=9,rowspan=10)\n",
    "            plt.title(\"Graph on Map - Subject \" + str(subject))\n",
    "            plt.xlim(0, 4096)\n",
    "            plt.ylim(0, 4096)\n",
    "            ax.set_frame_on(False)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(white_bg_img,aspect=ax.get_aspect(),\n",
    "                     extent= ax.get_xlim() + ax.get_ylim(),\n",
    "                     zorder=1, alpha=0.8)\n",
    "\n",
    "            # Draw the graph \n",
    "            vmin = degree_df['degree'].min()\n",
    "            vmax = degree_df['degree'].max()\n",
    "\n",
    "            nx.draw_networkx_nodes(G,\n",
    "                                   node_pos, \n",
    "                                   alpha = 1, \n",
    "                                   node_size = 100, \n",
    "                                   node_color=degree_df['degree'], \n",
    "                                   cmap=parula_map)\n",
    "\n",
    "            if plot_edges_bool == True:\n",
    "                nx.draw_networkx_edges(G, \n",
    "                                       node_pos, \n",
    "                                       edge_color='k', \n",
    "                                       alpha=0.5, \n",
    "                                       width=1,\n",
    "                                       style='dashed')\n",
    "\n",
    "\n",
    "            # subgraph for highlighting single nodes\n",
    "            building = list(degree_df.sort_values('degree', ascending=False)[:10].node) #'Building_214'\n",
    "            #nx.draw_networkx(G.subgraph(building), node_color = 'r', pos=node_pos, node_size=400)\n",
    "\n",
    "\n",
    "            sm = plt.cm.ScalarMappable(cmap=parula_map, norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "            sm.set_array([])\n",
    "            cbar = plt.colorbar(sm)\n",
    "            cbar.ax.tick_params(labelsize=20)\n",
    "            cbar.set_label('Node Degree', size=20)\n",
    "\n",
    "\n",
    "        # --------- SAVING ---------\n",
    "        \n",
    "        # save the edge list \n",
    "        if EdgeList_save_bool == True:\n",
    "            # saving the subject info dataframe\n",
    "            try:\n",
    "                edge_list.to_csv(THEORETICAL_GRAPH_PATH\n",
    "                                + str(subject)\n",
    "                                + \"_edgelist.csv\", \n",
    "                                index=False)\n",
    "\n",
    "                print(\"\\tEdge list saved\")\n",
    "            except:\n",
    "                print(\"\\tCould not save subject \" + str(subject) + \" edge list!\")\n",
    "\n",
    "        \n",
    "        \n",
    "        # save the graph \n",
    "        if Graph_save_bool == True:\n",
    "            # saving the subject info dataframe\n",
    "            try:\n",
    "                nx.write_gexf(G, THEORETICAL_GRAPH_PATH + str(subject) + '_Graph')\n",
    "\n",
    "                print(\"\\tGraph saved\")\n",
    "            except:\n",
    "                print(\"\\tCould not save subject \" + str(subject) + \" Graph!\")\n",
    "\n",
    "        # save the graph as png \n",
    "        if Graph_save_img_bool == True:\n",
    "            # saving the subject info dataframe\n",
    "            try:\n",
    "                plt.savefig(THEORETICAL_GRAPH_PATH + str(subject) + \"_Graph.png\", format=\"PNG\")\n",
    "\n",
    "                print(\"\\tGraph PNG saved\")\n",
    "            except:\n",
    "                print(\"\\tCould not save subject \" + str(subject) + \" Graph as PNG!\")\n",
    "                \n",
    "    \n",
    "        \n",
    "        \n",
    "print('Done')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'centrality_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-69587c118b06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcentrality_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'centrality_df' is not defined"
     ]
    }
   ],
   "source": [
    "centrality_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "centrality_df = pd.DataFrame(list(G.degree), columns=['node','degree'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Building_214</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Building_154</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TaskBuilding_35</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Building_176</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Building_97</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Building_171</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Building_152</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TaskBuilding_27</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Building_198</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Building_232</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Building_166</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>TaskBuilding_50</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Building_215</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>church</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Building_158</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                node  degree\n",
       "127     Building_214      31\n",
       "119     Building_154      30\n",
       "0    TaskBuilding_35      29\n",
       "24      Building_176      28\n",
       "13       Building_97      27\n",
       "129     Building_171      26\n",
       "185     Building_152      24\n",
       "8    TaskBuilding_27      24\n",
       "137     Building_198      24\n",
       "90      Building_232      24\n",
       "2       Building_166      23\n",
       "130  TaskBuilding_50      23\n",
       "116     Building_215      23\n",
       "62            church      23\n",
       "19      Building_158      23"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centrality_df.sort_values(by='degree', ascending=False)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.hist(degree_values, bins=15, ec='black')\n",
    "plt.xlabel(\"Node Degree\", fontsize=30)\n",
    "plt.ylabel(\"Frequency\", fontsize=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean/Std Degree: 15.54/6.93\n",
      "Maxmimum Degree of 34.00 is 2.66 sigma away from the mean\n"
     ]
    }
   ],
   "source": [
    "mean_degree = np.mean(degree_values)\n",
    "std_degree = np.std(degree_values)\n",
    "max_degree = max(degree_values)\n",
    "\n",
    "print('Mean/Std Degree: ' + str(\"{:.2f}\".format(mean_degree)) + '/' + str(\"{:.2f}\".format(std_degree)))\n",
    "print('Maxmimum Degree of ' \n",
    "      + str(\"{:.2f}\".format(max_degree)) \n",
    "      + ' is ' +\n",
    "      \"{:.2f}\".format((max_degree-mean_degree)/std_degree)\n",
    "      + ' sigma away from the mean')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
